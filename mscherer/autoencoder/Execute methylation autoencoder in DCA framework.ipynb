{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "developing-essence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-30 11:22:23.903062: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-07-30 11:22:23.903078: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/users/mscherer/software/anaconda3/envs/dca/lib/python3.8/site-packages/kopt/config.py:60: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  _config = yaml.load(open(_config_path))\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import os\n",
    "from dca.api import dca\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aquatic-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 'Sample5_80_percent'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2cb355",
   "metadata": {},
   "source": [
    "Loading the read count data and potentially removing cell doublets/mulitplets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compressed-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_table('/users/lvelten/project/Methylome/analysis/missionbio/tapestri/' + sample + '/tsv/' + sample + '.barcode.cell.distribution.tsv',sep='\\t')\n",
    "remove_mixed = True\n",
    "if remove_mixed:\n",
    "    clust_file = pd.read_csv('/users/lvelten/project/Methylome/analysis/missionbio/tapestri/'+ sample + '/tsv/cluster_assignment.tsv',\n",
    "                            sep='\\t')\n",
    "    drop_rows = clust_file['Barcode'][clust_file['CellType']=='Mixed']\n",
    "    dat = dat.drop(drop_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5238c4e4",
   "metadata": {},
   "source": [
    "Creating an AnnData object from the read counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7bda643",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.AnnData(dat)\n",
    "sc.pp.filter_genes(adata,min_cells=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8a670e",
   "metadata": {},
   "source": [
    "Running the autoencoder: Currently, we have the following available architectures:\n",
    "\n",
    "    -'meth-encoder': A classical autoencoder, where the dispersion parameters of both NB-distributions can be freely selected by the model.\n",
    "    -'meth-encoder-constant': An autoencoder, where the dispersion parameters is fixed for each gene. This lowers the number of paramters substantially.\n",
    "    -'meth-encoder-poisson': An autoencoder, which mixes a negative bionomial distribution (foreground) with a Poisson distribution as the background\n",
    "    -'meth-encoder-poisson-constant': Same as the above, but with a fixed dispersion for each gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "elementary-queen",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-30 11:22:26.717235: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-30 11:22:26.717382: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-07-30 11:22:26.717395: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-07-30 11:22:26.717410: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (CZC041BTPK): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dca: Successfully preprocessed 199 genes and 5207 cells.\n",
      "WARNING:tensorflow:From /users/lvelten/project/Methylome/src/error_mod/dca/dca/train.py:41: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-30 11:22:26,871 [WARNING] From /users/lvelten/project/Methylome/src/error_mod/dca/dca/train.py:41: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n",
      "2021-07-30 11:22:26.873307: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "count (InputLayer)              [(None, 199)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc0 (Dense)                    (None, 16)           3200        count[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 16)           48          enc0[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "enc0_act (Activation)           (None, 16)           0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "center (Dense)                  (None, 8)            136         enc0_act[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8)            24          center[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_act (Activation)         (None, 8)            0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dec1 (Dense)                    (None, 16)           144         center_act[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16)           48          dec1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dec1_act (Activation)           (None, 16)           0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "pi (Dense)                      (None, 199)          3383        dec1_act[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "size_factors (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 199)          0           pi[0][0]                         \n",
      "                                                                 size_factors[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,983\n",
      "Trainable params: 6,903\n",
      "Non-trainable params: 80\n",
      "__________________________________________________________________________________________________\n",
      "Train on 4686 samples, validate on 521 samples\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-30 11:22:27.681601: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2021-07-30 11:22:27.704049: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3000000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 1s 139us/sample - loss: 80.3345 - val_loss: 81.1404\n",
      "Epoch 2/300\n",
      "2272/4686 [=============>................] - ETA: 0s - loss: 79.4717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/mscherer/software/anaconda3/envs/dca/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.8257 - val_loss: 80.7826\n",
      "Epoch 3/300\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 79.6470 - val_loss: 80.6803\n",
      "Epoch 4/300\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 79.6032 - val_loss: 80.6545\n",
      "Epoch 5/300\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 79.5904 - val_loss: 80.6465\n",
      "Epoch 6/300\n",
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5862 - val_loss: 80.6425\n",
      "Epoch 7/300\n",
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5830 - val_loss: 80.6394\n",
      "Epoch 8/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5805 - val_loss: 80.6365\n",
      "Epoch 9/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5787 - val_loss: 80.6343\n",
      "Epoch 10/300\n",
      "4686/4686 [==============================] - 0s 46us/sample - loss: 79.5769 - val_loss: 80.6336\n",
      "Epoch 11/300\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 79.5756 - val_loss: 80.6315\n",
      "Epoch 12/300\n",
      "4686/4686 [==============================] - 0s 54us/sample - loss: 79.5742 - val_loss: 80.6304\n",
      "Epoch 13/300\n",
      "4686/4686 [==============================] - 0s 52us/sample - loss: 79.5730 - val_loss: 80.6287\n",
      "Epoch 14/300\n",
      "4686/4686 [==============================] - 0s 57us/sample - loss: 79.5721 - val_loss: 80.6274\n",
      "Epoch 15/300\n",
      "4686/4686 [==============================] - 0s 53us/sample - loss: 79.5716 - val_loss: 80.6261\n",
      "Epoch 16/300\n",
      "4686/4686 [==============================] - 0s 54us/sample - loss: 79.5710 - val_loss: 80.6259\n",
      "Epoch 17/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5703 - val_loss: 80.6252\n",
      "Epoch 18/300\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 79.5696 - val_loss: 80.6245\n",
      "Epoch 19/300\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 79.5694 - val_loss: 80.6239\n",
      "Epoch 20/300\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 79.5685 - val_loss: 80.6232\n",
      "Epoch 21/300\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 79.5675 - val_loss: 80.6233\n",
      "Epoch 22/300\n",
      "4686/4686 [==============================] - 0s 46us/sample - loss: 79.5677 - val_loss: 80.6240\n",
      "Epoch 23/300\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 79.5673 - val_loss: 80.6221\n",
      "Epoch 24/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5664 - val_loss: 80.6224\n",
      "Epoch 25/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5671 - val_loss: 80.6224\n",
      "Epoch 26/300\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 79.5657 - val_loss: 80.6217\n",
      "Epoch 27/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5660 - val_loss: 80.6216\n",
      "Epoch 28/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5642 - val_loss: 80.6221\n",
      "Epoch 29/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5651 - val_loss: 80.6219\n",
      "Epoch 30/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5642 - val_loss: 80.6219\n",
      "Epoch 31/300\n",
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5639 - val_loss: 80.6231\n",
      "Epoch 32/300\n",
      "4686/4686 [==============================] - 0s 46us/sample - loss: 79.5638 - val_loss: 80.6218\n",
      "Epoch 33/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5639 - val_loss: 80.6221\n",
      "Epoch 34/300\n",
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5628 - val_loss: 80.6208\n",
      "Epoch 35/300\n",
      "4686/4686 [==============================] - 0s 46us/sample - loss: 79.5622 - val_loss: 80.6210\n",
      "Epoch 36/300\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 79.5628 - val_loss: 80.6210\n",
      "Epoch 37/300\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 79.5627 - val_loss: 80.6215\n",
      "Epoch 38/300\n",
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5628 - val_loss: 80.6223\n",
      "Epoch 39/300\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 79.5616 - val_loss: 80.6214\n",
      "Epoch 40/300\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 79.5611 - val_loss: 80.6215\n",
      "Epoch 41/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5616 - val_loss: 80.6201\n",
      "Epoch 42/300\n",
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5621 - val_loss: 80.6193\n",
      "Epoch 43/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5611 - val_loss: 80.6232\n",
      "Epoch 44/300\n",
      "4686/4686 [==============================] - 0s 50us/sample - loss: 79.5617 - val_loss: 80.6203\n",
      "Epoch 45/300\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 79.5600 - val_loss: 80.6217\n",
      "Epoch 46/300\n",
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5604 - val_loss: 80.6202\n",
      "Epoch 47/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5602 - val_loss: 80.6210\n",
      "Epoch 48/300\n",
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5602 - val_loss: 80.6230\n",
      "Epoch 49/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5604 - val_loss: 80.6207\n",
      "Epoch 50/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5606 - val_loss: 80.6209\n",
      "Epoch 51/300\n",
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5595 - val_loss: 80.6234\n",
      "Epoch 52/300\n",
      "4576/4686 [============================>.] - ETA: 0s - loss: 79.5381\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "4686/4686 [==============================] - 0s 55us/sample - loss: 79.5595 - val_loss: 80.6214\n",
      "Epoch 53/300\n",
      "4686/4686 [==============================] - 0s 51us/sample - loss: 79.5584 - val_loss: 80.6212\n",
      "Epoch 54/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5584 - val_loss: 80.6210\n",
      "Epoch 55/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5581 - val_loss: 80.6211\n",
      "Epoch 56/300\n",
      "4686/4686 [==============================] - 0s 50us/sample - loss: 79.5587 - val_loss: 80.6207\n",
      "Epoch 57/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5580 - val_loss: 80.6209\n",
      "Epoch 58/300\n",
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5588 - val_loss: 80.6208\n",
      "Epoch 59/300\n",
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5586 - val_loss: 80.6207\n",
      "Epoch 60/300\n",
      "4686/4686 [==============================] - 0s 50us/sample - loss: 79.5573 - val_loss: 80.6204\n",
      "Epoch 61/300\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 79.5581 - val_loss: 80.6203\n",
      "Epoch 62/300\n",
      "4512/4686 [===========================>..] - ETA: 0s - loss: 79.6160\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5583 - val_loss: 80.6205\n",
      "Epoch 63/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5579 - val_loss: 80.6204\n",
      "Epoch 64/300\n",
      "4686/4686 [==============================] - 0s 50us/sample - loss: 79.5581 - val_loss: 80.6206\n",
      "Epoch 65/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5580 - val_loss: 80.6204\n",
      "Epoch 66/300\n",
      "4686/4686 [==============================] - 0s 50us/sample - loss: 79.5578 - val_loss: 80.6203\n",
      "Epoch 67/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5575 - val_loss: 80.6203\n",
      "Epoch 68/300\n",
      "4686/4686 [==============================] - 0s 50us/sample - loss: 79.5574 - val_loss: 80.6202\n",
      "Epoch 69/300\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 79.5571 - val_loss: 80.6204\n",
      "Epoch 70/300\n",
      "4686/4686 [==============================] - 0s 50us/sample - loss: 79.5578 - val_loss: 80.6202\n",
      "Epoch 71/300\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 79.5570 - val_loss: 80.6204\n",
      "Epoch 72/300\n",
      "4480/4686 [===========================>..] - ETA: 0s - loss: 79.4876\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5590 - val_loss: 80.6203\n",
      "Epoch 73/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5574 - val_loss: 80.6203\n",
      "Epoch 74/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5579 - val_loss: 80.6202\n",
      "Epoch 75/300\n",
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5586 - val_loss: 80.6203\n",
      "Epoch 76/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5575 - val_loss: 80.6203\n",
      "Epoch 77/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5584 - val_loss: 80.6202\n",
      "Epoch 78/300\n",
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5587 - val_loss: 80.6203\n",
      "Epoch 79/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5580 - val_loss: 80.6203\n",
      "Epoch 80/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5584 - val_loss: 80.6203\n",
      "Epoch 81/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5584 - val_loss: 80.6203\n",
      "Epoch 82/300\n",
      "4448/4686 [===========================>..] - ETA: 0s - loss: 79.4591\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "4686/4686 [==============================] - 0s 50us/sample - loss: 79.5570 - val_loss: 80.6202\n",
      "Epoch 83/300\n",
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5575 - val_loss: 80.6203\n",
      "Epoch 84/300\n",
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5586 - val_loss: 80.6203\n",
      "Epoch 85/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5582 - val_loss: 80.6204\n",
      "Epoch 86/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5581 - val_loss: 80.6204\n",
      "Epoch 87/300\n",
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5574 - val_loss: 80.6203\n",
      "Epoch 88/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5577 - val_loss: 80.6203\n",
      "Epoch 89/300\n",
      "4686/4686 [==============================] - 0s 49us/sample - loss: 79.5574 - val_loss: 80.6203\n",
      "Epoch 90/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5576 - val_loss: 80.6203\n",
      "Epoch 91/300\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5576 - val_loss: 80.6203\n",
      "Epoch 92/300\n",
      "4608/4686 [============================>.] - ETA: 0s - loss: 79.5107\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 79.5576 - val_loss: 80.6203\n",
      "Epoch 00092: early stopping\n",
      "dca: Calculating reconstructions...\n"
     ]
    }
   ],
   "source": [
    "res = dca(adata,\n",
    "          ae_type='meth-simple-encoder',\n",
    "          return_info=True,\n",
    "          return_model=True,\n",
    "          return_bottleneck=True,\n",
    "          verbose=True,\n",
    "          early_stop=50,\n",
    "          network_kwds={'debug': True},\n",
    "          init='glorot_normal',\n",
    "         hidden_size=(16,8,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8237a8",
   "metadata": {},
   "source": [
    "Writing the data on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "di = '/users/lvelten/project/Methylome/analysis/missionbio/tapestri/' + sample + '/methylation_autoencoder/'\n",
    "if not os.path.isdir(di):\n",
    "    os.mkdir(di)\n",
    "    \n",
    "pd.DataFrame(adata.obsm['X_meth_value']).to_csv(di + 'mixture_prob_dca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81520432",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = res.get_encoder().predict([adata.X, adata.X.mean(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beb56ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(adata.obsm['X_bottleneck']).to_csv(di + 'bottleneck.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6097b4d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lambda_poisson'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18267/462975560.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobsm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lambda_poisson'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'lambda_poisson_neg_binom.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/users/mscherer/software/anaconda3/envs/dca/lib/python3.8/site-packages/anndata/_core/aligned_mapping.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lambda_poisson'"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(adata.obsm['lambda_poisson']).to_csv(di + 'lambda_poisson_neg_binom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc49777",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(adata.var['meth_dispersion_nb']).to_csv(di + 'dispersion_nb_neg_binom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84c532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm['X_meth_value']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
