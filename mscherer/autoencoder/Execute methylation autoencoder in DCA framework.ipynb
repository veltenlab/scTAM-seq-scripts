{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "developing-essence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-03 18:04:07.267438: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-03 18:04:07.267456: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/users/mscherer/software/anaconda3/envs/dca/lib/python3.8/site-packages/kopt/config.py:60: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  _config = yaml.load(open(_config_path))\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import os\n",
    "from dca.api import dca\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d040f",
   "metadata": {},
   "source": [
    "### INPUT: Specify which sample you want to analyze. Currently available are:\n",
    "\n",
    "- Sample2_70_percent\n",
    "- Sample2_80_percent\n",
    "- Sample3_default\n",
    "- Sample4_70_percent\n",
    "- Sample4_80_percent\n",
    "- Sample5_70_percent\n",
    "- Sample5_80_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aquatic-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 'Sample5_80_percent'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2cb355",
   "metadata": {},
   "source": [
    "### Loading the read count data and potentially removing cell doublets/mulitplets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compressed-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_table('/users/lvelten/project/Methylome/analysis/missionbio/tapestri/' + sample + '/tsv/' + sample + '.barcode.cell.distribution.tsv',sep='\\t')\n",
    "remove_mixed = True\n",
    "if remove_mixed:\n",
    "    clust_file = pd.read_csv('/users/lvelten/project/Methylome/analysis/missionbio/tapestri/'+ sample + '/tsv/cluster_assignment.tsv',\n",
    "                            sep='\\t')\n",
    "    drop_rows = clust_file['Barcode'][clust_file['CellType']=='Mixed']\n",
    "    dat = dat.drop(drop_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5238c4e4",
   "metadata": {},
   "source": [
    "### Creating an AnnData object from the read counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7bda643",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.AnnData(dat)\n",
    "sc.pp.filter_genes(adata,min_cells=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8a670e",
   "metadata": {},
   "source": [
    "### Running the autoencoder: Currently, we have the following available architectures:\n",
    "\n",
    "- 'meth-encoder': A classical autoencoder, where the dispersion parameters of both NB-distributions can be freely selected by the model.\n",
    "- 'meth-encoder-constant': An autoencoder, where the dispersion parameters is fixed for each gene. This lowers the number of paramters substantially.\n",
    "- 'meth-encoder-poisson': An autoencoder, which mixes a negative bionomial distribution (foreground) with a Poisson distribution as the background\n",
    "- 'meth-encoder-poisson-constant': Same as the above, but with a fixed dispersion for each gene\n",
    "- 'meth-encoder-simple': Instead of having a dense layer representing the mean per cell and amplicon, we use a constant mean per amplicon for both the foreground and the background distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "elementary-queen",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-03 18:04:09.316161: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-03 18:04:09.316302: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-08-03 18:04:09.316314: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-08-03 18:04:09.316330: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (CZC041BTPK): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dca: Successfully preprocessed 199 genes and 5207 cells.\n",
      "WARNING:tensorflow:From /users/lvelten/project/Methylome/src/error_mod/dca/dca/train.py:41: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-03 18:04:09,483 [WARNING] From /users/lvelten/project/Methylome/src/error_mod/dca/dca/train.py:41: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n",
      "2021-08-03 18:04:09.485185: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "count (InputLayer)              [(None, 199)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc0 (Dense)                    (None, 16)           3200        count[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 16)           48          enc0[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "enc0_act (Activation)           (None, 16)           0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "center (Dense)                  (None, 8)            136         enc0_act[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8)            24          center[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_act (Activation)         (None, 8)            0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dec1 (Dense)                    (None, 16)           144         center_act[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16)           48          dec1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dec1_act (Activation)           (None, 16)           0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "pi (Dense)                      (None, 199)          3383        dec1_act[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dispersion1 (Linear)            (None, 1)            199         pi[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "dispersion2 (Linear)            (None, 1)            199         pi[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "size_factors (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mean1 (Linear)                  (None, 1)            1           dispersion1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "alpha (Linear)                  (None, 1)            1           dispersion2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 199)          0           pi[0][0]                         \n",
      "                                                                 size_factors[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul (TensorFlowOpLa [(None, 1)]          0           mean1[0][0]                      \n",
      "                                                                 alpha[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "slice (SliceLayer)              (None, 199)          0           lambda_1[0][0]                   \n",
      "                                                                 mean1[0][0]                      \n",
      "                                                                 tf_op_layer_mul[0][0]            \n",
      "                                                                 dispersion1[0][0]                \n",
      "                                                                 dispersion2[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,383\n",
      "Trainable params: 7,303\n",
      "Non-trainable params: 80\n",
      "__________________________________________________________________________________________________\n",
      "Train on 4686 samples, validate on 521 samples\n",
      "Epoch 1/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-03 18:04:10.231896: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2021-08-03 18:04:10.248573: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3000000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 1s 140us/sample - loss: 217.2549 - val_loss: 143.3026\n",
      "Epoch 2/3000\n",
      "1248/4686 [======>.......................] - ETA: 0s - loss: 101.7968"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/mscherer/software/anaconda3/envs/dca/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 44us/sample - loss: 82.8194 - val_loss: 69.0962\n",
      "Epoch 3/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 61.8633 - val_loss: 58.1922\n",
      "Epoch 4/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 53.0525 - val_loss: 49.7731\n",
      "Epoch 5/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 46.1407 - val_loss: 44.6369\n",
      "Epoch 6/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 42.4428 - val_loss: 41.9226\n",
      "Epoch 7/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 40.1475 - val_loss: 39.7273\n",
      "Epoch 8/3000\n",
      "4686/4686 [==============================] - 0s 47us/sample - loss: 38.1366 - val_loss: 37.8136\n",
      "Epoch 9/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 36.3758 - val_loss: 36.1032\n",
      "Epoch 10/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 34.7944 - val_loss: 34.5756\n",
      "Epoch 11/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 33.3687 - val_loss: 33.1881\n",
      "Epoch 12/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 32.0808 - val_loss: 31.9223\n",
      "Epoch 13/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 30.9074 - val_loss: 30.7886\n",
      "Epoch 14/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 29.8369 - val_loss: 29.7678\n",
      "Epoch 15/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 28.8530 - val_loss: 28.7618\n",
      "Epoch 16/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 27.9456 - val_loss: 27.8811\n",
      "Epoch 17/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 27.1059 - val_loss: 27.0390\n",
      "Epoch 18/3000\n",
      "4686/4686 [==============================] - 0s 46us/sample - loss: 26.3261 - val_loss: 26.2869\n",
      "Epoch 19/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 25.6008 - val_loss: 25.5643\n",
      "Epoch 20/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 24.9259 - val_loss: 24.9024\n",
      "Epoch 21/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 24.2980 - val_loss: 24.2839\n",
      "Epoch 22/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 23.7062 - val_loss: 23.6952\n",
      "Epoch 23/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 23.1478 - val_loss: 23.1572\n",
      "Epoch 24/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 22.6250 - val_loss: 22.6516\n",
      "Epoch 25/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 22.1373 - val_loss: 22.1617\n",
      "Epoch 26/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 21.6638 - val_loss: 21.6793\n",
      "Epoch 27/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 21.2229 - val_loss: 21.2552\n",
      "Epoch 28/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 20.8034 - val_loss: 20.8329\n",
      "Epoch 29/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 20.4114 - val_loss: 20.4581\n",
      "Epoch 30/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 20.0299 - val_loss: 20.0711\n",
      "Epoch 31/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 19.6721 - val_loss: 19.7032\n",
      "Epoch 32/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 19.3278 - val_loss: 19.3645\n",
      "Epoch 33/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 19.0034 - val_loss: 19.0371\n",
      "Epoch 34/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 18.6915 - val_loss: 18.7337\n",
      "Epoch 35/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 18.3921 - val_loss: 18.4387\n",
      "Epoch 36/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 18.1083 - val_loss: 18.1487\n",
      "Epoch 37/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 17.8348 - val_loss: 17.8804\n",
      "Epoch 38/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 17.5739 - val_loss: 17.6186\n",
      "Epoch 39/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 17.3237 - val_loss: 17.3688\n",
      "Epoch 40/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 17.0809 - val_loss: 17.1275\n",
      "Epoch 41/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 16.8508 - val_loss: 16.8952\n",
      "Epoch 42/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 16.6269 - val_loss: 16.6793\n",
      "Epoch 43/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 16.4124 - val_loss: 16.4627\n",
      "Epoch 44/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 16.2071 - val_loss: 16.2533\n",
      "Epoch 45/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 16.0062 - val_loss: 16.0567\n",
      "Epoch 46/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 15.8164 - val_loss: 15.8678\n",
      "Epoch 47/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 15.6306 - val_loss: 15.6791\n",
      "Epoch 48/3000\n",
      "4686/4686 [==============================] - 0s 46us/sample - loss: 15.4524 - val_loss: 15.5092\n",
      "Epoch 49/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 15.2808 - val_loss: 15.3306\n",
      "Epoch 50/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 15.1136 - val_loss: 15.1648\n",
      "Epoch 51/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 14.9505 - val_loss: 15.0015\n",
      "Epoch 52/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 14.7958 - val_loss: 14.8475\n",
      "Epoch 53/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 14.6456 - val_loss: 14.6963\n",
      "Epoch 54/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 14.4981 - val_loss: 14.5519\n",
      "Epoch 55/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 14.3568 - val_loss: 14.4119\n",
      "Epoch 56/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 14.2181 - val_loss: 14.2736\n",
      "Epoch 57/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 14.0858 - val_loss: 14.1385\n",
      "Epoch 58/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 13.9573 - val_loss: 14.0121\n",
      "Epoch 59/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 13.8308 - val_loss: 13.8832\n",
      "Epoch 60/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 13.7077 - val_loss: 13.7622\n",
      "Epoch 61/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 13.5899 - val_loss: 13.6439\n",
      "Epoch 62/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 13.4751 - val_loss: 13.5333\n",
      "Epoch 63/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 13.3631 - val_loss: 13.4156\n",
      "Epoch 64/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 13.2529 - val_loss: 13.3083\n",
      "Epoch 65/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 13.1488 - val_loss: 13.2022\n",
      "Epoch 66/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 13.0437 - val_loss: 13.0981\n",
      "Epoch 67/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 12.9440 - val_loss: 12.9978\n",
      "Epoch 68/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 12.8459 - val_loss: 12.9012\n",
      "Epoch 69/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 12.7498 - val_loss: 12.8022\n",
      "Epoch 70/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 12.6559 - val_loss: 12.7109\n",
      "Epoch 71/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 12.5649 - val_loss: 12.6204\n",
      "Epoch 72/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 12.4776 - val_loss: 12.5328\n",
      "Epoch 73/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 12.3895 - val_loss: 12.4417\n",
      "Epoch 74/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 12.3059 - val_loss: 12.3687\n",
      "Epoch 75/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 12.2216 - val_loss: 12.2766\n",
      "Epoch 76/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 44us/sample - loss: 12.1403 - val_loss: 12.1950\n",
      "Epoch 77/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 12.0611 - val_loss: 12.1127\n",
      "Epoch 78/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 11.9834 - val_loss: 12.0371\n",
      "Epoch 79/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 11.9064 - val_loss: 11.9595\n",
      "Epoch 80/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 11.8312 - val_loss: 11.8847\n",
      "Epoch 81/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 11.7586 - val_loss: 11.8106\n",
      "Epoch 82/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 11.6866 - val_loss: 11.7389\n",
      "Epoch 83/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 11.6166 - val_loss: 11.6747\n",
      "Epoch 84/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 11.5480 - val_loss: 11.6078\n",
      "Epoch 85/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 11.4815 - val_loss: 11.5341\n",
      "Epoch 86/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 11.4173 - val_loss: 11.4688\n",
      "Epoch 87/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 11.3533 - val_loss: 11.4092\n",
      "Epoch 88/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 11.2916 - val_loss: 11.3441\n",
      "Epoch 89/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 11.2311 - val_loss: 11.2918\n",
      "Epoch 90/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 11.1717 - val_loss: 11.2251\n",
      "Epoch 91/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 11.1149 - val_loss: 11.1696\n",
      "Epoch 92/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 11.0573 - val_loss: 11.1118\n",
      "Epoch 93/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 11.0026 - val_loss: 11.0582\n",
      "Epoch 94/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 10.9483 - val_loss: 11.0047\n",
      "Epoch 95/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 10.8956 - val_loss: 10.9515\n",
      "Epoch 96/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 10.8434 - val_loss: 10.9024\n",
      "Epoch 97/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 10.7926 - val_loss: 10.8456\n",
      "Epoch 98/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 10.7436 - val_loss: 10.8028\n",
      "Epoch 99/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 10.6943 - val_loss: 10.7490\n",
      "Epoch 100/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 10.6461 - val_loss: 10.7014\n",
      "Epoch 101/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 10.6006 - val_loss: 10.6556\n",
      "Epoch 102/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 10.5547 - val_loss: 10.6079\n",
      "Epoch 103/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 10.5092 - val_loss: 10.5689\n",
      "Epoch 104/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 10.4649 - val_loss: 10.5175\n",
      "Epoch 105/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 10.4217 - val_loss: 10.4792\n",
      "Epoch 106/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 10.3802 - val_loss: 10.4387\n",
      "Epoch 107/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 10.3379 - val_loss: 10.4020\n",
      "Epoch 108/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 10.2964 - val_loss: 10.3539\n",
      "Epoch 109/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 10.2568 - val_loss: 10.3108\n",
      "Epoch 110/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 10.2173 - val_loss: 10.2689\n",
      "Epoch 111/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 10.1788 - val_loss: 10.2380\n",
      "Epoch 112/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 10.1409 - val_loss: 10.1984\n",
      "Epoch 113/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 10.1034 - val_loss: 10.1593\n",
      "Epoch 114/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 10.0662 - val_loss: 10.1209\n",
      "Epoch 115/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 10.0308 - val_loss: 10.0848\n",
      "Epoch 116/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.9946 - val_loss: 10.0496\n",
      "Epoch 117/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.9610 - val_loss: 10.0169\n",
      "Epoch 118/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 9.9266 - val_loss: 9.9918\n",
      "Epoch 119/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 9.8923 - val_loss: 9.9423\n",
      "Epoch 120/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 9.8591 - val_loss: 9.9116\n",
      "Epoch 121/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.8264 - val_loss: 9.8827\n",
      "Epoch 122/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.7945 - val_loss: 9.8498\n",
      "Epoch 123/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.7637 - val_loss: 9.8127\n",
      "Epoch 124/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.7321 - val_loss: 9.7817\n",
      "Epoch 125/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.7020 - val_loss: 9.7731\n",
      "Epoch 126/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.6722 - val_loss: 9.7296\n",
      "Epoch 127/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.6428 - val_loss: 9.7170\n",
      "Epoch 128/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.6135 - val_loss: 9.6630\n",
      "Epoch 129/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 9.5848 - val_loss: 9.6325\n",
      "Epoch 130/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.5572 - val_loss: 9.6067\n",
      "Epoch 131/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 9.5295 - val_loss: 9.5785\n",
      "Epoch 132/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.5032 - val_loss: 9.5551\n",
      "Epoch 133/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.4755 - val_loss: 9.5233\n",
      "Epoch 134/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.4497 - val_loss: 9.4988\n",
      "Epoch 135/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.4233 - val_loss: 9.4780\n",
      "Epoch 136/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.3975 - val_loss: 9.4594\n",
      "Epoch 137/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 9.3727 - val_loss: 9.4275\n",
      "Epoch 138/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.3479 - val_loss: 9.3957\n",
      "Epoch 139/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.3242 - val_loss: 9.3717\n",
      "Epoch 140/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.3002 - val_loss: 9.3544\n",
      "Epoch 141/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.2758 - val_loss: 9.3230\n",
      "Epoch 142/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 9.2530 - val_loss: 9.2999\n",
      "Epoch 143/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 9.2296 - val_loss: 9.2779\n",
      "Epoch 144/3000\n",
      "4686/4686 [==============================] - 0s 46us/sample - loss: 9.2068 - val_loss: 9.2541\n",
      "Epoch 145/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.1843 - val_loss: 9.2323\n",
      "Epoch 146/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.1628 - val_loss: 9.2109\n",
      "Epoch 147/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 9.1410 - val_loss: 9.2043\n",
      "Epoch 148/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.1195 - val_loss: 9.1681\n",
      "Epoch 149/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.0990 - val_loss: 9.1462\n",
      "Epoch 150/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.0777 - val_loss: 9.1246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.0571 - val_loss: 9.1255\n",
      "Epoch 152/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.0375 - val_loss: 9.0904\n",
      "Epoch 153/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 9.0176 - val_loss: 9.0661\n",
      "Epoch 154/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.9973 - val_loss: 9.0510\n",
      "Epoch 155/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 8.9787 - val_loss: 9.0292\n",
      "Epoch 156/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.9598 - val_loss: 9.0058\n",
      "Epoch 157/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.9405 - val_loss: 8.9887\n",
      "Epoch 158/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.9222 - val_loss: 8.9679\n",
      "Epoch 159/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.9032 - val_loss: 8.9537\n",
      "Epoch 160/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 8.8857 - val_loss: 8.9428\n",
      "Epoch 161/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.8678 - val_loss: 8.9167\n",
      "Epoch 162/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.8500 - val_loss: 8.8960\n",
      "Epoch 163/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.8327 - val_loss: 8.8801\n",
      "Epoch 164/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.8159 - val_loss: 8.8632\n",
      "Epoch 165/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.7986 - val_loss: 8.8487\n",
      "Epoch 166/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.7820 - val_loss: 8.8277\n",
      "Epoch 167/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.7651 - val_loss: 8.8168\n",
      "Epoch 168/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.7491 - val_loss: 8.8047\n",
      "Epoch 169/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.7332 - val_loss: 8.7910\n",
      "Epoch 170/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.7171 - val_loss: 8.7642\n",
      "Epoch 171/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.7017 - val_loss: 8.7469\n",
      "Epoch 172/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.6859 - val_loss: 8.7342\n",
      "Epoch 173/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.6708 - val_loss: 8.7177\n",
      "Epoch 174/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.6556 - val_loss: 8.7052\n",
      "Epoch 175/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.6406 - val_loss: 8.6868\n",
      "Epoch 176/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.6263 - val_loss: 8.6766\n",
      "Epoch 177/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.6111 - val_loss: 8.6801\n",
      "Epoch 178/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.5975 - val_loss: 8.6497\n",
      "Epoch 179/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.5836 - val_loss: 8.6314\n",
      "Epoch 180/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.5691 - val_loss: 8.6201\n",
      "Epoch 181/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 8.5558 - val_loss: 8.6140\n",
      "Epoch 182/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.5420 - val_loss: 8.5875\n",
      "Epoch 183/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.5280 - val_loss: 8.5744\n",
      "Epoch 184/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.5151 - val_loss: 8.5611\n",
      "Epoch 185/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.5013 - val_loss: 8.5502\n",
      "Epoch 186/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.4888 - val_loss: 8.5347\n",
      "Epoch 187/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 8.4758 - val_loss: 8.5220\n",
      "Epoch 188/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.4633 - val_loss: 8.5122\n",
      "Epoch 189/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.4504 - val_loss: 8.4974\n",
      "Epoch 190/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.4381 - val_loss: 8.4918\n",
      "Epoch 191/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.4263 - val_loss: 8.4712\n",
      "Epoch 192/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.4137 - val_loss: 8.4589\n",
      "Epoch 193/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.4015 - val_loss: 8.4472\n",
      "Epoch 194/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.3896 - val_loss: 8.4355\n",
      "Epoch 195/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.3777 - val_loss: 8.4305\n",
      "Epoch 196/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.3663 - val_loss: 8.4236\n",
      "Epoch 197/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.3547 - val_loss: 8.4027\n",
      "Epoch 198/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.3430 - val_loss: 8.3954\n",
      "Epoch 199/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.3323 - val_loss: 8.3808\n",
      "Epoch 200/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.3211 - val_loss: 8.3678\n",
      "Epoch 201/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.3106 - val_loss: 8.3562\n",
      "Epoch 202/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.2996 - val_loss: 8.3457\n",
      "Epoch 203/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.2887 - val_loss: 8.3347\n",
      "Epoch 204/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.2783 - val_loss: 8.3314\n",
      "Epoch 205/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.2679 - val_loss: 8.3156\n",
      "Epoch 206/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.2571 - val_loss: 8.3021\n",
      "Epoch 207/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.2469 - val_loss: 8.2936\n",
      "Epoch 208/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.2371 - val_loss: 8.2901\n",
      "Epoch 209/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.2266 - val_loss: 8.2744\n",
      "Epoch 210/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.2169 - val_loss: 8.2618\n",
      "Epoch 211/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 8.2067 - val_loss: 8.2917\n",
      "Epoch 212/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.1974 - val_loss: 8.2630\n",
      "Epoch 213/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.1882 - val_loss: 8.2384\n",
      "Epoch 214/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.1777 - val_loss: 8.2251\n",
      "Epoch 215/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.1685 - val_loss: 8.2225\n",
      "Epoch 216/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.1592 - val_loss: 8.2105\n",
      "Epoch 217/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.1498 - val_loss: 8.1989\n",
      "Epoch 218/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.1410 - val_loss: 8.1869\n",
      "Epoch 219/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.1320 - val_loss: 8.1775\n",
      "Epoch 220/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.1230 - val_loss: 8.1704\n",
      "Epoch 221/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.1142 - val_loss: 8.1609\n",
      "Epoch 222/3000\n",
      "4686/4686 [==============================] - 0s 46us/sample - loss: 8.1051 - val_loss: 8.1509\n",
      "Epoch 223/3000\n",
      "4686/4686 [==============================] - 0s 48us/sample - loss: 8.0962 - val_loss: 8.1422\n",
      "Epoch 224/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.0879 - val_loss: 8.1380\n",
      "Epoch 225/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.0796 - val_loss: 8.1257\n",
      "Epoch 226/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.0713 - val_loss: 8.1227\n",
      "Epoch 227/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.0629 - val_loss: 8.1099\n",
      "Epoch 228/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.0545 - val_loss: 8.1006\n",
      "Epoch 229/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.0460 - val_loss: 8.1126\n",
      "Epoch 230/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.0381 - val_loss: 8.0899\n",
      "Epoch 231/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.0300 - val_loss: 8.0776\n",
      "Epoch 232/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.0220 - val_loss: 8.0845\n",
      "Epoch 233/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 8.0139 - val_loss: 8.0642\n",
      "Epoch 234/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 8.0064 - val_loss: 8.0604\n",
      "Epoch 235/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.9988 - val_loss: 8.0573\n",
      "Epoch 236/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.9911 - val_loss: 8.0399\n",
      "Epoch 237/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.9834 - val_loss: 8.0292\n",
      "Epoch 238/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.9760 - val_loss: 8.0232\n",
      "Epoch 239/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.9682 - val_loss: 8.0133\n",
      "Epoch 240/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.9615 - val_loss: 8.0068\n",
      "Epoch 241/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.9540 - val_loss: 8.0033\n",
      "Epoch 242/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.9465 - val_loss: 7.9928\n",
      "Epoch 243/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.9396 - val_loss: 7.9858\n",
      "Epoch 244/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.9323 - val_loss: 7.9859\n",
      "Epoch 245/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.9254 - val_loss: 7.9810\n",
      "Epoch 246/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.9184 - val_loss: 7.9637\n",
      "Epoch 247/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.9113 - val_loss: 7.9571\n",
      "Epoch 248/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.9049 - val_loss: 7.9516\n",
      "Epoch 249/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.8981 - val_loss: 7.9459\n",
      "Epoch 250/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.8914 - val_loss: 7.9367\n",
      "Epoch 251/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.8845 - val_loss: 7.9309\n",
      "Epoch 252/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.8780 - val_loss: 7.9420\n",
      "Epoch 253/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.8714 - val_loss: 7.9194\n",
      "Epoch 254/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.8652 - val_loss: 7.9184\n",
      "Epoch 255/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.8585 - val_loss: 7.9052\n",
      "Epoch 256/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.8521 - val_loss: 7.9012\n",
      "Epoch 257/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.8463 - val_loss: 7.9012\n",
      "Epoch 258/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.8395 - val_loss: 7.8851\n",
      "Epoch 259/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.8336 - val_loss: 7.8801\n",
      "Epoch 260/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.8277 - val_loss: 7.8779\n",
      "Epoch 261/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.8213 - val_loss: 7.8694\n",
      "Epoch 262/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.8150 - val_loss: 7.8603\n",
      "Epoch 263/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.8092 - val_loss: 7.8549\n",
      "Epoch 264/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.8029 - val_loss: 7.8588\n",
      "Epoch 265/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.7976 - val_loss: 7.8427\n",
      "Epoch 266/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.7914 - val_loss: 7.8388\n",
      "Epoch 267/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.7860 - val_loss: 7.8391\n",
      "Epoch 268/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.7802 - val_loss: 7.8268\n",
      "Epoch 269/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.7746 - val_loss: 7.8269\n",
      "Epoch 270/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.7688 - val_loss: 7.8412\n",
      "Epoch 271/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.7632 - val_loss: 7.8109\n",
      "Epoch 272/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.7576 - val_loss: 7.8045\n",
      "Epoch 273/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.7523 - val_loss: 7.7987\n",
      "Epoch 274/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.7466 - val_loss: 7.7921\n",
      "Epoch 275/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.7414 - val_loss: 7.8043\n",
      "Epoch 276/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.7360 - val_loss: 7.7812\n",
      "Epoch 277/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.7307 - val_loss: 7.7759\n",
      "Epoch 278/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.7254 - val_loss: 7.7765\n",
      "Epoch 279/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.7203 - val_loss: 7.7695\n",
      "Epoch 280/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.7149 - val_loss: 7.7641\n",
      "Epoch 281/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.7099 - val_loss: 7.7549\n",
      "Epoch 282/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.7048 - val_loss: 7.7505\n",
      "Epoch 283/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.6998 - val_loss: 7.7455\n",
      "Epoch 284/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.6947 - val_loss: 7.7397\n",
      "Epoch 285/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.6895 - val_loss: 7.7388\n",
      "Epoch 286/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.6851 - val_loss: 7.7298\n",
      "Epoch 287/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.6801 - val_loss: 7.7300\n",
      "Epoch 288/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.6754 - val_loss: 7.7217\n",
      "Epoch 289/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.6703 - val_loss: 7.7172\n",
      "Epoch 290/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.6655 - val_loss: 7.7215\n",
      "Epoch 291/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.6607 - val_loss: 7.7065\n",
      "Epoch 292/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.6560 - val_loss: 7.7125\n",
      "Epoch 293/3000\n",
      "4686/4686 [==============================] - 0s 46us/sample - loss: 7.6519 - val_loss: 7.6966\n",
      "Epoch 294/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.6467 - val_loss: 7.6944\n",
      "Epoch 295/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.6421 - val_loss: 7.6893\n",
      "Epoch 296/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 7.6378 - val_loss: 7.6839\n",
      "Epoch 297/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.6333 - val_loss: 7.6905\n",
      "Epoch 298/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.6288 - val_loss: 7.6733\n",
      "Epoch 299/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.6244 - val_loss: 7.6700\n",
      "Epoch 300/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.6198 - val_loss: 7.6692\n",
      "Epoch 301/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.6152 - val_loss: 7.6620\n",
      "Epoch 302/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.6112 - val_loss: 7.6556\n",
      "Epoch 303/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 7.6066 - val_loss: 7.6538\n",
      "Epoch 304/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 7.6024 - val_loss: 7.6485\n",
      "Epoch 305/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.5983 - val_loss: 7.6508\n",
      "Epoch 306/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.5939 - val_loss: 7.6393\n",
      "Epoch 307/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.5900 - val_loss: 7.6401\n",
      "Epoch 308/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.5858 - val_loss: 7.6307\n",
      "Epoch 309/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 7.5814 - val_loss: 7.6282\n",
      "Epoch 310/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 7.5773 - val_loss: 7.6228\n",
      "Epoch 311/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.5738 - val_loss: 7.6184\n",
      "Epoch 312/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.5694 - val_loss: 7.6202\n",
      "Epoch 313/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.5652 - val_loss: 7.6127\n",
      "Epoch 314/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.5613 - val_loss: 7.6076\n",
      "Epoch 315/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.5572 - val_loss: 7.6028\n",
      "Epoch 316/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.5534 - val_loss: 7.5999\n",
      "Epoch 317/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.5496 - val_loss: 7.5952\n",
      "Epoch 318/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.5459 - val_loss: 7.5917\n",
      "Epoch 319/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.5418 - val_loss: 7.5878\n",
      "Epoch 320/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.5383 - val_loss: 7.5863\n",
      "Epoch 321/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.5342 - val_loss: 7.5790\n",
      "Epoch 322/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.5306 - val_loss: 7.5761\n",
      "Epoch 323/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.5266 - val_loss: 7.5788\n",
      "Epoch 324/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.5232 - val_loss: 7.5675\n",
      "Epoch 325/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.5195 - val_loss: 7.5865\n",
      "Epoch 326/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.5157 - val_loss: 7.5614\n",
      "Epoch 327/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.5121 - val_loss: 7.5630\n",
      "Epoch 328/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.5082 - val_loss: 7.5543\n",
      "Epoch 329/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.5050 - val_loss: 7.5493\n",
      "Epoch 330/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.5014 - val_loss: 7.5461\n",
      "Epoch 331/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4976 - val_loss: 7.5546\n",
      "Epoch 332/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4944 - val_loss: 7.5434\n",
      "Epoch 333/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4909 - val_loss: 7.5374\n",
      "Epoch 334/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4874 - val_loss: 7.5341\n",
      "Epoch 335/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4837 - val_loss: 7.5364\n",
      "Epoch 336/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4804 - val_loss: 7.5276\n",
      "Epoch 337/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4774 - val_loss: 7.5293\n",
      "Epoch 338/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4738 - val_loss: 7.5193\n",
      "Epoch 339/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.4703 - val_loss: 7.5161\n",
      "Epoch 340/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4670 - val_loss: 7.5197\n",
      "Epoch 341/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.4640 - val_loss: 7.5098\n",
      "Epoch 342/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4603 - val_loss: 7.5085\n",
      "Epoch 343/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4572 - val_loss: 7.5029\n",
      "Epoch 344/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 7.4540 - val_loss: 7.5018\n",
      "Epoch 345/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4510 - val_loss: 7.4955\n",
      "Epoch 346/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4477 - val_loss: 7.4932\n",
      "Epoch 347/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4445 - val_loss: 7.4934\n",
      "Epoch 348/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4414 - val_loss: 7.4898\n",
      "Epoch 349/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4380 - val_loss: 7.4884\n",
      "Epoch 350/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4350 - val_loss: 7.4797\n",
      "Epoch 351/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.4318 - val_loss: 7.4763\n",
      "Epoch 352/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4286 - val_loss: 7.4733\n",
      "Epoch 353/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.4259 - val_loss: 7.4703\n",
      "Epoch 354/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4229 - val_loss: 7.4694\n",
      "Epoch 355/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4200 - val_loss: 7.4640\n",
      "Epoch 356/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4169 - val_loss: 7.4701\n",
      "Epoch 357/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4137 - val_loss: 7.4600\n",
      "Epoch 358/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4109 - val_loss: 7.4581\n",
      "Epoch 359/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4076 - val_loss: 7.4599\n",
      "Epoch 360/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4050 - val_loss: 7.4492\n",
      "Epoch 361/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.4021 - val_loss: 7.4476\n",
      "Epoch 362/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3994 - val_loss: 7.4472\n",
      "Epoch 363/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.3963 - val_loss: 7.4447\n",
      "Epoch 364/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3935 - val_loss: 7.4424\n",
      "Epoch 365/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3908 - val_loss: 7.4492\n",
      "Epoch 366/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3878 - val_loss: 7.4378\n",
      "Epoch 367/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3852 - val_loss: 7.4318\n",
      "Epoch 368/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3825 - val_loss: 7.4300\n",
      "Epoch 369/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3794 - val_loss: 7.4250\n",
      "Epoch 370/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3767 - val_loss: 7.4253\n",
      "Epoch 371/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3743 - val_loss: 7.4188\n",
      "Epoch 372/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3712 - val_loss: 7.4201\n",
      "Epoch 373/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3687 - val_loss: 7.4149\n",
      "Epoch 374/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3659 - val_loss: 7.4105\n",
      "Epoch 375/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3631 - val_loss: 7.4181\n",
      "Epoch 376/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3604 - val_loss: 7.4159\n",
      "Epoch 377/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3580 - val_loss: 7.4025\n",
      "Epoch 378/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3553 - val_loss: 7.4042\n",
      "Epoch 379/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3527 - val_loss: 7.3979\n",
      "Epoch 380/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.3501 - val_loss: 7.3952\n",
      "Epoch 381/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3473 - val_loss: 7.3924\n",
      "Epoch 382/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3450 - val_loss: 7.3891\n",
      "Epoch 383/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3424 - val_loss: 7.3961\n",
      "Epoch 384/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3399 - val_loss: 7.3864\n",
      "Epoch 385/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3373 - val_loss: 7.3826\n",
      "Epoch 386/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3349 - val_loss: 7.3789\n",
      "Epoch 387/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3324 - val_loss: 7.3784\n",
      "Epoch 388/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.3297 - val_loss: 7.3762\n",
      "Epoch 389/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3273 - val_loss: 7.3730\n",
      "Epoch 390/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3250 - val_loss: 7.3802\n",
      "Epoch 391/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3226 - val_loss: 7.3668\n",
      "Epoch 392/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3200 - val_loss: 7.3650\n",
      "Epoch 393/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3176 - val_loss: 7.3697\n",
      "Epoch 394/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3154 - val_loss: 7.3593\n",
      "Epoch 395/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3128 - val_loss: 7.3613\n",
      "Epoch 396/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3105 - val_loss: 7.3588\n",
      "Epoch 397/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3081 - val_loss: 7.3701\n",
      "Epoch 398/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3057 - val_loss: 7.3501\n",
      "Epoch 399/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.3033 - val_loss: 7.3477\n",
      "Epoch 400/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.3011 - val_loss: 7.3460\n",
      "Epoch 401/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2990 - val_loss: 7.3429\n",
      "Epoch 402/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2966 - val_loss: 7.3423\n",
      "Epoch 403/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.2942 - val_loss: 7.3387\n",
      "Epoch 404/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2920 - val_loss: 7.3359\n",
      "Epoch 405/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2898 - val_loss: 7.3340\n",
      "Epoch 406/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2875 - val_loss: 7.3319\n",
      "Epoch 407/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2853 - val_loss: 7.3301\n",
      "Epoch 408/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2829 - val_loss: 7.3288\n",
      "Epoch 409/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.2808 - val_loss: 7.3271\n",
      "Epoch 410/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2786 - val_loss: 7.3226\n",
      "Epoch 411/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.2765 - val_loss: 7.3210\n",
      "Epoch 412/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2742 - val_loss: 7.3219\n",
      "Epoch 413/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2720 - val_loss: 7.3163\n",
      "Epoch 414/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2699 - val_loss: 7.3157\n",
      "Epoch 415/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2679 - val_loss: 7.3121\n",
      "Epoch 416/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2658 - val_loss: 7.3112\n",
      "Epoch 417/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2635 - val_loss: 7.3075\n",
      "Epoch 418/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2612 - val_loss: 7.3067\n",
      "Epoch 419/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2592 - val_loss: 7.3062\n",
      "Epoch 420/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.2571 - val_loss: 7.3071\n",
      "Epoch 421/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2551 - val_loss: 7.2990\n",
      "Epoch 422/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.2531 - val_loss: 7.2978\n",
      "Epoch 423/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2510 - val_loss: 7.2953\n",
      "Epoch 424/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2489 - val_loss: 7.2949\n",
      "Epoch 425/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2468 - val_loss: 7.2957\n",
      "Epoch 426/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2448 - val_loss: 7.2894\n",
      "Epoch 427/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.2428 - val_loss: 7.2919\n",
      "Epoch 428/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2409 - val_loss: 7.2870\n",
      "Epoch 429/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2388 - val_loss: 7.2871\n",
      "Epoch 430/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.2368 - val_loss: 7.2809\n",
      "Epoch 431/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2349 - val_loss: 7.2794\n",
      "Epoch 432/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2329 - val_loss: 7.2780\n",
      "Epoch 433/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2309 - val_loss: 7.2755\n",
      "Epoch 434/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2290 - val_loss: 7.2771\n",
      "Epoch 435/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2271 - val_loss: 7.2732\n",
      "Epoch 436/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2252 - val_loss: 7.2712\n",
      "Epoch 437/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2232 - val_loss: 7.2678\n",
      "Epoch 438/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2212 - val_loss: 7.2700\n",
      "Epoch 439/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2194 - val_loss: 7.2635\n",
      "Epoch 440/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2174 - val_loss: 7.2622\n",
      "Epoch 441/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2155 - val_loss: 7.2640\n",
      "Epoch 442/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.2136 - val_loss: 7.2598\n",
      "Epoch 443/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2116 - val_loss: 7.2592\n",
      "Epoch 444/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2098 - val_loss: 7.2566\n",
      "Epoch 445/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2079 - val_loss: 7.2534\n",
      "Epoch 446/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2061 - val_loss: 7.2498\n",
      "Epoch 447/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2040 - val_loss: 7.2515\n",
      "Epoch 448/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.2026 - val_loss: 7.2490\n",
      "Epoch 449/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.2006 - val_loss: 7.2441\n",
      "Epoch 450/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1986 - val_loss: 7.2431\n",
      "Epoch 451/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1970 - val_loss: 7.2425\n",
      "Epoch 452/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1952 - val_loss: 7.2444\n",
      "Epoch 453/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1937 - val_loss: 7.2382\n",
      "Epoch 454/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1917 - val_loss: 7.2430\n",
      "Epoch 455/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1900 - val_loss: 7.2331\n",
      "Epoch 456/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1879 - val_loss: 7.2345\n",
      "Epoch 457/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1861 - val_loss: 7.2371\n",
      "Epoch 458/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1848 - val_loss: 7.2283\n",
      "Epoch 459/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1829 - val_loss: 7.2262\n",
      "Epoch 460/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1810 - val_loss: 7.2265\n",
      "Epoch 461/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1794 - val_loss: 7.2298\n",
      "Epoch 462/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.1776 - val_loss: 7.2229\n",
      "Epoch 463/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1760 - val_loss: 7.2195\n",
      "Epoch 464/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1741 - val_loss: 7.2221\n",
      "Epoch 465/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1726 - val_loss: 7.2180\n",
      "Epoch 466/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1707 - val_loss: 7.2163\n",
      "Epoch 467/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1695 - val_loss: 7.2125\n",
      "Epoch 468/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1673 - val_loss: 7.2107\n",
      "Epoch 469/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1657 - val_loss: 7.2144\n",
      "Epoch 470/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1641 - val_loss: 7.2094\n",
      "Epoch 471/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1622 - val_loss: 7.2070\n",
      "Epoch 472/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1608 - val_loss: 7.2076\n",
      "Epoch 473/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1591 - val_loss: 7.2034\n",
      "Epoch 474/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.1574 - val_loss: 7.2042\n",
      "Epoch 475/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1559 - val_loss: 7.2005\n",
      "Epoch 476/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.1540 - val_loss: 7.2013\n",
      "Epoch 477/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1527 - val_loss: 7.1972\n",
      "Epoch 478/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1510 - val_loss: 7.1999\n",
      "Epoch 479/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1493 - val_loss: 7.1938\n",
      "Epoch 480/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1479 - val_loss: 7.1907\n",
      "Epoch 481/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1463 - val_loss: 7.1906\n",
      "Epoch 482/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1448 - val_loss: 7.1880\n",
      "Epoch 483/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.1429 - val_loss: 7.1939\n",
      "Epoch 484/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1414 - val_loss: 7.1860\n",
      "Epoch 485/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1400 - val_loss: 7.1856\n",
      "Epoch 486/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1383 - val_loss: 7.1835\n",
      "Epoch 487/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1369 - val_loss: 7.1796\n",
      "Epoch 488/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1353 - val_loss: 7.1784\n",
      "Epoch 489/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1336 - val_loss: 7.1803\n",
      "Epoch 490/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1321 - val_loss: 7.1761\n",
      "Epoch 491/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1305 - val_loss: 7.1743\n",
      "Epoch 492/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1291 - val_loss: 7.1759\n",
      "Epoch 493/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1276 - val_loss: 7.1709\n",
      "Epoch 494/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1258 - val_loss: 7.1751\n",
      "Epoch 495/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1245 - val_loss: 7.1690\n",
      "Epoch 496/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1231 - val_loss: 7.1721\n",
      "Epoch 497/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1214 - val_loss: 7.1649\n",
      "Epoch 498/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1201 - val_loss: 7.1682\n",
      "Epoch 499/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1185 - val_loss: 7.1616\n",
      "Epoch 500/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1170 - val_loss: 7.1606\n",
      "Epoch 501/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1157 - val_loss: 7.1606\n",
      "Epoch 502/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1142 - val_loss: 7.1599\n",
      "Epoch 503/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1125 - val_loss: 7.1555\n",
      "Epoch 504/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1112 - val_loss: 7.1594\n",
      "Epoch 505/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1096 - val_loss: 7.1525\n",
      "Epoch 506/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1084 - val_loss: 7.1518\n",
      "Epoch 507/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1069 - val_loss: 7.1565\n",
      "Epoch 508/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1053 - val_loss: 7.1503\n",
      "Epoch 509/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.1042 - val_loss: 7.1498\n",
      "Epoch 510/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1026 - val_loss: 7.1454\n",
      "Epoch 511/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.1012 - val_loss: 7.1450\n",
      "Epoch 512/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0997 - val_loss: 7.1433\n",
      "Epoch 513/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0982 - val_loss: 7.1427\n",
      "Epoch 514/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.0968 - val_loss: 7.1416\n",
      "Epoch 515/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0956 - val_loss: 7.1439\n",
      "Epoch 516/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0941 - val_loss: 7.1391\n",
      "Epoch 517/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0927 - val_loss: 7.1355\n",
      "Epoch 518/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0915 - val_loss: 7.1377\n",
      "Epoch 519/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0900 - val_loss: 7.1337\n",
      "Epoch 520/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.0886 - val_loss: 7.1333\n",
      "Epoch 521/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0873 - val_loss: 7.1311\n",
      "Epoch 522/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0858 - val_loss: 7.1286\n",
      "Epoch 523/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0846 - val_loss: 7.1288\n",
      "Epoch 524/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.0831 - val_loss: 7.1278\n",
      "Epoch 525/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0819 - val_loss: 7.1278\n",
      "Epoch 526/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0806 - val_loss: 7.1254\n",
      "Epoch 527/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0791 - val_loss: 7.1217\n",
      "Epoch 528/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0777 - val_loss: 7.1221\n",
      "Epoch 529/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0764 - val_loss: 7.1214\n",
      "Epoch 530/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0752 - val_loss: 7.1183\n",
      "Epoch 531/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0739 - val_loss: 7.1188\n",
      "Epoch 532/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0723 - val_loss: 7.1161\n",
      "Epoch 533/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.0710 - val_loss: 7.1181\n",
      "Epoch 534/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0699 - val_loss: 7.1119\n",
      "Epoch 535/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0685 - val_loss: 7.1133\n",
      "Epoch 536/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0672 - val_loss: 7.1111\n",
      "Epoch 537/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0661 - val_loss: 7.1100\n",
      "Epoch 538/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0647 - val_loss: 7.1073\n",
      "Epoch 539/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0636 - val_loss: 7.1094\n",
      "Epoch 540/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0622 - val_loss: 7.1042\n",
      "Epoch 541/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0610 - val_loss: 7.1046\n",
      "Epoch 542/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0596 - val_loss: 7.1041\n",
      "Epoch 543/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0584 - val_loss: 7.1013\n",
      "Epoch 544/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0572 - val_loss: 7.1065\n",
      "Epoch 545/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.0559 - val_loss: 7.0976\n",
      "Epoch 546/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0545 - val_loss: 7.0981\n",
      "Epoch 547/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0533 - val_loss: 7.0991\n",
      "Epoch 548/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0521 - val_loss: 7.0940\n",
      "Epoch 549/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0508 - val_loss: 7.0940\n",
      "Epoch 550/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0495 - val_loss: 7.0935\n",
      "Epoch 551/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0483 - val_loss: 7.0964\n",
      "Epoch 552/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.0471 - val_loss: 7.0966\n",
      "Epoch 553/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0458 - val_loss: 7.0874\n",
      "Epoch 554/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.0447 - val_loss: 7.0872\n",
      "Epoch 555/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0434 - val_loss: 7.0873\n",
      "Epoch 556/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0421 - val_loss: 7.0861\n",
      "Epoch 557/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0408 - val_loss: 7.0830\n",
      "Epoch 558/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0399 - val_loss: 7.0851\n",
      "Epoch 559/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0389 - val_loss: 7.0819\n",
      "Epoch 560/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0373 - val_loss: 7.0796\n",
      "Epoch 561/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.0363 - val_loss: 7.0803\n",
      "Epoch 562/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0349 - val_loss: 7.0772\n",
      "Epoch 563/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0338 - val_loss: 7.0768\n",
      "Epoch 564/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0327 - val_loss: 7.0742\n",
      "Epoch 565/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0315 - val_loss: 7.0731\n",
      "Epoch 566/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.0303 - val_loss: 7.0754\n",
      "Epoch 567/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0290 - val_loss: 7.0737\n",
      "Epoch 568/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0279 - val_loss: 7.0740\n",
      "Epoch 569/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.0269 - val_loss: 7.0686\n",
      "Epoch 570/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0256 - val_loss: 7.0726\n",
      "Epoch 571/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0244 - val_loss: 7.0698\n",
      "Epoch 572/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0235 - val_loss: 7.0682\n",
      "Epoch 573/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0223 - val_loss: 7.0640\n",
      "Epoch 574/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0210 - val_loss: 7.0629\n",
      "Epoch 575/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 7.0197 - val_loss: 7.0660\n",
      "Epoch 576/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0186 - val_loss: 7.0602\n",
      "Epoch 577/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0177 - val_loss: 7.0599\n",
      "Epoch 578/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0164 - val_loss: 7.0596\n",
      "Epoch 579/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.0155 - val_loss: 7.0570\n",
      "Epoch 580/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0142 - val_loss: 7.0583\n",
      "Epoch 581/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0131 - val_loss: 7.0554\n",
      "Epoch 582/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0120 - val_loss: 7.0541\n",
      "Epoch 583/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0107 - val_loss: 7.0544\n",
      "Epoch 584/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.0096 - val_loss: 7.0519\n",
      "Epoch 585/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0085 - val_loss: 7.0556\n",
      "Epoch 586/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0076 - val_loss: 7.0529\n",
      "Epoch 587/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0063 - val_loss: 7.0504\n",
      "Epoch 588/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0053 - val_loss: 7.0488\n",
      "Epoch 589/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0044 - val_loss: 7.0457\n",
      "Epoch 590/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0030 - val_loss: 7.0456\n",
      "Epoch 591/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 7.0022 - val_loss: 7.0452\n",
      "Epoch 592/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 7.0011 - val_loss: 7.0433\n",
      "Epoch 593/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.9999 - val_loss: 7.0451\n",
      "Epoch 594/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9988 - val_loss: 7.0417\n",
      "Epoch 595/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9977 - val_loss: 7.0431\n",
      "Epoch 596/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9967 - val_loss: 7.0406\n",
      "Epoch 597/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.9955 - val_loss: 7.0415\n",
      "Epoch 598/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9944 - val_loss: 7.0390\n",
      "Epoch 599/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9936 - val_loss: 7.0352\n",
      "Epoch 600/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9925 - val_loss: 7.0372\n",
      "Epoch 601/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9913 - val_loss: 7.0347\n",
      "Epoch 602/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9902 - val_loss: 7.0378\n",
      "Epoch 603/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.9893 - val_loss: 7.0351\n",
      "Epoch 604/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9882 - val_loss: 7.0292\n",
      "Epoch 605/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9872 - val_loss: 7.0300\n",
      "Epoch 606/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9860 - val_loss: 7.0291\n",
      "Epoch 607/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9850 - val_loss: 7.0283\n",
      "Epoch 608/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9839 - val_loss: 7.0251\n",
      "Epoch 609/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.9831 - val_loss: 7.0259\n",
      "Epoch 610/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9819 - val_loss: 7.0237\n",
      "Epoch 611/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9809 - val_loss: 7.0257\n",
      "Epoch 612/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.9799 - val_loss: 7.0260\n",
      "Epoch 613/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9790 - val_loss: 7.0247\n",
      "Epoch 614/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9779 - val_loss: 7.0199\n",
      "Epoch 615/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9769 - val_loss: 7.0190\n",
      "Epoch 616/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9760 - val_loss: 7.0171\n",
      "Epoch 617/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9747 - val_loss: 7.0160\n",
      "Epoch 618/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9738 - val_loss: 7.0174\n",
      "Epoch 619/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.9728 - val_loss: 7.0135\n",
      "Epoch 620/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9717 - val_loss: 7.0135\n",
      "Epoch 621/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9708 - val_loss: 7.0117\n",
      "Epoch 622/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9698 - val_loss: 7.0111\n",
      "Epoch 623/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9688 - val_loss: 7.0156\n",
      "Epoch 624/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9677 - val_loss: 7.0132\n",
      "Epoch 625/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9668 - val_loss: 7.0072\n",
      "Epoch 626/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9658 - val_loss: 7.0076\n",
      "Epoch 627/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9648 - val_loss: 7.0093\n",
      "Epoch 628/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.9638 - val_loss: 7.0046\n",
      "Epoch 629/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9631 - val_loss: 7.0057\n",
      "Epoch 630/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9620 - val_loss: 7.0036\n",
      "Epoch 631/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9609 - val_loss: 7.0014\n",
      "Epoch 632/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9600 - val_loss: 7.0033\n",
      "Epoch 633/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9590 - val_loss: 7.0002\n",
      "Epoch 634/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9582 - val_loss: 7.0000\n",
      "Epoch 635/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9570 - val_loss: 6.9981\n",
      "Epoch 636/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9561 - val_loss: 6.9991\n",
      "Epoch 637/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9554 - val_loss: 6.9974\n",
      "Epoch 638/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9542 - val_loss: 6.9945\n",
      "Epoch 639/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9533 - val_loss: 6.9943\n",
      "Epoch 640/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9524 - val_loss: 6.9931\n",
      "Epoch 641/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9515 - val_loss: 6.9925\n",
      "Epoch 642/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9504 - val_loss: 6.9951\n",
      "Epoch 643/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9496 - val_loss: 6.9897\n",
      "Epoch 644/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9485 - val_loss: 6.9895\n",
      "Epoch 645/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.9476 - val_loss: 6.9906\n",
      "Epoch 646/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9468 - val_loss: 6.9908\n",
      "Epoch 647/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9458 - val_loss: 6.9890\n",
      "Epoch 648/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9449 - val_loss: 6.9882\n",
      "Epoch 649/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9438 - val_loss: 6.9856\n",
      "Epoch 650/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9430 - val_loss: 6.9832\n",
      "Epoch 651/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.9421 - val_loss: 6.9826\n",
      "Epoch 652/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9411 - val_loss: 6.9865\n",
      "Epoch 653/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9401 - val_loss: 6.9833\n",
      "Epoch 654/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9394 - val_loss: 6.9826\n",
      "Epoch 655/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9384 - val_loss: 6.9823\n",
      "Epoch 656/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9375 - val_loss: 6.9790\n",
      "Epoch 657/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9367 - val_loss: 6.9765\n",
      "Epoch 658/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9357 - val_loss: 6.9758\n",
      "Epoch 659/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9350 - val_loss: 6.9756\n",
      "Epoch 660/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9340 - val_loss: 6.9744\n",
      "Epoch 661/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9329 - val_loss: 6.9731\n",
      "Epoch 662/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9322 - val_loss: 6.9742\n",
      "Epoch 663/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9312 - val_loss: 6.9737\n",
      "Epoch 664/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9303 - val_loss: 6.9735\n",
      "Epoch 665/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9297 - val_loss: 6.9700\n",
      "Epoch 666/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9287 - val_loss: 6.9693\n",
      "Epoch 667/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9277 - val_loss: 6.9701\n",
      "Epoch 668/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9269 - val_loss: 6.9688\n",
      "Epoch 669/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.9260 - val_loss: 6.9663\n",
      "Epoch 670/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9250 - val_loss: 6.9664\n",
      "Epoch 671/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9242 - val_loss: 6.9671\n",
      "Epoch 672/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9234 - val_loss: 6.9695\n",
      "Epoch 673/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9224 - val_loss: 6.9647\n",
      "Epoch 674/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9216 - val_loss: 6.9643\n",
      "Epoch 675/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9207 - val_loss: 6.9605\n",
      "Epoch 676/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9199 - val_loss: 6.9645\n",
      "Epoch 677/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9191 - val_loss: 6.9590\n",
      "Epoch 678/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9181 - val_loss: 6.9587\n",
      "Epoch 679/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.9173 - val_loss: 6.9574\n",
      "Epoch 680/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9164 - val_loss: 6.9652\n",
      "Epoch 681/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.9156 - val_loss: 6.9557\n",
      "Epoch 682/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.9148 - val_loss: 6.9567\n",
      "Epoch 683/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9138 - val_loss: 6.9539\n",
      "Epoch 684/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9130 - val_loss: 6.9577\n",
      "Epoch 685/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9123 - val_loss: 6.9536\n",
      "Epoch 686/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9114 - val_loss: 6.9513\n",
      "Epoch 687/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9106 - val_loss: 6.9542\n",
      "Epoch 688/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9097 - val_loss: 6.9525\n",
      "Epoch 689/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9089 - val_loss: 6.9530\n",
      "Epoch 690/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9081 - val_loss: 6.9476\n",
      "Epoch 691/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9070 - val_loss: 6.9473\n",
      "Epoch 692/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9062 - val_loss: 6.9532\n",
      "Epoch 693/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.9055 - val_loss: 6.9456\n",
      "Epoch 694/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9046 - val_loss: 6.9454\n",
      "Epoch 695/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9040 - val_loss: 6.9455\n",
      "Epoch 696/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9030 - val_loss: 6.9431\n",
      "Epoch 697/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9022 - val_loss: 6.9446\n",
      "Epoch 698/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9012 - val_loss: 6.9412\n",
      "Epoch 699/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.9005 - val_loss: 6.9440\n",
      "Epoch 700/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8998 - val_loss: 6.9438\n",
      "Epoch 701/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8990 - val_loss: 6.9408\n",
      "Epoch 702/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8982 - val_loss: 6.9410\n",
      "Epoch 703/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8973 - val_loss: 6.9384\n",
      "Epoch 704/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8965 - val_loss: 6.9376\n",
      "Epoch 705/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8958 - val_loss: 6.9356\n",
      "Epoch 706/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.8950 - val_loss: 6.9347\n",
      "Epoch 707/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8942 - val_loss: 6.9340\n",
      "Epoch 708/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8934 - val_loss: 6.9328\n",
      "Epoch 709/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8925 - val_loss: 6.9344\n",
      "Epoch 710/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8916 - val_loss: 6.9322\n",
      "Epoch 711/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8910 - val_loss: 6.9320\n",
      "Epoch 712/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8902 - val_loss: 6.9349\n",
      "Epoch 713/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8893 - val_loss: 6.9297\n",
      "Epoch 714/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.8884 - val_loss: 6.9294\n",
      "Epoch 715/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8877 - val_loss: 6.9349\n",
      "Epoch 716/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8871 - val_loss: 6.9278\n",
      "Epoch 717/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8862 - val_loss: 6.9263\n",
      "Epoch 718/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8854 - val_loss: 6.9289\n",
      "Epoch 719/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8846 - val_loss: 6.9298\n",
      "Epoch 720/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8839 - val_loss: 6.9261\n",
      "Epoch 721/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8831 - val_loss: 6.9229\n",
      "Epoch 722/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8824 - val_loss: 6.9215\n",
      "Epoch 723/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8816 - val_loss: 6.9217\n",
      "Epoch 724/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8809 - val_loss: 6.9213\n",
      "Epoch 725/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8800 - val_loss: 6.9211\n",
      "Epoch 726/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8793 - val_loss: 6.9273\n",
      "Epoch 727/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8784 - val_loss: 6.9260\n",
      "Epoch 728/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8779 - val_loss: 6.9200\n",
      "Epoch 729/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8770 - val_loss: 6.9164\n",
      "Epoch 730/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8762 - val_loss: 6.9150\n",
      "Epoch 731/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8756 - val_loss: 6.9166\n",
      "Epoch 732/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8748 - val_loss: 6.9151\n",
      "Epoch 733/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8740 - val_loss: 6.9209\n",
      "Epoch 734/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8733 - val_loss: 6.9162\n",
      "Epoch 735/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8725 - val_loss: 6.9121\n",
      "Epoch 736/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8719 - val_loss: 6.9152\n",
      "Epoch 737/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8711 - val_loss: 6.9138\n",
      "Epoch 738/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8703 - val_loss: 6.9155\n",
      "Epoch 739/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8696 - val_loss: 6.9108\n",
      "Epoch 740/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8688 - val_loss: 6.9086\n",
      "Epoch 741/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8681 - val_loss: 6.9102\n",
      "Epoch 742/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8674 - val_loss: 6.9073\n",
      "Epoch 743/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8665 - val_loss: 6.9072\n",
      "Epoch 744/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8658 - val_loss: 6.9047\n",
      "Epoch 745/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8651 - val_loss: 6.9055\n",
      "Epoch 746/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8643 - val_loss: 6.9057\n",
      "Epoch 747/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.8637 - val_loss: 6.9027\n",
      "Epoch 748/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8629 - val_loss: 6.9032\n",
      "Epoch 749/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8620 - val_loss: 6.9028\n",
      "Epoch 750/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8614 - val_loss: 6.9031\n",
      "Epoch 751/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8607 - val_loss: 6.9027\n",
      "Epoch 752/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8600 - val_loss: 6.8990\n",
      "Epoch 753/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8591 - val_loss: 6.9035\n",
      "Epoch 754/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8588 - val_loss: 6.9033\n",
      "Epoch 755/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8579 - val_loss: 6.8969\n",
      "Epoch 756/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8572 - val_loss: 6.8966\n",
      "Epoch 757/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8565 - val_loss: 6.8969\n",
      "Epoch 758/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8557 - val_loss: 6.8945\n",
      "Epoch 759/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8549 - val_loss: 6.8965\n",
      "Epoch 760/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8543 - val_loss: 6.8969\n",
      "Epoch 761/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8535 - val_loss: 6.8957\n",
      "Epoch 762/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8529 - val_loss: 6.8932\n",
      "Epoch 763/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8523 - val_loss: 6.8907\n",
      "Epoch 764/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.8514 - val_loss: 6.8918\n",
      "Epoch 765/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8508 - val_loss: 6.8898\n",
      "Epoch 766/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8500 - val_loss: 6.8907\n",
      "Epoch 767/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.8493 - val_loss: 6.8926\n",
      "Epoch 768/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8487 - val_loss: 6.8892\n",
      "Epoch 769/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8482 - val_loss: 6.8891\n",
      "Epoch 770/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8473 - val_loss: 6.8891\n",
      "Epoch 771/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8466 - val_loss: 6.8855\n",
      "Epoch 772/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8460 - val_loss: 6.8876\n",
      "Epoch 773/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8453 - val_loss: 6.8848\n",
      "Epoch 774/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8444 - val_loss: 6.8837\n",
      "Epoch 775/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8440 - val_loss: 6.8848\n",
      "Epoch 776/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8431 - val_loss: 6.8847\n",
      "Epoch 777/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8425 - val_loss: 6.8808\n",
      "Epoch 778/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8419 - val_loss: 6.8800\n",
      "Epoch 779/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8411 - val_loss: 6.8855\n",
      "Epoch 780/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8404 - val_loss: 6.8814\n",
      "Epoch 781/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8398 - val_loss: 6.8785\n",
      "Epoch 782/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.8391 - val_loss: 6.8785\n",
      "Epoch 783/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.8384 - val_loss: 6.8815\n",
      "Epoch 784/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8379 - val_loss: 6.8765\n",
      "Epoch 785/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8370 - val_loss: 6.8786\n",
      "Epoch 786/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.8364 - val_loss: 6.8753\n",
      "Epoch 787/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8358 - val_loss: 6.8741\n",
      "Epoch 788/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8350 - val_loss: 6.8742\n",
      "Epoch 789/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.8343 - val_loss: 6.8732\n",
      "Epoch 790/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8338 - val_loss: 6.8727\n",
      "Epoch 791/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8332 - val_loss: 6.8715\n",
      "Epoch 792/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8325 - val_loss: 6.8712\n",
      "Epoch 793/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8319 - val_loss: 6.8706\n",
      "Epoch 794/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8312 - val_loss: 6.8721\n",
      "Epoch 795/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8304 - val_loss: 6.8699\n",
      "Epoch 796/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8298 - val_loss: 6.8685\n",
      "Epoch 797/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.8292 - val_loss: 6.8714\n",
      "Epoch 798/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.8285 - val_loss: 6.8712\n",
      "Epoch 799/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.8278 - val_loss: 6.8658\n",
      "Epoch 800/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8273 - val_loss: 6.8690\n",
      "Epoch 801/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8266 - val_loss: 6.8653\n",
      "Epoch 802/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8258 - val_loss: 6.8646\n",
      "Epoch 803/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8252 - val_loss: 6.8693\n",
      "Epoch 804/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.8245 - val_loss: 6.8648\n",
      "Epoch 805/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8240 - val_loss: 6.8638\n",
      "Epoch 806/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8234 - val_loss: 6.8649\n",
      "Epoch 807/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8227 - val_loss: 6.8609\n",
      "Epoch 808/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8221 - val_loss: 6.8628\n",
      "Epoch 809/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8215 - val_loss: 6.8604\n",
      "Epoch 810/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8209 - val_loss: 6.8597\n",
      "Epoch 811/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 6.8201 - val_loss: 6.8585\n",
      "Epoch 812/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.8196 - val_loss: 6.8585\n",
      "Epoch 813/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.8189 - val_loss: 6.8572\n",
      "Epoch 814/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8184 - val_loss: 6.8606\n",
      "Epoch 815/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8177 - val_loss: 6.8563\n",
      "Epoch 816/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8169 - val_loss: 6.8590\n",
      "Epoch 817/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8163 - val_loss: 6.8555\n",
      "Epoch 818/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 6.8156 - val_loss: 6.8541\n",
      "Epoch 819/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.8151 - val_loss: 6.8530\n",
      "Epoch 820/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.8145 - val_loss: 6.8524\n",
      "Epoch 821/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8138 - val_loss: 6.8554\n",
      "Epoch 822/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8132 - val_loss: 6.8562\n",
      "Epoch 823/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.8126 - val_loss: 6.8517\n",
      "Epoch 824/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8119 - val_loss: 6.8497\n",
      "Epoch 825/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.8114 - val_loss: 6.8516\n",
      "Epoch 826/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8107 - val_loss: 6.8492\n",
      "Epoch 827/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8102 - val_loss: 6.8506\n",
      "Epoch 828/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8095 - val_loss: 6.8472\n",
      "Epoch 829/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8089 - val_loss: 6.8472\n",
      "Epoch 830/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8083 - val_loss: 6.8466\n",
      "Epoch 831/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8079 - val_loss: 6.8454\n",
      "Epoch 832/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8072 - val_loss: 6.8494\n",
      "Epoch 833/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8064 - val_loss: 6.8469\n",
      "Epoch 834/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.8059 - val_loss: 6.8447\n",
      "Epoch 835/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8053 - val_loss: 6.8478\n",
      "Epoch 836/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8046 - val_loss: 6.8445\n",
      "Epoch 837/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8041 - val_loss: 6.8451\n",
      "Epoch 838/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8034 - val_loss: 6.8414\n",
      "Epoch 839/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8028 - val_loss: 6.8412\n",
      "Epoch 840/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.8022 - val_loss: 6.8408\n",
      "Epoch 841/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8017 - val_loss: 6.8393\n",
      "Epoch 842/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8010 - val_loss: 6.8450\n",
      "Epoch 843/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.8005 - val_loss: 6.8406\n",
      "Epoch 844/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7999 - val_loss: 6.8387\n",
      "Epoch 845/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7992 - val_loss: 6.8371\n",
      "Epoch 846/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7986 - val_loss: 6.8376\n",
      "Epoch 847/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7980 - val_loss: 6.8394\n",
      "Epoch 848/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7976 - val_loss: 6.8374\n",
      "Epoch 849/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7969 - val_loss: 6.8364\n",
      "Epoch 850/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7964 - val_loss: 6.8347\n",
      "Epoch 851/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7957 - val_loss: 6.8333\n",
      "Epoch 852/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7953 - val_loss: 6.8332\n",
      "Epoch 853/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7947 - val_loss: 6.8328\n",
      "Epoch 854/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7939 - val_loss: 6.8326\n",
      "Epoch 855/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7934 - val_loss: 6.8320\n",
      "Epoch 856/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7928 - val_loss: 6.8312\n",
      "Epoch 857/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7922 - val_loss: 6.8341\n",
      "Epoch 858/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7916 - val_loss: 6.8291\n",
      "Epoch 859/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7911 - val_loss: 6.8292\n",
      "Epoch 860/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7906 - val_loss: 6.8292\n",
      "Epoch 861/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7899 - val_loss: 6.8282\n",
      "Epoch 862/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7894 - val_loss: 6.8274\n",
      "Epoch 863/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7889 - val_loss: 6.8288\n",
      "Epoch 864/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7883 - val_loss: 6.8267\n",
      "Epoch 865/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7879 - val_loss: 6.8251\n",
      "Epoch 866/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7870 - val_loss: 6.8254\n",
      "Epoch 867/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7866 - val_loss: 6.8308\n",
      "Epoch 868/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7858 - val_loss: 6.8239\n",
      "Epoch 869/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7855 - val_loss: 6.8233\n",
      "Epoch 870/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7847 - val_loss: 6.8222\n",
      "Epoch 871/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7842 - val_loss: 6.8253\n",
      "Epoch 872/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7836 - val_loss: 6.8248\n",
      "Epoch 873/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7833 - val_loss: 6.8222\n",
      "Epoch 874/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7825 - val_loss: 6.8209\n",
      "Epoch 875/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7820 - val_loss: 6.8231\n",
      "Epoch 876/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7813 - val_loss: 6.8191\n",
      "Epoch 877/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.7808 - val_loss: 6.8184\n",
      "Epoch 878/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7804 - val_loss: 6.8212\n",
      "Epoch 879/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7798 - val_loss: 6.8174\n",
      "Epoch 880/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.7793 - val_loss: 6.8169\n",
      "Epoch 881/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7786 - val_loss: 6.8163\n",
      "Epoch 882/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7780 - val_loss: 6.8153\n",
      "Epoch 883/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7776 - val_loss: 6.8164\n",
      "Epoch 884/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7770 - val_loss: 6.8145\n",
      "Epoch 885/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7765 - val_loss: 6.8157\n",
      "Epoch 886/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7760 - val_loss: 6.8135\n",
      "Epoch 887/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7754 - val_loss: 6.8130\n",
      "Epoch 888/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7747 - val_loss: 6.8122\n",
      "Epoch 889/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7742 - val_loss: 6.8121\n",
      "Epoch 890/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7736 - val_loss: 6.8185\n",
      "Epoch 891/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7733 - val_loss: 6.8115\n",
      "Epoch 892/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7727 - val_loss: 6.8101\n",
      "Epoch 893/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7720 - val_loss: 6.8141\n",
      "Epoch 894/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.7716 - val_loss: 6.8098\n",
      "Epoch 895/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7710 - val_loss: 6.8096\n",
      "Epoch 896/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7704 - val_loss: 6.8079\n",
      "Epoch 897/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7700 - val_loss: 6.8070\n",
      "Epoch 898/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7693 - val_loss: 6.8078\n",
      "Epoch 899/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7688 - val_loss: 6.8069\n",
      "Epoch 900/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7683 - val_loss: 6.8068\n",
      "Epoch 901/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7679 - val_loss: 6.8073\n",
      "Epoch 902/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7672 - val_loss: 6.8049\n",
      "Epoch 903/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7668 - val_loss: 6.8044\n",
      "Epoch 904/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7662 - val_loss: 6.8066\n",
      "Epoch 905/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7658 - val_loss: 6.8056\n",
      "Epoch 906/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7651 - val_loss: 6.8039\n",
      "Epoch 907/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7646 - val_loss: 6.8051\n",
      "Epoch 908/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7641 - val_loss: 6.8085\n",
      "Epoch 909/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7635 - val_loss: 6.8004\n",
      "Epoch 910/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7631 - val_loss: 6.8009\n",
      "Epoch 911/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7625 - val_loss: 6.8000\n",
      "Epoch 912/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.7620 - val_loss: 6.8001\n",
      "Epoch 913/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7615 - val_loss: 6.8072\n",
      "Epoch 914/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7609 - val_loss: 6.8035\n",
      "Epoch 915/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7605 - val_loss: 6.7972\n",
      "Epoch 916/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7599 - val_loss: 6.7978\n",
      "Epoch 917/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7593 - val_loss: 6.7966\n",
      "Epoch 918/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7588 - val_loss: 6.7965\n",
      "Epoch 919/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7583 - val_loss: 6.7960\n",
      "Epoch 920/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7579 - val_loss: 6.7958\n",
      "Epoch 921/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7574 - val_loss: 6.7972\n",
      "Epoch 922/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7568 - val_loss: 6.7958\n",
      "Epoch 923/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7563 - val_loss: 6.7931\n",
      "Epoch 924/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7557 - val_loss: 6.7949\n",
      "Epoch 925/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7553 - val_loss: 6.7924\n",
      "Epoch 926/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7548 - val_loss: 6.7934\n",
      "Epoch 927/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7542 - val_loss: 6.7909\n",
      "Epoch 928/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7538 - val_loss: 6.7926\n",
      "Epoch 929/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7531 - val_loss: 6.7942\n",
      "Epoch 930/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7528 - val_loss: 6.7896\n",
      "Epoch 931/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7522 - val_loss: 6.7893\n",
      "Epoch 932/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7518 - val_loss: 6.7944\n",
      "Epoch 933/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7512 - val_loss: 6.7898\n",
      "Epoch 934/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7506 - val_loss: 6.7885\n",
      "Epoch 935/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7502 - val_loss: 6.7869\n",
      "Epoch 936/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7497 - val_loss: 6.7866\n",
      "Epoch 937/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7491 - val_loss: 6.7866\n",
      "Epoch 938/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7486 - val_loss: 6.7854\n",
      "Epoch 939/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7481 - val_loss: 6.7844\n",
      "Epoch 940/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7477 - val_loss: 6.7855\n",
      "Epoch 941/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7473 - val_loss: 6.7859\n",
      "Epoch 942/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7467 - val_loss: 6.7845\n",
      "Epoch 943/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7462 - val_loss: 6.7838\n",
      "Epoch 944/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7457 - val_loss: 6.7848\n",
      "Epoch 945/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7452 - val_loss: 6.7844\n",
      "Epoch 946/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7447 - val_loss: 6.7819\n",
      "Epoch 947/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7442 - val_loss: 6.7854\n",
      "Epoch 948/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7437 - val_loss: 6.7822\n",
      "Epoch 949/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7433 - val_loss: 6.7804\n",
      "Epoch 950/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7426 - val_loss: 6.7800\n",
      "Epoch 951/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7424 - val_loss: 6.7809\n",
      "Epoch 952/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7419 - val_loss: 6.7792\n",
      "Epoch 953/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7413 - val_loss: 6.7792\n",
      "Epoch 954/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7408 - val_loss: 6.7777\n",
      "Epoch 955/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7403 - val_loss: 6.7808\n",
      "Epoch 956/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7398 - val_loss: 6.7772\n",
      "Epoch 957/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7394 - val_loss: 6.7777\n",
      "Epoch 958/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7389 - val_loss: 6.7754\n",
      "Epoch 959/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7384 - val_loss: 6.7773\n",
      "Epoch 960/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7379 - val_loss: 6.7742\n",
      "Epoch 961/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7374 - val_loss: 6.7766\n",
      "Epoch 962/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7369 - val_loss: 6.7760\n",
      "Epoch 963/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7365 - val_loss: 6.7748\n",
      "Epoch 964/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7360 - val_loss: 6.7757\n",
      "Epoch 965/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7355 - val_loss: 6.7736\n",
      "Epoch 966/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7350 - val_loss: 6.7725\n",
      "Epoch 967/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7346 - val_loss: 6.7740\n",
      "Epoch 968/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7342 - val_loss: 6.7739\n",
      "Epoch 969/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7337 - val_loss: 6.7700\n",
      "Epoch 970/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7332 - val_loss: 6.7717\n",
      "Epoch 971/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7327 - val_loss: 6.7718\n",
      "Epoch 972/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7322 - val_loss: 6.7685\n",
      "Epoch 973/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7316 - val_loss: 6.7731\n",
      "Epoch 974/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7312 - val_loss: 6.7706\n",
      "Epoch 975/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7308 - val_loss: 6.7667\n",
      "Epoch 976/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7303 - val_loss: 6.7665\n",
      "Epoch 977/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7299 - val_loss: 6.7660\n",
      "Epoch 978/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7293 - val_loss: 6.7692\n",
      "Epoch 979/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7289 - val_loss: 6.7649\n",
      "Epoch 980/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7285 - val_loss: 6.7674\n",
      "Epoch 981/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7280 - val_loss: 6.7644\n",
      "Epoch 982/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7276 - val_loss: 6.7647\n",
      "Epoch 983/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7274 - val_loss: 6.7638\n",
      "Epoch 984/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7265 - val_loss: 6.7674\n",
      "Epoch 985/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7262 - val_loss: 6.7647\n",
      "Epoch 986/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7256 - val_loss: 6.7630\n",
      "Epoch 987/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7253 - val_loss: 6.7670\n",
      "Epoch 988/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7249 - val_loss: 6.7627\n",
      "Epoch 989/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7243 - val_loss: 6.7602\n",
      "Epoch 990/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7239 - val_loss: 6.7620\n",
      "Epoch 991/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7235 - val_loss: 6.7593\n",
      "Epoch 992/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7229 - val_loss: 6.7602\n",
      "Epoch 993/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7225 - val_loss: 6.7591\n",
      "Epoch 994/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7220 - val_loss: 6.7608\n",
      "Epoch 995/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7215 - val_loss: 6.7577\n",
      "Epoch 996/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7212 - val_loss: 6.7579\n",
      "Epoch 997/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7207 - val_loss: 6.7577\n",
      "Epoch 998/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7203 - val_loss: 6.7587\n",
      "Epoch 999/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7198 - val_loss: 6.7580\n",
      "Epoch 1000/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7194 - val_loss: 6.7558\n",
      "Epoch 1001/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7188 - val_loss: 6.7555\n",
      "Epoch 1002/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7184 - val_loss: 6.7569\n",
      "Epoch 1003/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7180 - val_loss: 6.7575\n",
      "Epoch 1004/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7175 - val_loss: 6.7549\n",
      "Epoch 1005/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7171 - val_loss: 6.7543\n",
      "Epoch 1006/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7167 - val_loss: 6.7528\n",
      "Epoch 1007/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7162 - val_loss: 6.7521\n",
      "Epoch 1008/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7157 - val_loss: 6.7519\n",
      "Epoch 1009/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7154 - val_loss: 6.7511\n",
      "Epoch 1010/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7149 - val_loss: 6.7528\n",
      "Epoch 1011/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7144 - val_loss: 6.7536\n",
      "Epoch 1012/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7140 - val_loss: 6.7509\n",
      "Epoch 1013/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7135 - val_loss: 6.7517\n",
      "Epoch 1014/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7132 - val_loss: 6.7489\n",
      "Epoch 1015/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7126 - val_loss: 6.7504\n",
      "Epoch 1016/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.7121 - val_loss: 6.7491\n",
      "Epoch 1017/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7117 - val_loss: 6.7521\n",
      "Epoch 1018/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7114 - val_loss: 6.7481\n",
      "Epoch 1019/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7110 - val_loss: 6.7465\n",
      "Epoch 1020/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7105 - val_loss: 6.7474\n",
      "Epoch 1021/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7100 - val_loss: 6.7459\n",
      "Epoch 1022/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7097 - val_loss: 6.7468\n",
      "Epoch 1023/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7092 - val_loss: 6.7449\n",
      "Epoch 1024/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7087 - val_loss: 6.7454\n",
      "Epoch 1025/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7083 - val_loss: 6.7484\n",
      "Epoch 1026/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.7080 - val_loss: 6.7523\n",
      "Epoch 1027/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7074 - val_loss: 6.7435\n",
      "Epoch 1028/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7071 - val_loss: 6.7439\n",
      "Epoch 1029/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7066 - val_loss: 6.7466\n",
      "Epoch 1030/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7063 - val_loss: 6.7455\n",
      "Epoch 1031/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7058 - val_loss: 6.7442\n",
      "Epoch 1032/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7053 - val_loss: 6.7454\n",
      "Epoch 1033/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7050 - val_loss: 6.7413\n",
      "Epoch 1034/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7045 - val_loss: 6.7497\n",
      "Epoch 1035/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7041 - val_loss: 6.7405\n",
      "Epoch 1036/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7036 - val_loss: 6.7400\n",
      "Epoch 1037/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7031 - val_loss: 6.7391\n",
      "Epoch 1038/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7028 - val_loss: 6.7385\n",
      "Epoch 1039/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7023 - val_loss: 6.7396\n",
      "Epoch 1040/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7019 - val_loss: 6.7380\n",
      "Epoch 1041/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7015 - val_loss: 6.7372\n",
      "Epoch 1042/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.7011 - val_loss: 6.7370\n",
      "Epoch 1043/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7008 - val_loss: 6.7410\n",
      "Epoch 1044/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.7002 - val_loss: 6.7362\n",
      "Epoch 1045/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6999 - val_loss: 6.7393\n",
      "Epoch 1046/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6993 - val_loss: 6.7353\n",
      "Epoch 1047/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6990 - val_loss: 6.7370\n",
      "Epoch 1048/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6987 - val_loss: 6.7343\n",
      "Epoch 1049/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6981 - val_loss: 6.7368\n",
      "Epoch 1050/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6978 - val_loss: 6.7382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1051/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6972 - val_loss: 6.7338\n",
      "Epoch 1052/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6969 - val_loss: 6.7348\n",
      "Epoch 1053/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6966 - val_loss: 6.7362\n",
      "Epoch 1054/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6961 - val_loss: 6.7314\n",
      "Epoch 1055/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6958 - val_loss: 6.7346\n",
      "Epoch 1056/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6953 - val_loss: 6.7311\n",
      "Epoch 1057/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6949 - val_loss: 6.7316\n",
      "Epoch 1058/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6944 - val_loss: 6.7301\n",
      "Epoch 1059/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6940 - val_loss: 6.7305\n",
      "Epoch 1060/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6936 - val_loss: 6.7328\n",
      "Epoch 1061/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6932 - val_loss: 6.7287\n",
      "Epoch 1062/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6929 - val_loss: 6.7284\n",
      "Epoch 1063/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6925 - val_loss: 6.7277\n",
      "Epoch 1064/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6919 - val_loss: 6.7296\n",
      "Epoch 1065/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6916 - val_loss: 6.7308\n",
      "Epoch 1066/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6912 - val_loss: 6.7272\n",
      "Epoch 1067/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6909 - val_loss: 6.7273\n",
      "Epoch 1068/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6904 - val_loss: 6.7293\n",
      "Epoch 1069/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6899 - val_loss: 6.7252\n",
      "Epoch 1070/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6897 - val_loss: 6.7255\n",
      "Epoch 1071/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6891 - val_loss: 6.7259\n",
      "Epoch 1072/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6888 - val_loss: 6.7240\n",
      "Epoch 1073/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6884 - val_loss: 6.7268\n",
      "Epoch 1074/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6880 - val_loss: 6.7231\n",
      "Epoch 1075/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6876 - val_loss: 6.7233\n",
      "Epoch 1076/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6873 - val_loss: 6.7283\n",
      "Epoch 1077/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6867 - val_loss: 6.7231\n",
      "Epoch 1078/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6863 - val_loss: 6.7226\n",
      "Epoch 1079/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6860 - val_loss: 6.7213\n",
      "Epoch 1080/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.6856 - val_loss: 6.7220\n",
      "Epoch 1081/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6852 - val_loss: 6.7207\n",
      "Epoch 1082/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6849 - val_loss: 6.7199\n",
      "Epoch 1083/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6844 - val_loss: 6.7202\n",
      "Epoch 1084/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6841 - val_loss: 6.7238\n",
      "Epoch 1085/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6835 - val_loss: 6.7248\n",
      "Epoch 1086/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6833 - val_loss: 6.7216\n",
      "Epoch 1087/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6830 - val_loss: 6.7189\n",
      "Epoch 1088/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6825 - val_loss: 6.7197\n",
      "Epoch 1089/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6821 - val_loss: 6.7214\n",
      "Epoch 1090/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6817 - val_loss: 6.7176\n",
      "Epoch 1091/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6813 - val_loss: 6.7184\n",
      "Epoch 1092/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6810 - val_loss: 6.7170\n",
      "Epoch 1093/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6805 - val_loss: 6.7179\n",
      "Epoch 1094/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6801 - val_loss: 6.7157\n",
      "Epoch 1095/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6797 - val_loss: 6.7208\n",
      "Epoch 1096/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6793 - val_loss: 6.7145\n",
      "Epoch 1097/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6789 - val_loss: 6.7144\n",
      "Epoch 1098/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6787 - val_loss: 6.7139\n",
      "Epoch 1099/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6782 - val_loss: 6.7140\n",
      "Epoch 1100/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6779 - val_loss: 6.7152\n",
      "Epoch 1101/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6775 - val_loss: 6.7128\n",
      "Epoch 1102/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6771 - val_loss: 6.7129\n",
      "Epoch 1103/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6766 - val_loss: 6.7136\n",
      "Epoch 1104/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6762 - val_loss: 6.7112\n",
      "Epoch 1105/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6759 - val_loss: 6.7115\n",
      "Epoch 1106/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6755 - val_loss: 6.7110\n",
      "Epoch 1107/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6753 - val_loss: 6.7102\n",
      "Epoch 1108/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6747 - val_loss: 6.7103\n",
      "Epoch 1109/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6743 - val_loss: 6.7097\n",
      "Epoch 1110/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6741 - val_loss: 6.7100\n",
      "Epoch 1111/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6736 - val_loss: 6.7094\n",
      "Epoch 1112/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6732 - val_loss: 6.7094\n",
      "Epoch 1113/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6729 - val_loss: 6.7134\n",
      "Epoch 1114/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6725 - val_loss: 6.7098\n",
      "Epoch 1115/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6722 - val_loss: 6.7074\n",
      "Epoch 1116/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6717 - val_loss: 6.7091\n",
      "Epoch 1117/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6714 - val_loss: 6.7077\n",
      "Epoch 1118/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6710 - val_loss: 6.7078\n",
      "Epoch 1119/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6706 - val_loss: 6.7072\n",
      "Epoch 1120/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6704 - val_loss: 6.7079\n",
      "Epoch 1121/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6698 - val_loss: 6.7050\n",
      "Epoch 1122/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6695 - val_loss: 6.7059\n",
      "Epoch 1123/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6691 - val_loss: 6.7057\n",
      "Epoch 1124/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6687 - val_loss: 6.7054\n",
      "Epoch 1125/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6684 - val_loss: 6.7035\n",
      "Epoch 1126/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6680 - val_loss: 6.7049\n",
      "Epoch 1127/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6676 - val_loss: 6.7035\n",
      "Epoch 1128/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6673 - val_loss: 6.7023\n",
      "Epoch 1129/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6669 - val_loss: 6.7037\n",
      "Epoch 1130/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6665 - val_loss: 6.7020\n",
      "Epoch 1131/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6662 - val_loss: 6.7015\n",
      "Epoch 1132/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6658 - val_loss: 6.7014\n",
      "Epoch 1133/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6655 - val_loss: 6.7038\n",
      "Epoch 1134/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6650 - val_loss: 6.7000\n",
      "Epoch 1135/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6647 - val_loss: 6.7011\n",
      "Epoch 1136/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6644 - val_loss: 6.7013\n",
      "Epoch 1137/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.6639 - val_loss: 6.7014\n",
      "Epoch 1138/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6637 - val_loss: 6.6995\n",
      "Epoch 1139/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6632 - val_loss: 6.6990\n",
      "Epoch 1140/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6631 - val_loss: 6.6982\n",
      "Epoch 1141/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6625 - val_loss: 6.6977\n",
      "Epoch 1142/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6621 - val_loss: 6.7006\n",
      "Epoch 1143/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6618 - val_loss: 6.6966\n",
      "Epoch 1144/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6614 - val_loss: 6.7000\n",
      "Epoch 1145/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6612 - val_loss: 6.6967\n",
      "Epoch 1146/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6608 - val_loss: 6.6977\n",
      "Epoch 1147/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6604 - val_loss: 6.6970\n",
      "Epoch 1148/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6600 - val_loss: 6.6945\n",
      "Epoch 1149/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6597 - val_loss: 6.6945\n",
      "Epoch 1150/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6593 - val_loss: 6.6943\n",
      "Epoch 1151/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6590 - val_loss: 6.6949\n",
      "Epoch 1152/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6587 - val_loss: 6.6939\n",
      "Epoch 1153/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6583 - val_loss: 6.6940\n",
      "Epoch 1154/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6579 - val_loss: 6.6962\n",
      "Epoch 1155/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6577 - val_loss: 6.6927\n",
      "Epoch 1156/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6572 - val_loss: 6.6974\n",
      "Epoch 1157/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6568 - val_loss: 6.6919\n",
      "Epoch 1158/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6565 - val_loss: 6.6912\n",
      "Epoch 1159/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6562 - val_loss: 6.6917\n",
      "Epoch 1160/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6558 - val_loss: 6.6903\n",
      "Epoch 1161/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6555 - val_loss: 6.6919\n",
      "Epoch 1162/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6551 - val_loss: 6.6906\n",
      "Epoch 1163/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6547 - val_loss: 6.6898\n",
      "Epoch 1164/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6545 - val_loss: 6.6905\n",
      "Epoch 1165/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6540 - val_loss: 6.6912\n",
      "Epoch 1166/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6536 - val_loss: 6.6893\n",
      "Epoch 1167/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6534 - val_loss: 6.6886\n",
      "Epoch 1168/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6531 - val_loss: 6.6884\n",
      "Epoch 1169/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6527 - val_loss: 6.6874\n",
      "Epoch 1170/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6524 - val_loss: 6.6875\n",
      "Epoch 1171/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6520 - val_loss: 6.6891\n",
      "Epoch 1172/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6516 - val_loss: 6.6867\n",
      "Epoch 1173/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6513 - val_loss: 6.6860\n",
      "Epoch 1174/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6509 - val_loss: 6.6855\n",
      "Epoch 1175/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6506 - val_loss: 6.6891\n",
      "Epoch 1176/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6502 - val_loss: 6.6850\n",
      "Epoch 1177/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6499 - val_loss: 6.6874\n",
      "Epoch 1178/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6496 - val_loss: 6.6848\n",
      "Epoch 1179/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6492 - val_loss: 6.6880\n",
      "Epoch 1180/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6487 - val_loss: 6.6835\n",
      "Epoch 1181/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6484 - val_loss: 6.6830\n",
      "Epoch 1182/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6481 - val_loss: 6.6827\n",
      "Epoch 1183/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6479 - val_loss: 6.6823\n",
      "Epoch 1184/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6475 - val_loss: 6.6826\n",
      "Epoch 1185/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6471 - val_loss: 6.6830\n",
      "Epoch 1186/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6468 - val_loss: 6.6823\n",
      "Epoch 1187/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.6464 - val_loss: 6.6849\n",
      "Epoch 1188/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6462 - val_loss: 6.6809\n",
      "Epoch 1189/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6459 - val_loss: 6.6802\n",
      "Epoch 1190/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6454 - val_loss: 6.6809\n",
      "Epoch 1191/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6452 - val_loss: 6.6805\n",
      "Epoch 1192/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6448 - val_loss: 6.6797\n",
      "Epoch 1193/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6446 - val_loss: 6.6801\n",
      "Epoch 1194/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6441 - val_loss: 6.6793\n",
      "Epoch 1195/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6439 - val_loss: 6.6785\n",
      "Epoch 1196/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6434 - val_loss: 6.6776\n",
      "Epoch 1197/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6430 - val_loss: 6.6784\n",
      "Epoch 1198/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6427 - val_loss: 6.6768\n",
      "Epoch 1199/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6426 - val_loss: 6.6784\n",
      "Epoch 1200/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6421 - val_loss: 6.6766\n",
      "Epoch 1201/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6418 - val_loss: 6.6777\n",
      "Epoch 1202/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.6414 - val_loss: 6.6754\n",
      "Epoch 1203/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6411 - val_loss: 6.6756\n",
      "Epoch 1204/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6408 - val_loss: 6.6777\n",
      "Epoch 1205/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6405 - val_loss: 6.6818\n",
      "Epoch 1206/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6401 - val_loss: 6.6763\n",
      "Epoch 1207/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6399 - val_loss: 6.6748\n",
      "Epoch 1208/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6395 - val_loss: 6.6738\n",
      "Epoch 1209/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6392 - val_loss: 6.6775\n",
      "Epoch 1210/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6388 - val_loss: 6.6738\n",
      "Epoch 1211/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6385 - val_loss: 6.6733\n",
      "Epoch 1212/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6381 - val_loss: 6.6733\n",
      "Epoch 1213/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6379 - val_loss: 6.6725\n",
      "Epoch 1214/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6376 - val_loss: 6.6719\n",
      "Epoch 1215/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.6371 - val_loss: 6.6712\n",
      "Epoch 1216/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6369 - val_loss: 6.6716\n",
      "Epoch 1217/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6365 - val_loss: 6.6729\n",
      "Epoch 1218/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6361 - val_loss: 6.6720\n",
      "Epoch 1219/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6359 - val_loss: 6.6717\n",
      "Epoch 1220/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6355 - val_loss: 6.6743\n",
      "Epoch 1221/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6352 - val_loss: 6.6709\n",
      "Epoch 1222/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6348 - val_loss: 6.6748\n",
      "Epoch 1223/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6346 - val_loss: 6.6709\n",
      "Epoch 1224/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6342 - val_loss: 6.6682\n",
      "Epoch 1225/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6340 - val_loss: 6.6680\n",
      "Epoch 1226/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6336 - val_loss: 6.6692\n",
      "Epoch 1227/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6333 - val_loss: 6.6682\n",
      "Epoch 1228/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6330 - val_loss: 6.6683\n",
      "Epoch 1229/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 6.6327 - val_loss: 6.6707\n",
      "Epoch 1230/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6325 - val_loss: 6.6663\n",
      "Epoch 1231/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6321 - val_loss: 6.6676\n",
      "Epoch 1232/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6317 - val_loss: 6.6674\n",
      "Epoch 1233/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6313 - val_loss: 6.6656\n",
      "Epoch 1234/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.6312 - val_loss: 6.6651\n",
      "Epoch 1235/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6307 - val_loss: 6.6654\n",
      "Epoch 1236/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6303 - val_loss: 6.6657\n",
      "Epoch 1237/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6301 - val_loss: 6.6649\n",
      "Epoch 1238/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6298 - val_loss: 6.6650\n",
      "Epoch 1239/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6294 - val_loss: 6.6637\n",
      "Epoch 1240/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6292 - val_loss: 6.6630\n",
      "Epoch 1241/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6289 - val_loss: 6.6629\n",
      "Epoch 1242/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6285 - val_loss: 6.6630\n",
      "Epoch 1243/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6281 - val_loss: 6.6634\n",
      "Epoch 1244/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6279 - val_loss: 6.6671\n",
      "Epoch 1245/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6276 - val_loss: 6.6621\n",
      "Epoch 1246/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6273 - val_loss: 6.6611\n",
      "Epoch 1247/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6269 - val_loss: 6.6648\n",
      "Epoch 1248/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6267 - val_loss: 6.6606\n",
      "Epoch 1249/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6264 - val_loss: 6.6625\n",
      "Epoch 1250/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6260 - val_loss: 6.6605\n",
      "Epoch 1251/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6258 - val_loss: 6.6634\n",
      "Epoch 1252/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6256 - val_loss: 6.6594\n",
      "Epoch 1253/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6251 - val_loss: 6.6612\n",
      "Epoch 1254/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.6248 - val_loss: 6.6630\n",
      "Epoch 1255/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6244 - val_loss: 6.6584\n",
      "Epoch 1256/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6241 - val_loss: 6.6586\n",
      "Epoch 1257/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.6238 - val_loss: 6.6581\n",
      "Epoch 1258/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6236 - val_loss: 6.6604\n",
      "Epoch 1259/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6234 - val_loss: 6.6577\n",
      "Epoch 1260/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6230 - val_loss: 6.6570\n",
      "Epoch 1261/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6226 - val_loss: 6.6572\n",
      "Epoch 1262/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6223 - val_loss: 6.6565\n",
      "Epoch 1263/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6220 - val_loss: 6.6590\n",
      "Epoch 1264/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6217 - val_loss: 6.6567\n",
      "Epoch 1265/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6214 - val_loss: 6.6556\n",
      "Epoch 1266/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6211 - val_loss: 6.6574\n",
      "Epoch 1267/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6207 - val_loss: 6.6546\n",
      "Epoch 1268/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6206 - val_loss: 6.6581\n",
      "Epoch 1269/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6203 - val_loss: 6.6551\n",
      "Epoch 1270/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6200 - val_loss: 6.6559\n",
      "Epoch 1271/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6197 - val_loss: 6.6558\n",
      "Epoch 1272/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6194 - val_loss: 6.6565\n",
      "Epoch 1273/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6191 - val_loss: 6.6546\n",
      "Epoch 1274/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6187 - val_loss: 6.6536\n",
      "Epoch 1275/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6184 - val_loss: 6.6545\n",
      "Epoch 1276/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6182 - val_loss: 6.6542\n",
      "Epoch 1277/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6178 - val_loss: 6.6521\n",
      "Epoch 1278/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.6175 - val_loss: 6.6517\n",
      "Epoch 1279/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6173 - val_loss: 6.6543\n",
      "Epoch 1280/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6169 - val_loss: 6.6504\n",
      "Epoch 1281/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6166 - val_loss: 6.6550\n",
      "Epoch 1282/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6164 - val_loss: 6.6511\n",
      "Epoch 1283/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6159 - val_loss: 6.6524\n",
      "Epoch 1284/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6157 - val_loss: 6.6513\n",
      "Epoch 1285/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6154 - val_loss: 6.6503\n",
      "Epoch 1286/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6153 - val_loss: 6.6502\n",
      "Epoch 1287/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6148 - val_loss: 6.6521\n",
      "Epoch 1288/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6145 - val_loss: 6.6485\n",
      "Epoch 1289/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6142 - val_loss: 6.6515\n",
      "Epoch 1290/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6139 - val_loss: 6.6488\n",
      "Epoch 1291/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6137 - val_loss: 6.6480\n",
      "Epoch 1292/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6133 - val_loss: 6.6474\n",
      "Epoch 1293/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6130 - val_loss: 6.6480\n",
      "Epoch 1294/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6128 - val_loss: 6.6481\n",
      "Epoch 1295/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6124 - val_loss: 6.6466\n",
      "Epoch 1296/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6122 - val_loss: 6.6462\n",
      "Epoch 1297/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6119 - val_loss: 6.6476\n",
      "Epoch 1298/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6116 - val_loss: 6.6450\n",
      "Epoch 1299/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6113 - val_loss: 6.6454\n",
      "Epoch 1300/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6110 - val_loss: 6.6468\n",
      "Epoch 1301/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6107 - val_loss: 6.6446\n",
      "Epoch 1302/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6104 - val_loss: 6.6455\n",
      "Epoch 1303/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6102 - val_loss: 6.6457\n",
      "Epoch 1304/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6098 - val_loss: 6.6433\n",
      "Epoch 1305/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6096 - val_loss: 6.6436\n",
      "Epoch 1306/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6094 - val_loss: 6.6440\n",
      "Epoch 1307/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6089 - val_loss: 6.6424\n",
      "Epoch 1308/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6088 - val_loss: 6.6441\n",
      "Epoch 1309/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6084 - val_loss: 6.6420\n",
      "Epoch 1310/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6081 - val_loss: 6.6417\n",
      "Epoch 1311/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6079 - val_loss: 6.6431\n",
      "Epoch 1312/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.6075 - val_loss: 6.6410\n",
      "Epoch 1313/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6072 - val_loss: 6.6442\n",
      "Epoch 1314/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6069 - val_loss: 6.6423\n",
      "Epoch 1315/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6067 - val_loss: 6.6404\n",
      "Epoch 1316/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6063 - val_loss: 6.6444\n",
      "Epoch 1317/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6061 - val_loss: 6.6393\n",
      "Epoch 1318/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6057 - val_loss: 6.6412\n",
      "Epoch 1319/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6056 - val_loss: 6.6402\n",
      "Epoch 1320/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6052 - val_loss: 6.6410\n",
      "Epoch 1321/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6048 - val_loss: 6.6403\n",
      "Epoch 1322/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6048 - val_loss: 6.6380\n",
      "Epoch 1323/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6044 - val_loss: 6.6389\n",
      "Epoch 1324/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6042 - val_loss: 6.6378\n",
      "Epoch 1325/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6038 - val_loss: 6.6406\n",
      "Epoch 1326/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6035 - val_loss: 6.6372\n",
      "Epoch 1327/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6033 - val_loss: 6.6380\n",
      "Epoch 1328/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6031 - val_loss: 6.6370\n",
      "Epoch 1329/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6028 - val_loss: 6.6416\n",
      "Epoch 1330/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6025 - val_loss: 6.6358\n",
      "Epoch 1331/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6020 - val_loss: 6.6385\n",
      "Epoch 1332/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6019 - val_loss: 6.6370\n",
      "Epoch 1333/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6016 - val_loss: 6.6469\n",
      "Epoch 1334/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6013 - val_loss: 6.6364\n",
      "Epoch 1335/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.6011 - val_loss: 6.6342\n",
      "Epoch 1336/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.6008 - val_loss: 6.6349\n",
      "Epoch 1337/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6005 - val_loss: 6.6365\n",
      "Epoch 1338/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6002 - val_loss: 6.6335\n",
      "Epoch 1339/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.6000 - val_loss: 6.6341\n",
      "Epoch 1340/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5997 - val_loss: 6.6345\n",
      "Epoch 1341/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5994 - val_loss: 6.6330\n",
      "Epoch 1342/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5991 - val_loss: 6.6330\n",
      "Epoch 1343/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5987 - val_loss: 6.6325\n",
      "Epoch 1344/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5986 - val_loss: 6.6342\n",
      "Epoch 1345/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5983 - val_loss: 6.6323\n",
      "Epoch 1346/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5981 - val_loss: 6.6385\n",
      "Epoch 1347/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5978 - val_loss: 6.6318\n",
      "Epoch 1348/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5974 - val_loss: 6.6323\n",
      "Epoch 1349/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5972 - val_loss: 6.6317\n",
      "Epoch 1350/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5970 - val_loss: 6.6304\n",
      "Epoch 1351/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5966 - val_loss: 6.6339\n",
      "Epoch 1352/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5964 - val_loss: 6.6358\n",
      "Epoch 1353/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5961 - val_loss: 6.6291\n",
      "Epoch 1354/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5958 - val_loss: 6.6343\n",
      "Epoch 1355/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5956 - val_loss: 6.6321\n",
      "Epoch 1356/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5954 - val_loss: 6.6339\n",
      "Epoch 1357/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5950 - val_loss: 6.6289\n",
      "Epoch 1358/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5947 - val_loss: 6.6281\n",
      "Epoch 1359/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5944 - val_loss: 6.6278\n",
      "Epoch 1360/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5942 - val_loss: 6.6276\n",
      "Epoch 1361/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5939 - val_loss: 6.6278\n",
      "Epoch 1362/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5936 - val_loss: 6.6285\n",
      "Epoch 1363/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5935 - val_loss: 6.6275\n",
      "Epoch 1364/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5931 - val_loss: 6.6265\n",
      "Epoch 1365/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5929 - val_loss: 6.6322\n",
      "Epoch 1366/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5927 - val_loss: 6.6260\n",
      "Epoch 1367/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5923 - val_loss: 6.6255\n",
      "Epoch 1368/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5921 - val_loss: 6.6289\n",
      "Epoch 1369/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5918 - val_loss: 6.6283\n",
      "Epoch 1370/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5917 - val_loss: 6.6249\n",
      "Epoch 1371/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5913 - val_loss: 6.6264\n",
      "Epoch 1372/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5910 - val_loss: 6.6247\n",
      "Epoch 1373/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5908 - val_loss: 6.6235\n",
      "Epoch 1374/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5903 - val_loss: 6.6249\n",
      "Epoch 1375/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5902 - val_loss: 6.6232\n",
      "Epoch 1376/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5899 - val_loss: 6.6227\n",
      "Epoch 1377/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5897 - val_loss: 6.6232\n",
      "Epoch 1378/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5894 - val_loss: 6.6229\n",
      "Epoch 1379/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5890 - val_loss: 6.6228\n",
      "Epoch 1380/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5889 - val_loss: 6.6229\n",
      "Epoch 1381/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5886 - val_loss: 6.6237\n",
      "Epoch 1382/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5883 - val_loss: 6.6217\n",
      "Epoch 1383/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5881 - val_loss: 6.6234\n",
      "Epoch 1384/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.5879 - val_loss: 6.6221\n",
      "Epoch 1385/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5875 - val_loss: 6.6242\n",
      "Epoch 1386/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5874 - val_loss: 6.6216\n",
      "Epoch 1387/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5871 - val_loss: 6.6206\n",
      "Epoch 1388/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5869 - val_loss: 6.6208\n",
      "Epoch 1389/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5865 - val_loss: 6.6207\n",
      "Epoch 1390/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5863 - val_loss: 6.6191\n",
      "Epoch 1391/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5860 - val_loss: 6.6201\n",
      "Epoch 1392/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5858 - val_loss: 6.6223\n",
      "Epoch 1393/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5855 - val_loss: 6.6185\n",
      "Epoch 1394/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5853 - val_loss: 6.6203\n",
      "Epoch 1395/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5850 - val_loss: 6.6184\n",
      "Epoch 1396/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5846 - val_loss: 6.6184\n",
      "Epoch 1397/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5845 - val_loss: 6.6171\n",
      "Epoch 1398/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5843 - val_loss: 6.6172\n",
      "Epoch 1399/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5840 - val_loss: 6.6203\n",
      "Epoch 1400/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5837 - val_loss: 6.6170\n",
      "Epoch 1401/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5833 - val_loss: 6.6187\n",
      "Epoch 1402/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5832 - val_loss: 6.6163\n",
      "Epoch 1403/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5829 - val_loss: 6.6181\n",
      "Epoch 1404/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5827 - val_loss: 6.6211\n",
      "Epoch 1405/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5823 - val_loss: 6.6163\n",
      "Epoch 1406/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5821 - val_loss: 6.6153\n",
      "Epoch 1407/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5819 - val_loss: 6.6156\n",
      "Epoch 1408/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5817 - val_loss: 6.6153\n",
      "Epoch 1409/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5815 - val_loss: 6.6204\n",
      "Epoch 1410/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5811 - val_loss: 6.6140\n",
      "Epoch 1411/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5808 - val_loss: 6.6151\n",
      "Epoch 1412/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5806 - val_loss: 6.6136\n",
      "Epoch 1413/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5805 - val_loss: 6.6138\n",
      "Epoch 1414/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5801 - val_loss: 6.6140\n",
      "Epoch 1415/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5798 - val_loss: 6.6127\n",
      "Epoch 1416/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5796 - val_loss: 6.6159\n",
      "Epoch 1417/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5794 - val_loss: 6.6133\n",
      "Epoch 1418/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5791 - val_loss: 6.6119\n",
      "Epoch 1419/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5788 - val_loss: 6.6116\n",
      "Epoch 1420/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5785 - val_loss: 6.6120\n",
      "Epoch 1421/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5783 - val_loss: 6.6163\n",
      "Epoch 1422/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5781 - val_loss: 6.6149\n",
      "Epoch 1423/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5778 - val_loss: 6.6118\n",
      "Epoch 1424/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5777 - val_loss: 6.6116\n",
      "Epoch 1425/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5773 - val_loss: 6.6110\n",
      "Epoch 1426/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5771 - val_loss: 6.6126\n",
      "Epoch 1427/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5768 - val_loss: 6.6100\n",
      "Epoch 1428/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5766 - val_loss: 6.6096\n",
      "Epoch 1429/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5764 - val_loss: 6.6117\n",
      "Epoch 1430/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5760 - val_loss: 6.6090\n",
      "Epoch 1431/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5760 - val_loss: 6.6109\n",
      "Epoch 1432/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5756 - val_loss: 6.6086\n",
      "Epoch 1433/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5754 - val_loss: 6.6090\n",
      "Epoch 1434/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5751 - val_loss: 6.6085\n",
      "Epoch 1435/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5748 - val_loss: 6.6100\n",
      "Epoch 1436/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5747 - val_loss: 6.6103\n",
      "Epoch 1437/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5743 - val_loss: 6.6105\n",
      "Epoch 1438/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5742 - val_loss: 6.6069\n",
      "Epoch 1439/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5738 - val_loss: 6.6101\n",
      "Epoch 1440/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5737 - val_loss: 6.6068\n",
      "Epoch 1441/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5734 - val_loss: 6.6063\n",
      "Epoch 1442/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5731 - val_loss: 6.6075\n",
      "Epoch 1443/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5730 - val_loss: 6.6079\n",
      "Epoch 1444/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5726 - val_loss: 6.6055\n",
      "Epoch 1445/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5724 - val_loss: 6.6071\n",
      "Epoch 1446/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5721 - val_loss: 6.6065\n",
      "Epoch 1447/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5720 - val_loss: 6.6058\n",
      "Epoch 1448/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5716 - val_loss: 6.6069\n",
      "Epoch 1449/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5714 - val_loss: 6.6039\n",
      "Epoch 1450/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5712 - val_loss: 6.6044\n",
      "Epoch 1451/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5709 - val_loss: 6.6041\n",
      "Epoch 1452/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5707 - val_loss: 6.6037\n",
      "Epoch 1453/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5705 - val_loss: 6.6048\n",
      "Epoch 1454/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5702 - val_loss: 6.6036\n",
      "Epoch 1455/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5699 - val_loss: 6.6032\n",
      "Epoch 1456/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5697 - val_loss: 6.6026\n",
      "Epoch 1457/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5695 - val_loss: 6.6030\n",
      "Epoch 1458/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5693 - val_loss: 6.6018\n",
      "Epoch 1459/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5689 - val_loss: 6.6026\n",
      "Epoch 1460/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5687 - val_loss: 6.6015\n",
      "Epoch 1461/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5686 - val_loss: 6.6023\n",
      "Epoch 1462/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5684 - val_loss: 6.6007\n",
      "Epoch 1463/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5680 - val_loss: 6.6016\n",
      "Epoch 1464/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5678 - val_loss: 6.6009\n",
      "Epoch 1465/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5676 - val_loss: 6.6009\n",
      "Epoch 1466/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5673 - val_loss: 6.6015\n",
      "Epoch 1467/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5672 - val_loss: 6.6001\n",
      "Epoch 1468/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5669 - val_loss: 6.6016\n",
      "Epoch 1469/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5666 - val_loss: 6.6004\n",
      "Epoch 1470/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5664 - val_loss: 6.6005\n",
      "Epoch 1471/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5662 - val_loss: 6.5989\n",
      "Epoch 1472/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5660 - val_loss: 6.5991\n",
      "Epoch 1473/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5658 - val_loss: 6.5988\n",
      "Epoch 1474/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5655 - val_loss: 6.5992\n",
      "Epoch 1475/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5652 - val_loss: 6.6019\n",
      "Epoch 1476/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.5650 - val_loss: 6.5988\n",
      "Epoch 1477/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.5648 - val_loss: 6.5992\n",
      "Epoch 1478/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5645 - val_loss: 6.5973\n",
      "Epoch 1479/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5644 - val_loss: 6.6002\n",
      "Epoch 1480/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5640 - val_loss: 6.6010\n",
      "Epoch 1481/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5639 - val_loss: 6.5971\n",
      "Epoch 1482/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5636 - val_loss: 6.5973\n",
      "Epoch 1483/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5633 - val_loss: 6.5959\n",
      "Epoch 1484/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5632 - val_loss: 6.5982\n",
      "Epoch 1485/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5630 - val_loss: 6.5955\n",
      "Epoch 1486/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5626 - val_loss: 6.5951\n",
      "Epoch 1487/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5626 - val_loss: 6.5958\n",
      "Epoch 1488/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5622 - val_loss: 6.5945\n",
      "Epoch 1489/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5619 - val_loss: 6.5944\n",
      "Epoch 1490/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5618 - val_loss: 6.5948\n",
      "Epoch 1491/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5615 - val_loss: 6.5937\n",
      "Epoch 1492/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5613 - val_loss: 6.5938\n",
      "Epoch 1493/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5611 - val_loss: 6.5938\n",
      "Epoch 1494/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5608 - val_loss: 6.5942\n",
      "Epoch 1495/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5607 - val_loss: 6.5932\n",
      "Epoch 1496/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5603 - val_loss: 6.5937\n",
      "Epoch 1497/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5601 - val_loss: 6.5941\n",
      "Epoch 1498/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.5598 - val_loss: 6.5923\n",
      "Epoch 1499/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5596 - val_loss: 6.5927\n",
      "Epoch 1500/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5595 - val_loss: 6.5925\n",
      "Epoch 1501/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5591 - val_loss: 6.5914\n",
      "Epoch 1502/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5589 - val_loss: 6.5918\n",
      "Epoch 1503/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5587 - val_loss: 6.5934\n",
      "Epoch 1504/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5585 - val_loss: 6.5915\n",
      "Epoch 1505/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5582 - val_loss: 6.5909\n",
      "Epoch 1506/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5580 - val_loss: 6.5914\n",
      "Epoch 1507/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5579 - val_loss: 6.5911\n",
      "Epoch 1508/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5577 - val_loss: 6.5904\n",
      "Epoch 1509/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5574 - val_loss: 6.5896\n",
      "Epoch 1510/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5573 - val_loss: 6.5900\n",
      "Epoch 1511/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5569 - val_loss: 6.5896\n",
      "Epoch 1512/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5567 - val_loss: 6.5890\n",
      "Epoch 1513/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5564 - val_loss: 6.5912\n",
      "Epoch 1514/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5564 - val_loss: 6.5893\n",
      "Epoch 1515/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5561 - val_loss: 6.5896\n",
      "Epoch 1516/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5558 - val_loss: 6.5916\n",
      "Epoch 1517/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5556 - val_loss: 6.5881\n",
      "Epoch 1518/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5553 - val_loss: 6.5903\n",
      "Epoch 1519/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5552 - val_loss: 6.5904\n",
      "Epoch 1520/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5549 - val_loss: 6.5939\n",
      "Epoch 1521/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5546 - val_loss: 6.5882\n",
      "Epoch 1522/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5544 - val_loss: 6.5872\n",
      "Epoch 1523/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5542 - val_loss: 6.5869\n",
      "Epoch 1524/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5540 - val_loss: 6.5865\n",
      "Epoch 1525/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5538 - val_loss: 6.5867\n",
      "Epoch 1526/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5536 - val_loss: 6.5861\n",
      "Epoch 1527/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5533 - val_loss: 6.5894\n",
      "Epoch 1528/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5531 - val_loss: 6.5863\n",
      "Epoch 1529/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5529 - val_loss: 6.5892\n",
      "Epoch 1530/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5527 - val_loss: 6.5855\n",
      "Epoch 1531/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5524 - val_loss: 6.5872\n",
      "Epoch 1532/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5522 - val_loss: 6.5898\n",
      "Epoch 1533/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5520 - val_loss: 6.5848\n",
      "Epoch 1534/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5517 - val_loss: 6.5841\n",
      "Epoch 1535/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5515 - val_loss: 6.5843\n",
      "Epoch 1536/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5514 - val_loss: 6.5841\n",
      "Epoch 1537/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5511 - val_loss: 6.5847\n",
      "Epoch 1538/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5509 - val_loss: 6.5874\n",
      "Epoch 1539/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5506 - val_loss: 6.5840\n",
      "Epoch 1540/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5505 - val_loss: 6.5828\n",
      "Epoch 1541/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5502 - val_loss: 6.5849\n",
      "Epoch 1542/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5500 - val_loss: 6.5833\n",
      "Epoch 1543/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5499 - val_loss: 6.5840\n",
      "Epoch 1544/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5496 - val_loss: 6.5818\n",
      "Epoch 1545/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5494 - val_loss: 6.5819\n",
      "Epoch 1546/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5492 - val_loss: 6.5817\n",
      "Epoch 1547/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5490 - val_loss: 6.5824\n",
      "Epoch 1548/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5486 - val_loss: 6.5813\n",
      "Epoch 1549/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5486 - val_loss: 6.5815\n",
      "Epoch 1550/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5482 - val_loss: 6.5803\n",
      "Epoch 1551/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5480 - val_loss: 6.5827\n",
      "Epoch 1552/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5479 - val_loss: 6.5805\n",
      "Epoch 1553/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5477 - val_loss: 6.5809\n",
      "Epoch 1554/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5474 - val_loss: 6.5796\n",
      "Epoch 1555/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5471 - val_loss: 6.5797\n",
      "Epoch 1556/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5470 - val_loss: 6.5808\n",
      "Epoch 1557/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5468 - val_loss: 6.5813\n",
      "Epoch 1558/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5467 - val_loss: 6.5793\n",
      "Epoch 1559/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5463 - val_loss: 6.5785\n",
      "Epoch 1560/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5463 - val_loss: 6.5786\n",
      "Epoch 1561/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5458 - val_loss: 6.5794\n",
      "Epoch 1562/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5457 - val_loss: 6.5798\n",
      "Epoch 1563/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5455 - val_loss: 6.5783\n",
      "Epoch 1564/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5453 - val_loss: 6.5776\n",
      "Epoch 1565/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5451 - val_loss: 6.5780\n",
      "Epoch 1566/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5448 - val_loss: 6.5793\n",
      "Epoch 1567/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5446 - val_loss: 6.5826\n",
      "Epoch 1568/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5444 - val_loss: 6.5774\n",
      "Epoch 1569/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5443 - val_loss: 6.5763\n",
      "Epoch 1570/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5440 - val_loss: 6.5824\n",
      "Epoch 1571/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5439 - val_loss: 6.5757\n",
      "Epoch 1572/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5436 - val_loss: 6.5764\n",
      "Epoch 1573/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5434 - val_loss: 6.5760\n",
      "Epoch 1574/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.5432 - val_loss: 6.5750\n",
      "Epoch 1575/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5429 - val_loss: 6.5760\n",
      "Epoch 1576/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.5428 - val_loss: 6.5783\n",
      "Epoch 1577/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5425 - val_loss: 6.5766\n",
      "Epoch 1578/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5422 - val_loss: 6.5745\n",
      "Epoch 1579/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5420 - val_loss: 6.5747\n",
      "Epoch 1580/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5419 - val_loss: 6.5752\n",
      "Epoch 1581/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5417 - val_loss: 6.5736\n",
      "Epoch 1582/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5415 - val_loss: 6.5739\n",
      "Epoch 1583/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5413 - val_loss: 6.5735\n",
      "Epoch 1584/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5410 - val_loss: 6.5735\n",
      "Epoch 1585/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5408 - val_loss: 6.5728\n",
      "Epoch 1586/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5406 - val_loss: 6.5734\n",
      "Epoch 1587/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5404 - val_loss: 6.5723\n",
      "Epoch 1588/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5403 - val_loss: 6.5728\n",
      "Epoch 1589/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5401 - val_loss: 6.5739\n",
      "Epoch 1590/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5397 - val_loss: 6.5772\n",
      "Epoch 1591/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5396 - val_loss: 6.5744\n",
      "Epoch 1592/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5395 - val_loss: 6.5715\n",
      "Epoch 1593/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5392 - val_loss: 6.5713\n",
      "Epoch 1594/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5389 - val_loss: 6.5719\n",
      "Epoch 1595/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5388 - val_loss: 6.5731\n",
      "Epoch 1596/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5386 - val_loss: 6.5718\n",
      "Epoch 1597/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5383 - val_loss: 6.5702\n",
      "Epoch 1598/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5382 - val_loss: 6.5702\n",
      "Epoch 1599/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5380 - val_loss: 6.5698\n",
      "Epoch 1600/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5378 - val_loss: 6.5699\n",
      "Epoch 1601/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5375 - val_loss: 6.5708\n",
      "Epoch 1602/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5374 - val_loss: 6.5703\n",
      "Epoch 1603/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5372 - val_loss: 6.5725\n",
      "Epoch 1604/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5370 - val_loss: 6.5688\n",
      "Epoch 1605/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.5367 - val_loss: 6.5718\n",
      "Epoch 1606/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5366 - val_loss: 6.5701\n",
      "Epoch 1607/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5363 - val_loss: 6.5684\n",
      "Epoch 1608/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5361 - val_loss: 6.5711\n",
      "Epoch 1609/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5360 - val_loss: 6.5689\n",
      "Epoch 1610/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5357 - val_loss: 6.5685\n",
      "Epoch 1611/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5355 - val_loss: 6.5675\n",
      "Epoch 1612/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5354 - val_loss: 6.5679\n",
      "Epoch 1613/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5351 - val_loss: 6.5679\n",
      "Epoch 1614/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5349 - val_loss: 6.5676\n",
      "Epoch 1615/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5347 - val_loss: 6.5681\n",
      "Epoch 1616/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5345 - val_loss: 6.5661\n",
      "Epoch 1617/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5343 - val_loss: 6.5671\n",
      "Epoch 1618/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5342 - val_loss: 6.5658\n",
      "Epoch 1619/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5339 - val_loss: 6.5667\n",
      "Epoch 1620/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5337 - val_loss: 6.5658\n",
      "Epoch 1621/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5334 - val_loss: 6.5660\n",
      "Epoch 1622/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5332 - val_loss: 6.5670\n",
      "Epoch 1623/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.5332 - val_loss: 6.5671\n",
      "Epoch 1624/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5329 - val_loss: 6.5660\n",
      "Epoch 1625/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5327 - val_loss: 6.5645\n",
      "Epoch 1626/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5326 - val_loss: 6.5672\n",
      "Epoch 1627/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5323 - val_loss: 6.5647\n",
      "Epoch 1628/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5321 - val_loss: 6.5649\n",
      "Epoch 1629/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5319 - val_loss: 6.5636\n",
      "Epoch 1630/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.5317 - val_loss: 6.5635\n",
      "Epoch 1631/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5315 - val_loss: 6.5727\n",
      "Epoch 1632/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5313 - val_loss: 6.5654\n",
      "Epoch 1633/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5311 - val_loss: 6.5627\n",
      "Epoch 1634/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5309 - val_loss: 6.5626\n",
      "Epoch 1635/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5307 - val_loss: 6.5624\n",
      "Epoch 1636/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5304 - val_loss: 6.5621\n",
      "Epoch 1637/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5303 - val_loss: 6.5622\n",
      "Epoch 1638/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5301 - val_loss: 6.5623\n",
      "Epoch 1639/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5300 - val_loss: 6.5629\n",
      "Epoch 1640/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5296 - val_loss: 6.5630\n",
      "Epoch 1641/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5295 - val_loss: 6.5614\n",
      "Epoch 1642/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5293 - val_loss: 6.5639\n",
      "Epoch 1643/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5291 - val_loss: 6.5613\n",
      "Epoch 1644/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5290 - val_loss: 6.5618\n",
      "Epoch 1645/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5287 - val_loss: 6.5605\n",
      "Epoch 1646/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5286 - val_loss: 6.5616\n",
      "Epoch 1647/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5283 - val_loss: 6.5599\n",
      "Epoch 1648/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5282 - val_loss: 6.5613\n",
      "Epoch 1649/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5280 - val_loss: 6.5595\n",
      "Epoch 1650/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.5278 - val_loss: 6.5613\n",
      "Epoch 1651/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5277 - val_loss: 6.5593\n",
      "Epoch 1652/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5273 - val_loss: 6.5643\n",
      "Epoch 1653/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5273 - val_loss: 6.5607\n",
      "Epoch 1654/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5270 - val_loss: 6.5585\n",
      "Epoch 1655/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5268 - val_loss: 6.5597\n",
      "Epoch 1656/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5266 - val_loss: 6.5609\n",
      "Epoch 1657/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5264 - val_loss: 6.5608\n",
      "Epoch 1658/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5264 - val_loss: 6.5635\n",
      "Epoch 1659/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5261 - val_loss: 6.5638\n",
      "Epoch 1660/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5259 - val_loss: 6.5574\n",
      "Epoch 1661/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5258 - val_loss: 6.5577\n",
      "Epoch 1662/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5255 - val_loss: 6.5570\n",
      "Epoch 1663/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5253 - val_loss: 6.5576\n",
      "Epoch 1664/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5253 - val_loss: 6.5565\n",
      "Epoch 1665/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5248 - val_loss: 6.5578\n",
      "Epoch 1666/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5247 - val_loss: 6.5566\n",
      "Epoch 1667/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5244 - val_loss: 6.5559\n",
      "Epoch 1668/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5243 - val_loss: 6.5560\n",
      "Epoch 1669/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5241 - val_loss: 6.5568\n",
      "Epoch 1670/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5240 - val_loss: 6.5559\n",
      "Epoch 1671/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5238 - val_loss: 6.5551\n",
      "Epoch 1672/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5235 - val_loss: 6.5548\n",
      "Epoch 1673/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5234 - val_loss: 6.5551\n",
      "Epoch 1674/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5231 - val_loss: 6.5551\n",
      "Epoch 1675/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5230 - val_loss: 6.5570\n",
      "Epoch 1676/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5227 - val_loss: 6.5545\n",
      "Epoch 1677/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5227 - val_loss: 6.5559\n",
      "Epoch 1678/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5225 - val_loss: 6.5548\n",
      "Epoch 1679/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5222 - val_loss: 6.5539\n",
      "Epoch 1680/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5220 - val_loss: 6.5534\n",
      "Epoch 1681/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5218 - val_loss: 6.5541\n",
      "Epoch 1682/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5217 - val_loss: 6.5530\n",
      "Epoch 1683/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5215 - val_loss: 6.5562\n",
      "Epoch 1684/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5213 - val_loss: 6.5542\n",
      "Epoch 1685/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5212 - val_loss: 6.5534\n",
      "Epoch 1686/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5209 - val_loss: 6.5558\n",
      "Epoch 1687/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5207 - val_loss: 6.5539\n",
      "Epoch 1688/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5205 - val_loss: 6.5522\n",
      "Epoch 1689/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.5204 - val_loss: 6.5517\n",
      "Epoch 1690/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5201 - val_loss: 6.5540\n",
      "Epoch 1691/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5200 - val_loss: 6.5511\n",
      "Epoch 1692/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5198 - val_loss: 6.5527\n",
      "Epoch 1693/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5196 - val_loss: 6.5525\n",
      "Epoch 1694/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5195 - val_loss: 6.5512\n",
      "Epoch 1695/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5192 - val_loss: 6.5505\n",
      "Epoch 1696/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5190 - val_loss: 6.5505\n",
      "Epoch 1697/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5188 - val_loss: 6.5501\n",
      "Epoch 1698/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5187 - val_loss: 6.5507\n",
      "Epoch 1699/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5185 - val_loss: 6.5512\n",
      "Epoch 1700/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5184 - val_loss: 6.5522\n",
      "Epoch 1701/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5182 - val_loss: 6.5504\n",
      "Epoch 1702/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5180 - val_loss: 6.5497\n",
      "Epoch 1703/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5177 - val_loss: 6.5494\n",
      "Epoch 1704/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5176 - val_loss: 6.5489\n",
      "Epoch 1705/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5174 - val_loss: 6.5486\n",
      "Epoch 1706/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5172 - val_loss: 6.5489\n",
      "Epoch 1707/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5171 - val_loss: 6.5483\n",
      "Epoch 1708/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5169 - val_loss: 6.5485\n",
      "Epoch 1709/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5167 - val_loss: 6.5508\n",
      "Epoch 1710/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5165 - val_loss: 6.5482\n",
      "Epoch 1711/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5162 - val_loss: 6.5508\n",
      "Epoch 1712/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5162 - val_loss: 6.5477\n",
      "Epoch 1713/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5159 - val_loss: 6.5488\n",
      "Epoch 1714/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5157 - val_loss: 6.5472\n",
      "Epoch 1715/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5155 - val_loss: 6.5524\n",
      "Epoch 1716/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5154 - val_loss: 6.5465\n",
      "Epoch 1717/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5152 - val_loss: 6.5466\n",
      "Epoch 1718/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5150 - val_loss: 6.5490\n",
      "Epoch 1719/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5149 - val_loss: 6.5460\n",
      "Epoch 1720/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5146 - val_loss: 6.5489\n",
      "Epoch 1721/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5144 - val_loss: 6.5468\n",
      "Epoch 1722/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5143 - val_loss: 6.5456\n",
      "Epoch 1723/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5141 - val_loss: 6.5451\n",
      "Epoch 1724/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5138 - val_loss: 6.5457\n",
      "Epoch 1725/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5136 - val_loss: 6.5455\n",
      "Epoch 1726/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5137 - val_loss: 6.5473\n",
      "Epoch 1727/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5133 - val_loss: 6.5455\n",
      "Epoch 1728/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5133 - val_loss: 6.5447\n",
      "Epoch 1729/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5130 - val_loss: 6.5444\n",
      "Epoch 1730/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5129 - val_loss: 6.5498\n",
      "Epoch 1731/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5127 - val_loss: 6.5438\n",
      "Epoch 1732/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5125 - val_loss: 6.5443\n",
      "Epoch 1733/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5123 - val_loss: 6.5440\n",
      "Epoch 1734/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5122 - val_loss: 6.5436\n",
      "Epoch 1735/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5119 - val_loss: 6.5438\n",
      "Epoch 1736/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5118 - val_loss: 6.5434\n",
      "Epoch 1737/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5115 - val_loss: 6.5467\n",
      "Epoch 1738/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5113 - val_loss: 6.5425\n",
      "Epoch 1739/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5112 - val_loss: 6.5432\n",
      "Epoch 1740/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5110 - val_loss: 6.5434\n",
      "Epoch 1741/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5108 - val_loss: 6.5423\n",
      "Epoch 1742/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5107 - val_loss: 6.5424\n",
      "Epoch 1743/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5106 - val_loss: 6.5420\n",
      "Epoch 1744/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5103 - val_loss: 6.5417\n",
      "Epoch 1745/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5102 - val_loss: 6.5429\n",
      "Epoch 1746/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5100 - val_loss: 6.5410\n",
      "Epoch 1747/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5098 - val_loss: 6.5420\n",
      "Epoch 1748/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5096 - val_loss: 6.5415\n",
      "Epoch 1749/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5095 - val_loss: 6.5405\n",
      "Epoch 1750/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5092 - val_loss: 6.5413\n",
      "Epoch 1751/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5091 - val_loss: 6.5426\n",
      "Epoch 1752/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5089 - val_loss: 6.5402\n",
      "Epoch 1753/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.5088 - val_loss: 6.5397\n",
      "Epoch 1754/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5086 - val_loss: 6.5402\n",
      "Epoch 1755/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5085 - val_loss: 6.5399\n",
      "Epoch 1756/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5081 - val_loss: 6.5402\n",
      "Epoch 1757/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5081 - val_loss: 6.5403\n",
      "Epoch 1758/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5079 - val_loss: 6.5390\n",
      "Epoch 1759/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5078 - val_loss: 6.5390\n",
      "Epoch 1760/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5076 - val_loss: 6.5389\n",
      "Epoch 1761/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.5074 - val_loss: 6.5383\n",
      "Epoch 1762/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5072 - val_loss: 6.5391\n",
      "Epoch 1763/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5070 - val_loss: 6.5382\n",
      "Epoch 1764/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5068 - val_loss: 6.5380\n",
      "Epoch 1765/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5066 - val_loss: 6.5404\n",
      "Epoch 1766/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5064 - val_loss: 6.5383\n",
      "Epoch 1767/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5064 - val_loss: 6.5394\n",
      "Epoch 1768/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5061 - val_loss: 6.5376\n",
      "Epoch 1769/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5059 - val_loss: 6.5372\n",
      "Epoch 1770/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5058 - val_loss: 6.5375\n",
      "Epoch 1771/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5056 - val_loss: 6.5374\n",
      "Epoch 1772/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5054 - val_loss: 6.5375\n",
      "Epoch 1773/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5053 - val_loss: 6.5385\n",
      "Epoch 1774/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5050 - val_loss: 6.5360\n",
      "Epoch 1775/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5048 - val_loss: 6.5360\n",
      "Epoch 1776/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5048 - val_loss: 6.5366\n",
      "Epoch 1777/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5046 - val_loss: 6.5373\n",
      "Epoch 1778/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5045 - val_loss: 6.5378\n",
      "Epoch 1779/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5043 - val_loss: 6.5359\n",
      "Epoch 1780/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5041 - val_loss: 6.5381\n",
      "Epoch 1781/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.5039 - val_loss: 6.5347\n",
      "Epoch 1782/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5038 - val_loss: 6.5346\n",
      "Epoch 1783/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5035 - val_loss: 6.5350\n",
      "Epoch 1784/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5034 - val_loss: 6.5343\n",
      "Epoch 1785/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5032 - val_loss: 6.5348\n",
      "Epoch 1786/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5031 - val_loss: 6.5344\n",
      "Epoch 1787/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5029 - val_loss: 6.5344\n",
      "Epoch 1788/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5028 - val_loss: 6.5342\n",
      "Epoch 1789/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 6.5025 - val_loss: 6.5333\n",
      "Epoch 1790/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5023 - val_loss: 6.5331\n",
      "Epoch 1791/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5022 - val_loss: 6.5335\n",
      "Epoch 1792/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 6.5020 - val_loss: 6.5331\n",
      "Epoch 1793/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5019 - val_loss: 6.5329\n",
      "Epoch 1794/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.5016 - val_loss: 6.5343\n",
      "Epoch 1795/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5017 - val_loss: 6.5335\n",
      "Epoch 1796/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5014 - val_loss: 6.5324\n",
      "Epoch 1797/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5011 - val_loss: 6.5335\n",
      "Epoch 1798/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.5011 - val_loss: 6.5321\n",
      "Epoch 1799/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5009 - val_loss: 6.5368\n",
      "Epoch 1800/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5008 - val_loss: 6.5319\n",
      "Epoch 1801/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5005 - val_loss: 6.5313\n",
      "Epoch 1802/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5004 - val_loss: 6.5330\n",
      "Epoch 1803/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.5001 - val_loss: 6.5316\n",
      "Epoch 1804/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.5000 - val_loss: 6.5352\n",
      "Epoch 1805/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4998 - val_loss: 6.5321\n",
      "Epoch 1806/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4997 - val_loss: 6.5325\n",
      "Epoch 1807/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4995 - val_loss: 6.5306\n",
      "Epoch 1808/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.4993 - val_loss: 6.5317\n",
      "Epoch 1809/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.4992 - val_loss: 6.5300\n",
      "Epoch 1810/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4990 - val_loss: 6.5302\n",
      "Epoch 1811/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4988 - val_loss: 6.5319\n",
      "Epoch 1812/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4986 - val_loss: 6.5304\n",
      "Epoch 1813/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4985 - val_loss: 6.5304\n",
      "Epoch 1814/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4984 - val_loss: 6.5295\n",
      "Epoch 1815/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4982 - val_loss: 6.5290\n",
      "Epoch 1816/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4981 - val_loss: 6.5288\n",
      "Epoch 1817/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4978 - val_loss: 6.5291\n",
      "Epoch 1818/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4977 - val_loss: 6.5289\n",
      "Epoch 1819/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4976 - val_loss: 6.5303\n",
      "Epoch 1820/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4973 - val_loss: 6.5325\n",
      "Epoch 1821/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4972 - val_loss: 6.5318\n",
      "Epoch 1822/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4970 - val_loss: 6.5284\n",
      "Epoch 1823/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4969 - val_loss: 6.5284\n",
      "Epoch 1824/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4967 - val_loss: 6.5290\n",
      "Epoch 1825/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4966 - val_loss: 6.5277\n",
      "Epoch 1826/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4965 - val_loss: 6.5271\n",
      "Epoch 1827/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4962 - val_loss: 6.5281\n",
      "Epoch 1828/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4961 - val_loss: 6.5271\n",
      "Epoch 1829/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4958 - val_loss: 6.5270\n",
      "Epoch 1830/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4958 - val_loss: 6.5278\n",
      "Epoch 1831/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4956 - val_loss: 6.5264\n",
      "Epoch 1832/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4954 - val_loss: 6.5267\n",
      "Epoch 1833/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4952 - val_loss: 6.5260\n",
      "Epoch 1834/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4950 - val_loss: 6.5266\n",
      "Epoch 1835/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4950 - val_loss: 6.5259\n",
      "Epoch 1836/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4948 - val_loss: 6.5267\n",
      "Epoch 1837/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4946 - val_loss: 6.5282\n",
      "Epoch 1838/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4944 - val_loss: 6.5264\n",
      "Epoch 1839/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4942 - val_loss: 6.5257\n",
      "Epoch 1840/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4942 - val_loss: 6.5252\n",
      "Epoch 1841/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4939 - val_loss: 6.5255\n",
      "Epoch 1842/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4938 - val_loss: 6.5258\n",
      "Epoch 1843/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4936 - val_loss: 6.5249\n",
      "Epoch 1844/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4935 - val_loss: 6.5245\n",
      "Epoch 1845/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4933 - val_loss: 6.5247\n",
      "Epoch 1846/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4932 - val_loss: 6.5239\n",
      "Epoch 1847/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4931 - val_loss: 6.5241\n",
      "Epoch 1848/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4928 - val_loss: 6.5246\n",
      "Epoch 1849/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.4926 - val_loss: 6.5250\n",
      "Epoch 1850/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4925 - val_loss: 6.5255\n",
      "Epoch 1851/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4924 - val_loss: 6.5230\n",
      "Epoch 1852/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4922 - val_loss: 6.5234\n",
      "Epoch 1853/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4920 - val_loss: 6.5259\n",
      "Epoch 1854/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4919 - val_loss: 6.5226\n",
      "Epoch 1855/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4917 - val_loss: 6.5239\n",
      "Epoch 1856/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4916 - val_loss: 6.5237\n",
      "Epoch 1857/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4914 - val_loss: 6.5224\n",
      "Epoch 1858/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4913 - val_loss: 6.5219\n",
      "Epoch 1859/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4911 - val_loss: 6.5216\n",
      "Epoch 1860/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4909 - val_loss: 6.5222\n",
      "Epoch 1861/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.4907 - val_loss: 6.5219\n",
      "Epoch 1862/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4906 - val_loss: 6.5217\n",
      "Epoch 1863/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4905 - val_loss: 6.5241\n",
      "Epoch 1864/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4902 - val_loss: 6.5207\n",
      "Epoch 1865/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4902 - val_loss: 6.5205\n",
      "Epoch 1866/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4900 - val_loss: 6.5217\n",
      "Epoch 1867/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4898 - val_loss: 6.5208\n",
      "Epoch 1868/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4896 - val_loss: 6.5201\n",
      "Epoch 1869/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4895 - val_loss: 6.5228\n",
      "Epoch 1870/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4894 - val_loss: 6.5210\n",
      "Epoch 1871/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4892 - val_loss: 6.5196\n",
      "Epoch 1872/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4890 - val_loss: 6.5220\n",
      "Epoch 1873/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4889 - val_loss: 6.5201\n",
      "Epoch 1874/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4887 - val_loss: 6.5225\n",
      "Epoch 1875/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4886 - val_loss: 6.5221\n",
      "Epoch 1876/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4884 - val_loss: 6.5193\n",
      "Epoch 1877/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4882 - val_loss: 6.5196\n",
      "Epoch 1878/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4881 - val_loss: 6.5186\n",
      "Epoch 1879/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4879 - val_loss: 6.5186\n",
      "Epoch 1880/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4878 - val_loss: 6.5194\n",
      "Epoch 1881/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4876 - val_loss: 6.5182\n",
      "Epoch 1882/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4874 - val_loss: 6.5184\n",
      "Epoch 1883/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4874 - val_loss: 6.5184\n",
      "Epoch 1884/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4873 - val_loss: 6.5178\n",
      "Epoch 1885/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4870 - val_loss: 6.5180\n",
      "Epoch 1886/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4868 - val_loss: 6.5182\n",
      "Epoch 1887/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4867 - val_loss: 6.5175\n",
      "Epoch 1888/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4865 - val_loss: 6.5171\n",
      "Epoch 1889/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4864 - val_loss: 6.5171\n",
      "Epoch 1890/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4864 - val_loss: 6.5167\n",
      "Epoch 1891/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4861 - val_loss: 6.5166\n",
      "Epoch 1892/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4858 - val_loss: 6.5169\n",
      "Epoch 1893/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4857 - val_loss: 6.5174\n",
      "Epoch 1894/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4857 - val_loss: 6.5162\n",
      "Epoch 1895/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4855 - val_loss: 6.5165\n",
      "Epoch 1896/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4854 - val_loss: 6.5168\n",
      "Epoch 1897/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4851 - val_loss: 6.5200\n",
      "Epoch 1898/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4850 - val_loss: 6.5156\n",
      "Epoch 1899/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4848 - val_loss: 6.5157\n",
      "Epoch 1900/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4847 - val_loss: 6.5155\n",
      "Epoch 1901/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4846 - val_loss: 6.5153\n",
      "Epoch 1902/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4844 - val_loss: 6.5152\n",
      "Epoch 1903/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4842 - val_loss: 6.5153\n",
      "Epoch 1904/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4840 - val_loss: 6.5152\n",
      "Epoch 1905/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4839 - val_loss: 6.5161\n",
      "Epoch 1906/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4838 - val_loss: 6.5164\n",
      "Epoch 1907/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4836 - val_loss: 6.5141\n",
      "Epoch 1908/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4835 - val_loss: 6.5141\n",
      "Epoch 1909/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4833 - val_loss: 6.5164\n",
      "Epoch 1910/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4832 - val_loss: 6.5165\n",
      "Epoch 1911/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4831 - val_loss: 6.5147\n",
      "Epoch 1912/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4829 - val_loss: 6.5162\n",
      "Epoch 1913/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4828 - val_loss: 6.5138\n",
      "Epoch 1914/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4827 - val_loss: 6.5137\n",
      "Epoch 1915/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4824 - val_loss: 6.5129\n",
      "Epoch 1916/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4822 - val_loss: 6.5144\n",
      "Epoch 1917/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4821 - val_loss: 6.5129\n",
      "Epoch 1918/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4819 - val_loss: 6.5128\n",
      "Epoch 1919/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4819 - val_loss: 6.5132\n",
      "Epoch 1920/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4816 - val_loss: 6.5121\n",
      "Epoch 1921/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4816 - val_loss: 6.5191\n",
      "Epoch 1922/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4815 - val_loss: 6.5125\n",
      "Epoch 1923/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4813 - val_loss: 6.5130\n",
      "Epoch 1924/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4811 - val_loss: 6.5128\n",
      "Epoch 1925/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4809 - val_loss: 6.5178\n",
      "Epoch 1926/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4808 - val_loss: 6.5137\n",
      "Epoch 1927/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4807 - val_loss: 6.5117\n",
      "Epoch 1928/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4805 - val_loss: 6.5117\n",
      "Epoch 1929/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4803 - val_loss: 6.5113\n",
      "Epoch 1930/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4802 - val_loss: 6.5119\n",
      "Epoch 1931/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4800 - val_loss: 6.5104\n",
      "Epoch 1932/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4799 - val_loss: 6.5137\n",
      "Epoch 1933/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4798 - val_loss: 6.5106\n",
      "Epoch 1934/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4795 - val_loss: 6.5124\n",
      "Epoch 1935/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4794 - val_loss: 6.5108\n",
      "Epoch 1936/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4793 - val_loss: 6.5101\n",
      "Epoch 1937/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4792 - val_loss: 6.5095\n",
      "Epoch 1938/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4790 - val_loss: 6.5101\n",
      "Epoch 1939/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4789 - val_loss: 6.5093\n",
      "Epoch 1940/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4787 - val_loss: 6.5092\n",
      "Epoch 1941/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4786 - val_loss: 6.5090\n",
      "Epoch 1942/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4784 - val_loss: 6.5089\n",
      "Epoch 1943/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4783 - val_loss: 6.5088\n",
      "Epoch 1944/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4782 - val_loss: 6.5087\n",
      "Epoch 1945/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4781 - val_loss: 6.5084\n",
      "Epoch 1946/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4778 - val_loss: 6.5084\n",
      "Epoch 1947/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4776 - val_loss: 6.5080\n",
      "Epoch 1948/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4775 - val_loss: 6.5082\n",
      "Epoch 1949/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4774 - val_loss: 6.5077\n",
      "Epoch 1950/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4774 - val_loss: 6.5078\n",
      "Epoch 1951/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4771 - val_loss: 6.5078\n",
      "Epoch 1952/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4770 - val_loss: 6.5077\n",
      "Epoch 1953/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4768 - val_loss: 6.5075\n",
      "Epoch 1954/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4767 - val_loss: 6.5074\n",
      "Epoch 1955/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4765 - val_loss: 6.5082\n",
      "Epoch 1956/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4764 - val_loss: 6.5067\n",
      "Epoch 1957/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4763 - val_loss: 6.5065\n",
      "Epoch 1958/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4762 - val_loss: 6.5062\n",
      "Epoch 1959/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4759 - val_loss: 6.5076\n",
      "Epoch 1960/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4758 - val_loss: 6.5061\n",
      "Epoch 1961/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4757 - val_loss: 6.5063\n",
      "Epoch 1962/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4755 - val_loss: 6.5056\n",
      "Epoch 1963/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4754 - val_loss: 6.5069\n",
      "Epoch 1964/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4752 - val_loss: 6.5053\n",
      "Epoch 1965/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4751 - val_loss: 6.5052\n",
      "Epoch 1966/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4750 - val_loss: 6.5058\n",
      "Epoch 1967/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4748 - val_loss: 6.5056\n",
      "Epoch 1968/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4746 - val_loss: 6.5079\n",
      "Epoch 1969/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4746 - val_loss: 6.5046\n",
      "Epoch 1970/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4743 - val_loss: 6.5058\n",
      "Epoch 1971/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4742 - val_loss: 6.5051\n",
      "Epoch 1972/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4740 - val_loss: 6.5053\n",
      "Epoch 1973/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4739 - val_loss: 6.5040\n",
      "Epoch 1974/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4738 - val_loss: 6.5042\n",
      "Epoch 1975/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4736 - val_loss: 6.5043\n",
      "Epoch 1976/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4735 - val_loss: 6.5048\n",
      "Epoch 1977/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4735 - val_loss: 6.5034\n",
      "Epoch 1978/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4732 - val_loss: 6.5054\n",
      "Epoch 1979/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4731 - val_loss: 6.5047\n",
      "Epoch 1980/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4729 - val_loss: 6.5036\n",
      "Epoch 1981/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4728 - val_loss: 6.5067\n",
      "Epoch 1982/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4726 - val_loss: 6.5033\n",
      "Epoch 1983/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4724 - val_loss: 6.5027\n",
      "Epoch 1984/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4725 - val_loss: 6.5028\n",
      "Epoch 1985/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4722 - val_loss: 6.5023\n",
      "Epoch 1986/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4721 - val_loss: 6.5024\n",
      "Epoch 1987/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4719 - val_loss: 6.5026\n",
      "Epoch 1988/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4718 - val_loss: 6.5017\n",
      "Epoch 1989/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4716 - val_loss: 6.5018\n",
      "Epoch 1990/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4716 - val_loss: 6.5018\n",
      "Epoch 1991/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4714 - val_loss: 6.5040\n",
      "Epoch 1992/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4713 - val_loss: 6.5012\n",
      "Epoch 1993/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4710 - val_loss: 6.5032\n",
      "Epoch 1994/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4710 - val_loss: 6.5050\n",
      "Epoch 1995/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4709 - val_loss: 6.5010\n",
      "Epoch 1996/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4707 - val_loss: 6.5033\n",
      "Epoch 1997/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4705 - val_loss: 6.5041\n",
      "Epoch 1998/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4704 - val_loss: 6.5039\n",
      "Epoch 1999/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4702 - val_loss: 6.5020\n",
      "Epoch 2000/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4702 - val_loss: 6.5040\n",
      "Epoch 2001/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4700 - val_loss: 6.5003\n",
      "Epoch 2002/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4698 - val_loss: 6.5028\n",
      "Epoch 2003/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4697 - val_loss: 6.4997\n",
      "Epoch 2004/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4696 - val_loss: 6.5013\n",
      "Epoch 2005/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4694 - val_loss: 6.5003\n",
      "Epoch 2006/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4693 - val_loss: 6.5004\n",
      "Epoch 2007/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4692 - val_loss: 6.4997\n",
      "Epoch 2008/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4689 - val_loss: 6.4991\n",
      "Epoch 2009/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4688 - val_loss: 6.5001\n",
      "Epoch 2010/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4687 - val_loss: 6.4986\n",
      "Epoch 2011/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4686 - val_loss: 6.4989\n",
      "Epoch 2012/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4684 - val_loss: 6.4996\n",
      "Epoch 2013/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4683 - val_loss: 6.4987\n",
      "Epoch 2014/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4682 - val_loss: 6.4983\n",
      "Epoch 2015/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4681 - val_loss: 6.4983\n",
      "Epoch 2016/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4679 - val_loss: 6.4980\n",
      "Epoch 2017/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4678 - val_loss: 6.4983\n",
      "Epoch 2018/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4676 - val_loss: 6.5030\n",
      "Epoch 2019/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4675 - val_loss: 6.4982\n",
      "Epoch 2020/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4674 - val_loss: 6.4973\n",
      "Epoch 2021/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4673 - val_loss: 6.4981\n",
      "Epoch 2022/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4672 - val_loss: 6.4977\n",
      "Epoch 2023/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4669 - val_loss: 6.4998\n",
      "Epoch 2024/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4668 - val_loss: 6.4996\n",
      "Epoch 2025/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.4667 - val_loss: 6.4980\n",
      "Epoch 2026/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4665 - val_loss: 6.4973\n",
      "Epoch 2027/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4664 - val_loss: 6.4963\n",
      "Epoch 2028/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4663 - val_loss: 6.4979\n",
      "Epoch 2029/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4661 - val_loss: 6.4963\n",
      "Epoch 2030/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4661 - val_loss: 6.4987\n",
      "Epoch 2031/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4659 - val_loss: 6.4968\n",
      "Epoch 2032/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4658 - val_loss: 6.4972\n",
      "Epoch 2033/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4655 - val_loss: 6.4962\n",
      "Epoch 2034/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4655 - val_loss: 6.4995\n",
      "Epoch 2035/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4653 - val_loss: 6.4976\n",
      "Epoch 2036/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4652 - val_loss: 6.4951\n",
      "Epoch 2037/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4649 - val_loss: 6.4955\n",
      "Epoch 2038/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4650 - val_loss: 6.4969\n",
      "Epoch 2039/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4648 - val_loss: 6.4948\n",
      "Epoch 2040/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4646 - val_loss: 6.4950\n",
      "Epoch 2041/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4645 - val_loss: 6.4949\n",
      "Epoch 2042/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4643 - val_loss: 6.4944\n",
      "Epoch 2043/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4643 - val_loss: 6.4941\n",
      "Epoch 2044/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4641 - val_loss: 6.4945\n",
      "Epoch 2045/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4640 - val_loss: 6.4940\n",
      "Epoch 2046/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4639 - val_loss: 6.4941\n",
      "Epoch 2047/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4637 - val_loss: 6.4936\n",
      "Epoch 2048/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4636 - val_loss: 6.4964\n",
      "Epoch 2049/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4636 - val_loss: 6.4973\n",
      "Epoch 2050/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4633 - val_loss: 6.4949\n",
      "Epoch 2051/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4631 - val_loss: 6.4934\n",
      "Epoch 2052/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4631 - val_loss: 6.4937\n",
      "Epoch 2053/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4629 - val_loss: 6.4929\n",
      "Epoch 2054/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4627 - val_loss: 6.4946\n",
      "Epoch 2055/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4626 - val_loss: 6.4940\n",
      "Epoch 2056/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4625 - val_loss: 6.4923\n",
      "Epoch 2057/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4623 - val_loss: 6.4937\n",
      "Epoch 2058/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4623 - val_loss: 6.4925\n",
      "Epoch 2059/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4621 - val_loss: 6.4923\n",
      "Epoch 2060/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4619 - val_loss: 6.4954\n",
      "Epoch 2061/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4618 - val_loss: 6.4951\n",
      "Epoch 2062/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4618 - val_loss: 6.4919\n",
      "Epoch 2063/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4617 - val_loss: 6.4915\n",
      "Epoch 2064/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4614 - val_loss: 6.4936\n",
      "Epoch 2065/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4614 - val_loss: 6.4913\n",
      "Epoch 2066/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4612 - val_loss: 6.4910\n",
      "Epoch 2067/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4611 - val_loss: 6.4917\n",
      "Epoch 2068/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4609 - val_loss: 6.4916\n",
      "Epoch 2069/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4609 - val_loss: 6.4905\n",
      "Epoch 2070/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4607 - val_loss: 6.4905\n",
      "Epoch 2071/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4605 - val_loss: 6.4904\n",
      "Epoch 2072/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4604 - val_loss: 6.4903\n",
      "Epoch 2073/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4602 - val_loss: 6.4909\n",
      "Epoch 2074/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4602 - val_loss: 6.4905\n",
      "Epoch 2075/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4600 - val_loss: 6.4902\n",
      "Epoch 2076/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4598 - val_loss: 6.4897\n",
      "Epoch 2077/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4597 - val_loss: 6.4899\n",
      "Epoch 2078/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4596 - val_loss: 6.4895\n",
      "Epoch 2079/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4596 - val_loss: 6.4897\n",
      "Epoch 2080/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4593 - val_loss: 6.4898\n",
      "Epoch 2081/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4592 - val_loss: 6.4898\n",
      "Epoch 2082/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4591 - val_loss: 6.4893\n",
      "Epoch 2083/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4590 - val_loss: 6.4906\n",
      "Epoch 2084/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4588 - val_loss: 6.4889\n",
      "Epoch 2085/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4587 - val_loss: 6.4888\n",
      "Epoch 2086/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4586 - val_loss: 6.4887\n",
      "Epoch 2087/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4584 - val_loss: 6.4889\n",
      "Epoch 2088/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4583 - val_loss: 6.4882\n",
      "Epoch 2089/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4581 - val_loss: 6.4895\n",
      "Epoch 2090/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4581 - val_loss: 6.4877\n",
      "Epoch 2091/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4579 - val_loss: 6.4921\n",
      "Epoch 2092/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4579 - val_loss: 6.4899\n",
      "Epoch 2093/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4577 - val_loss: 6.4875\n",
      "Epoch 2094/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4575 - val_loss: 6.4875\n",
      "Epoch 2095/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4573 - val_loss: 6.4892\n",
      "Epoch 2096/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4572 - val_loss: 6.4891\n",
      "Epoch 2097/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4572 - val_loss: 6.4875\n",
      "Epoch 2098/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4570 - val_loss: 6.4892\n",
      "Epoch 2099/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4569 - val_loss: 6.4879\n",
      "Epoch 2100/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4567 - val_loss: 6.4863\n",
      "Epoch 2101/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4567 - val_loss: 6.4862\n",
      "Epoch 2102/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4565 - val_loss: 6.4874\n",
      "Epoch 2103/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4563 - val_loss: 6.4886\n",
      "Epoch 2104/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4563 - val_loss: 6.4858\n",
      "Epoch 2105/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4561 - val_loss: 6.4883\n",
      "Epoch 2106/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4560 - val_loss: 6.4856\n",
      "Epoch 2107/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4559 - val_loss: 6.4862\n",
      "Epoch 2108/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4558 - val_loss: 6.4861\n",
      "Epoch 2109/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4555 - val_loss: 6.4871\n",
      "Epoch 2110/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4554 - val_loss: 6.4876\n",
      "Epoch 2111/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4554 - val_loss: 6.4857\n",
      "Epoch 2112/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4552 - val_loss: 6.4860\n",
      "Epoch 2113/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4552 - val_loss: 6.4848\n",
      "Epoch 2114/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4550 - val_loss: 6.4863\n",
      "Epoch 2115/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4548 - val_loss: 6.4890\n",
      "Epoch 2116/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4547 - val_loss: 6.4858\n",
      "Epoch 2117/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4546 - val_loss: 6.4843\n",
      "Epoch 2118/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4544 - val_loss: 6.4850\n",
      "Epoch 2119/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.4543 - val_loss: 6.4841\n",
      "Epoch 2120/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4542 - val_loss: 6.4863\n",
      "Epoch 2121/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4541 - val_loss: 6.4853\n",
      "Epoch 2122/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4540 - val_loss: 6.4842\n",
      "Epoch 2123/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4538 - val_loss: 6.4854\n",
      "Epoch 2124/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4536 - val_loss: 6.4837\n",
      "Epoch 2125/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4536 - val_loss: 6.4855\n",
      "Epoch 2126/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4534 - val_loss: 6.4836\n",
      "Epoch 2127/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4534 - val_loss: 6.4829\n",
      "Epoch 2128/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4532 - val_loss: 6.4840\n",
      "Epoch 2129/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4532 - val_loss: 6.4859\n",
      "Epoch 2130/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4530 - val_loss: 6.4855\n",
      "Epoch 2131/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4529 - val_loss: 6.4834\n",
      "Epoch 2132/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4527 - val_loss: 6.4833\n",
      "Epoch 2133/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4526 - val_loss: 6.4839\n",
      "Epoch 2134/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4525 - val_loss: 6.4822\n",
      "Epoch 2135/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4524 - val_loss: 6.4825\n",
      "Epoch 2136/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4523 - val_loss: 6.4826\n",
      "Epoch 2137/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4521 - val_loss: 6.4816\n",
      "Epoch 2138/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4519 - val_loss: 6.4815\n",
      "Epoch 2139/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4519 - val_loss: 6.4828\n",
      "Epoch 2140/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4518 - val_loss: 6.4812\n",
      "Epoch 2141/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4516 - val_loss: 6.4815\n",
      "Epoch 2142/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4514 - val_loss: 6.4824\n",
      "Epoch 2143/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4513 - val_loss: 6.4841\n",
      "Epoch 2144/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4512 - val_loss: 6.4814\n",
      "Epoch 2145/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4511 - val_loss: 6.4825\n",
      "Epoch 2146/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4509 - val_loss: 6.4814\n",
      "Epoch 2147/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4508 - val_loss: 6.4807\n",
      "Epoch 2148/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4507 - val_loss: 6.4817\n",
      "Epoch 2149/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4506 - val_loss: 6.4818\n",
      "Epoch 2150/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4505 - val_loss: 6.4813\n",
      "Epoch 2151/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4504 - val_loss: 6.4834\n",
      "Epoch 2152/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4502 - val_loss: 6.4812\n",
      "Epoch 2153/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4501 - val_loss: 6.4799\n",
      "Epoch 2154/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4500 - val_loss: 6.4795\n",
      "Epoch 2155/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4499 - val_loss: 6.4817\n",
      "Epoch 2156/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4498 - val_loss: 6.4796\n",
      "Epoch 2157/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4496 - val_loss: 6.4791\n",
      "Epoch 2158/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4495 - val_loss: 6.4805\n",
      "Epoch 2159/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4494 - val_loss: 6.4798\n",
      "Epoch 2160/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4493 - val_loss: 6.4804\n",
      "Epoch 2161/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4492 - val_loss: 6.4787\n",
      "Epoch 2162/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4490 - val_loss: 6.4807\n",
      "Epoch 2163/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4490 - val_loss: 6.4783\n",
      "Epoch 2164/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4488 - val_loss: 6.4782\n",
      "Epoch 2165/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4486 - val_loss: 6.4794\n",
      "Epoch 2166/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4485 - val_loss: 6.4779\n",
      "Epoch 2167/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4484 - val_loss: 6.4781\n",
      "Epoch 2168/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4482 - val_loss: 6.4781\n",
      "Epoch 2169/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4481 - val_loss: 6.4784\n",
      "Epoch 2170/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4480 - val_loss: 6.4774\n",
      "Epoch 2171/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4479 - val_loss: 6.4776\n",
      "Epoch 2172/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4479 - val_loss: 6.4775\n",
      "Epoch 2173/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4477 - val_loss: 6.4772\n",
      "Epoch 2174/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4476 - val_loss: 6.4775\n",
      "Epoch 2175/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4475 - val_loss: 6.4771\n",
      "Epoch 2176/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4474 - val_loss: 6.4776\n",
      "Epoch 2177/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4472 - val_loss: 6.4772\n",
      "Epoch 2178/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4471 - val_loss: 6.4770\n",
      "Epoch 2179/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4470 - val_loss: 6.4805\n",
      "Epoch 2180/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4468 - val_loss: 6.4767\n",
      "Epoch 2181/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4467 - val_loss: 6.4760\n",
      "Epoch 2182/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4467 - val_loss: 6.4767\n",
      "Epoch 2183/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4465 - val_loss: 6.4769\n",
      "Epoch 2184/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4464 - val_loss: 6.4762\n",
      "Epoch 2185/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4462 - val_loss: 6.4757\n",
      "Epoch 2186/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4461 - val_loss: 6.4756\n",
      "Epoch 2187/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4461 - val_loss: 6.4754\n",
      "Epoch 2188/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4459 - val_loss: 6.4757\n",
      "Epoch 2189/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4457 - val_loss: 6.4752\n",
      "Epoch 2190/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4457 - val_loss: 6.4780\n",
      "Epoch 2191/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4455 - val_loss: 6.4758\n",
      "Epoch 2192/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4454 - val_loss: 6.4751\n",
      "Epoch 2193/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4453 - val_loss: 6.4763\n",
      "Epoch 2194/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4451 - val_loss: 6.4767\n",
      "Epoch 2195/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4451 - val_loss: 6.4748\n",
      "Epoch 2196/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4449 - val_loss: 6.4784\n",
      "Epoch 2197/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4449 - val_loss: 6.4744\n",
      "Epoch 2198/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4446 - val_loss: 6.4774\n",
      "Epoch 2199/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4445 - val_loss: 6.4744\n",
      "Epoch 2200/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4445 - val_loss: 6.4762\n",
      "Epoch 2201/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4444 - val_loss: 6.4743\n",
      "Epoch 2202/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4443 - val_loss: 6.4769\n",
      "Epoch 2203/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4441 - val_loss: 6.4739\n",
      "Epoch 2204/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4440 - val_loss: 6.4734\n",
      "Epoch 2205/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4439 - val_loss: 6.4744\n",
      "Epoch 2206/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4438 - val_loss: 6.4735\n",
      "Epoch 2207/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4436 - val_loss: 6.4752\n",
      "Epoch 2208/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4436 - val_loss: 6.4741\n",
      "Epoch 2209/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4434 - val_loss: 6.4730\n",
      "Epoch 2210/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4432 - val_loss: 6.4734\n",
      "Epoch 2211/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4432 - val_loss: 6.4743\n",
      "Epoch 2212/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4430 - val_loss: 6.4726\n",
      "Epoch 2213/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4431 - val_loss: 6.4724\n",
      "Epoch 2214/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4428 - val_loss: 6.4724\n",
      "Epoch 2215/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4427 - val_loss: 6.4721\n",
      "Epoch 2216/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4426 - val_loss: 6.4743\n",
      "Epoch 2217/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4426 - val_loss: 6.4764\n",
      "Epoch 2218/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4424 - val_loss: 6.4722\n",
      "Epoch 2219/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4422 - val_loss: 6.4717\n",
      "Epoch 2220/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4421 - val_loss: 6.4724\n",
      "Epoch 2221/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4420 - val_loss: 6.4720\n",
      "Epoch 2222/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4419 - val_loss: 6.4724\n",
      "Epoch 2223/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4418 - val_loss: 6.4710\n",
      "Epoch 2224/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4416 - val_loss: 6.4709\n",
      "Epoch 2225/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4415 - val_loss: 6.4731\n",
      "Epoch 2226/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4415 - val_loss: 6.4725\n",
      "Epoch 2227/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4413 - val_loss: 6.4711\n",
      "Epoch 2228/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4412 - val_loss: 6.4740\n",
      "Epoch 2229/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4411 - val_loss: 6.4718\n",
      "Epoch 2230/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4410 - val_loss: 6.4711\n",
      "Epoch 2231/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4408 - val_loss: 6.4706\n",
      "Epoch 2232/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4409 - val_loss: 6.4700\n",
      "Epoch 2233/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4407 - val_loss: 6.4701\n",
      "Epoch 2234/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4406 - val_loss: 6.4715\n",
      "Epoch 2235/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4405 - val_loss: 6.4698\n",
      "Epoch 2236/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4404 - val_loss: 6.4717\n",
      "Epoch 2237/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4402 - val_loss: 6.4703\n",
      "Epoch 2238/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4401 - val_loss: 6.4696\n",
      "Epoch 2239/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4399 - val_loss: 6.4698\n",
      "Epoch 2240/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4399 - val_loss: 6.4707\n",
      "Epoch 2241/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4397 - val_loss: 6.4696\n",
      "Epoch 2242/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4396 - val_loss: 6.4763\n",
      "Epoch 2243/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4395 - val_loss: 6.4707\n",
      "Epoch 2244/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4394 - val_loss: 6.4687\n",
      "Epoch 2245/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4393 - val_loss: 6.4699\n",
      "Epoch 2246/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4392 - val_loss: 6.4689\n",
      "Epoch 2247/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4391 - val_loss: 6.4714\n",
      "Epoch 2248/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4389 - val_loss: 6.4683\n",
      "Epoch 2249/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4389 - val_loss: 6.4706\n",
      "Epoch 2250/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4387 - val_loss: 6.4683\n",
      "Epoch 2251/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4386 - val_loss: 6.4681\n",
      "Epoch 2252/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4386 - val_loss: 6.4679\n",
      "Epoch 2253/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4384 - val_loss: 6.4689\n",
      "Epoch 2254/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4383 - val_loss: 6.4680\n",
      "Epoch 2255/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4382 - val_loss: 6.4678\n",
      "Epoch 2256/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4380 - val_loss: 6.4685\n",
      "Epoch 2257/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4379 - val_loss: 6.4669\n",
      "Epoch 2258/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4379 - val_loss: 6.4678\n",
      "Epoch 2259/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4377 - val_loss: 6.4704\n",
      "Epoch 2260/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4376 - val_loss: 6.4669\n",
      "Epoch 2261/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4375 - val_loss: 6.4706\n",
      "Epoch 2262/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4374 - val_loss: 6.4699\n",
      "Epoch 2263/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4372 - val_loss: 6.4705\n",
      "Epoch 2264/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4371 - val_loss: 6.4692\n",
      "Epoch 2265/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4371 - val_loss: 6.4665\n",
      "Epoch 2266/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4370 - val_loss: 6.4665\n",
      "Epoch 2267/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4368 - val_loss: 6.4666\n",
      "Epoch 2268/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4367 - val_loss: 6.4707\n",
      "Epoch 2269/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4366 - val_loss: 6.4662\n",
      "Epoch 2270/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4365 - val_loss: 6.4656\n",
      "Epoch 2271/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4364 - val_loss: 6.4664\n",
      "Epoch 2272/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4362 - val_loss: 6.4660\n",
      "Epoch 2273/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4362 - val_loss: 6.4665\n",
      "Epoch 2274/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4360 - val_loss: 6.4660\n",
      "Epoch 2275/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4359 - val_loss: 6.4652\n",
      "Epoch 2276/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4358 - val_loss: 6.4660\n",
      "Epoch 2277/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4358 - val_loss: 6.4664\n",
      "Epoch 2278/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4357 - val_loss: 6.4649\n",
      "Epoch 2279/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4354 - val_loss: 6.4650\n",
      "Epoch 2280/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4354 - val_loss: 6.4653\n",
      "Epoch 2281/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4353 - val_loss: 6.4648\n",
      "Epoch 2282/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4352 - val_loss: 6.4647\n",
      "Epoch 2283/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4351 - val_loss: 6.4640\n",
      "Epoch 2284/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4350 - val_loss: 6.4640\n",
      "Epoch 2285/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4348 - val_loss: 6.4684\n",
      "Epoch 2286/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4347 - val_loss: 6.4639\n",
      "Epoch 2287/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4346 - val_loss: 6.4639\n",
      "Epoch 2288/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4345 - val_loss: 6.4649\n",
      "Epoch 2289/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4344 - val_loss: 6.4637\n",
      "Epoch 2290/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4342 - val_loss: 6.4633\n",
      "Epoch 2291/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4342 - val_loss: 6.4652\n",
      "Epoch 2292/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4340 - val_loss: 6.4633\n",
      "Epoch 2293/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4340 - val_loss: 6.4635\n",
      "Epoch 2294/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4338 - val_loss: 6.4684\n",
      "Epoch 2295/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4338 - val_loss: 6.4638\n",
      "Epoch 2296/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4336 - val_loss: 6.4626\n",
      "Epoch 2297/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4335 - val_loss: 6.4632\n",
      "Epoch 2298/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4335 - val_loss: 6.4647\n",
      "Epoch 2299/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4332 - val_loss: 6.4633\n",
      "Epoch 2300/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4332 - val_loss: 6.4633\n",
      "Epoch 2301/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4331 - val_loss: 6.4625\n",
      "Epoch 2302/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4330 - val_loss: 6.4619\n",
      "Epoch 2303/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4329 - val_loss: 6.4620\n",
      "Epoch 2304/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4327 - val_loss: 6.4618\n",
      "Epoch 2305/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4326 - val_loss: 6.4617\n",
      "Epoch 2306/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4325 - val_loss: 6.4617\n",
      "Epoch 2307/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4324 - val_loss: 6.4614\n",
      "Epoch 2308/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4323 - val_loss: 6.4612\n",
      "Epoch 2309/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4322 - val_loss: 6.4613\n",
      "Epoch 2310/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4321 - val_loss: 6.4612\n",
      "Epoch 2311/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4320 - val_loss: 6.4610\n",
      "Epoch 2312/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4319 - val_loss: 6.4645\n",
      "Epoch 2313/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4318 - val_loss: 6.4638\n",
      "Epoch 2314/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4317 - val_loss: 6.4637\n",
      "Epoch 2315/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4316 - val_loss: 6.4606\n",
      "Epoch 2316/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4315 - val_loss: 6.4616\n",
      "Epoch 2317/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4314 - val_loss: 6.4605\n",
      "Epoch 2318/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4312 - val_loss: 6.4608\n",
      "Epoch 2319/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4311 - val_loss: 6.4602\n",
      "Epoch 2320/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4310 - val_loss: 6.4639\n",
      "Epoch 2321/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4310 - val_loss: 6.4612\n",
      "Epoch 2322/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4308 - val_loss: 6.4630\n",
      "Epoch 2323/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4306 - val_loss: 6.4617\n",
      "Epoch 2324/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4307 - val_loss: 6.4609\n",
      "Epoch 2325/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4306 - val_loss: 6.4596\n",
      "Epoch 2326/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4304 - val_loss: 6.4601\n",
      "Epoch 2327/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4303 - val_loss: 6.4591\n",
      "Epoch 2328/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4302 - val_loss: 6.4592\n",
      "Epoch 2329/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4300 - val_loss: 6.4607\n",
      "Epoch 2330/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4299 - val_loss: 6.4601\n",
      "Epoch 2331/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4298 - val_loss: 6.4589\n",
      "Epoch 2332/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4297 - val_loss: 6.4601\n",
      "Epoch 2333/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4296 - val_loss: 6.4586\n",
      "Epoch 2334/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4297 - val_loss: 6.4584\n",
      "Epoch 2335/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4294 - val_loss: 6.4584\n",
      "Epoch 2336/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4293 - val_loss: 6.4584\n",
      "Epoch 2337/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4291 - val_loss: 6.4606\n",
      "Epoch 2338/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4291 - val_loss: 6.4579\n",
      "Epoch 2339/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4290 - val_loss: 6.4585\n",
      "Epoch 2340/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4290 - val_loss: 6.4619\n",
      "Epoch 2341/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4288 - val_loss: 6.4584\n",
      "Epoch 2342/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4287 - val_loss: 6.4580\n",
      "Epoch 2343/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4286 - val_loss: 6.4581\n",
      "Epoch 2344/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4285 - val_loss: 6.4583\n",
      "Epoch 2345/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4284 - val_loss: 6.4585\n",
      "Epoch 2346/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4282 - val_loss: 6.4571\n",
      "Epoch 2347/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4282 - val_loss: 6.4578\n",
      "Epoch 2348/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4281 - val_loss: 6.4574\n",
      "Epoch 2349/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4280 - val_loss: 6.4569\n",
      "Epoch 2350/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4280 - val_loss: 6.4577\n",
      "Epoch 2351/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4278 - val_loss: 6.4590\n",
      "Epoch 2352/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4276 - val_loss: 6.4586\n",
      "Epoch 2353/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4275 - val_loss: 6.4568\n",
      "Epoch 2354/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4275 - val_loss: 6.4568\n",
      "Epoch 2355/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4275 - val_loss: 6.4568\n",
      "Epoch 2356/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4272 - val_loss: 6.4561\n",
      "Epoch 2357/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4271 - val_loss: 6.4564\n",
      "Epoch 2358/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4270 - val_loss: 6.4561\n",
      "Epoch 2359/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4269 - val_loss: 6.4557\n",
      "Epoch 2360/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4268 - val_loss: 6.4578\n",
      "Epoch 2361/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4266 - val_loss: 6.4614\n",
      "Epoch 2362/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4267 - val_loss: 6.4556\n",
      "Epoch 2363/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4265 - val_loss: 6.4553\n",
      "Epoch 2364/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4263 - val_loss: 6.4574\n",
      "Epoch 2365/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4263 - val_loss: 6.4550\n",
      "Epoch 2366/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4262 - val_loss: 6.4551\n",
      "Epoch 2367/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4260 - val_loss: 6.4565\n",
      "Epoch 2368/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4260 - val_loss: 6.4559\n",
      "Epoch 2369/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4260 - val_loss: 6.4569\n",
      "Epoch 2370/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4257 - val_loss: 6.4556\n",
      "Epoch 2371/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4257 - val_loss: 6.4550\n",
      "Epoch 2372/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4256 - val_loss: 6.4551\n",
      "Epoch 2373/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4254 - val_loss: 6.4548\n",
      "Epoch 2374/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.4254 - val_loss: 6.4552\n",
      "Epoch 2375/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4253 - val_loss: 6.4576\n",
      "Epoch 2376/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4252 - val_loss: 6.4540\n",
      "Epoch 2377/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4250 - val_loss: 6.4540\n",
      "Epoch 2378/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4249 - val_loss: 6.4539\n",
      "Epoch 2379/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4248 - val_loss: 6.4536\n",
      "Epoch 2380/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4248 - val_loss: 6.4544\n",
      "Epoch 2381/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4247 - val_loss: 6.4533\n",
      "Epoch 2382/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4246 - val_loss: 6.4538\n",
      "Epoch 2383/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4244 - val_loss: 6.4533\n",
      "Epoch 2384/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4244 - val_loss: 6.4532\n",
      "Epoch 2385/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4242 - val_loss: 6.4544\n",
      "Epoch 2386/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4242 - val_loss: 6.4530\n",
      "Epoch 2387/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4240 - val_loss: 6.4528\n",
      "Epoch 2388/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4239 - val_loss: 6.4528\n",
      "Epoch 2389/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4239 - val_loss: 6.4526\n",
      "Epoch 2390/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4237 - val_loss: 6.4540\n",
      "Epoch 2391/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4237 - val_loss: 6.4538\n",
      "Epoch 2392/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4236 - val_loss: 6.4523\n",
      "Epoch 2393/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4235 - val_loss: 6.4523\n",
      "Epoch 2394/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4233 - val_loss: 6.4570\n",
      "Epoch 2395/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4232 - val_loss: 6.4530\n",
      "Epoch 2396/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4231 - val_loss: 6.4518\n",
      "Epoch 2397/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4231 - val_loss: 6.4524\n",
      "Epoch 2398/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4229 - val_loss: 6.4524\n",
      "Epoch 2399/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4229 - val_loss: 6.4518\n",
      "Epoch 2400/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4228 - val_loss: 6.4519\n",
      "Epoch 2401/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4226 - val_loss: 6.4521\n",
      "Epoch 2402/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4225 - val_loss: 6.4533\n",
      "Epoch 2403/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4224 - val_loss: 6.4513\n",
      "Epoch 2404/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4224 - val_loss: 6.4511\n",
      "Epoch 2405/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4222 - val_loss: 6.4532\n",
      "Epoch 2406/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4221 - val_loss: 6.4515\n",
      "Epoch 2407/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4220 - val_loss: 6.4512\n",
      "Epoch 2408/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4219 - val_loss: 6.4505\n",
      "Epoch 2409/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4218 - val_loss: 6.4523\n",
      "Epoch 2410/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4217 - val_loss: 6.4507\n",
      "Epoch 2411/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4216 - val_loss: 6.4516\n",
      "Epoch 2412/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4214 - val_loss: 6.4508\n",
      "Epoch 2413/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4214 - val_loss: 6.4501\n",
      "Epoch 2414/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4213 - val_loss: 6.4520\n",
      "Epoch 2415/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4213 - val_loss: 6.4501\n",
      "Epoch 2416/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4212 - val_loss: 6.4501\n",
      "Epoch 2417/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4210 - val_loss: 6.4508\n",
      "Epoch 2418/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4209 - val_loss: 6.4508\n",
      "Epoch 2419/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4209 - val_loss: 6.4508\n",
      "Epoch 2420/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4208 - val_loss: 6.4544\n",
      "Epoch 2421/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4206 - val_loss: 6.4493\n",
      "Epoch 2422/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4205 - val_loss: 6.4491\n",
      "Epoch 2423/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4204 - val_loss: 6.4521\n",
      "Epoch 2424/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4204 - val_loss: 6.4489\n",
      "Epoch 2425/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4202 - val_loss: 6.4492\n",
      "Epoch 2426/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4201 - val_loss: 6.4509\n",
      "Epoch 2427/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4200 - val_loss: 6.4495\n",
      "Epoch 2428/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4199 - val_loss: 6.4495\n",
      "Epoch 2429/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4198 - val_loss: 6.4521\n",
      "Epoch 2430/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4198 - val_loss: 6.4499\n",
      "Epoch 2431/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4196 - val_loss: 6.4501\n",
      "Epoch 2432/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4196 - val_loss: 6.4484\n",
      "Epoch 2433/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4195 - val_loss: 6.4480\n",
      "Epoch 2434/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4193 - val_loss: 6.4482\n",
      "Epoch 2435/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4192 - val_loss: 6.4489\n",
      "Epoch 2436/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4192 - val_loss: 6.4478\n",
      "Epoch 2437/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4190 - val_loss: 6.4476\n",
      "Epoch 2438/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4190 - val_loss: 6.4488\n",
      "Epoch 2439/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4188 - val_loss: 6.4551\n",
      "Epoch 2440/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4187 - val_loss: 6.4474\n",
      "Epoch 2441/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4187 - val_loss: 6.4476\n",
      "Epoch 2442/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4186 - val_loss: 6.4473\n",
      "Epoch 2443/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4185 - val_loss: 6.4491\n",
      "Epoch 2444/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4184 - val_loss: 6.4487\n",
      "Epoch 2445/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4183 - val_loss: 6.4474\n",
      "Epoch 2446/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4181 - val_loss: 6.4471\n",
      "Epoch 2447/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4181 - val_loss: 6.4475\n",
      "Epoch 2448/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.4180 - val_loss: 6.4466\n",
      "Epoch 2449/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4178 - val_loss: 6.4484\n",
      "Epoch 2450/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4178 - val_loss: 6.4485\n",
      "Epoch 2451/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4177 - val_loss: 6.4463\n",
      "Epoch 2452/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4175 - val_loss: 6.4462\n",
      "Epoch 2453/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4175 - val_loss: 6.4472\n",
      "Epoch 2454/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4174 - val_loss: 6.4462\n",
      "Epoch 2455/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4174 - val_loss: 6.4461\n",
      "Epoch 2456/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4173 - val_loss: 6.4489\n",
      "Epoch 2457/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4171 - val_loss: 6.4466\n",
      "Epoch 2458/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4171 - val_loss: 6.4458\n",
      "Epoch 2459/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4170 - val_loss: 6.4460\n",
      "Epoch 2460/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4168 - val_loss: 6.4468\n",
      "Epoch 2461/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4167 - val_loss: 6.4473\n",
      "Epoch 2462/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4166 - val_loss: 6.4474\n",
      "Epoch 2463/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4165 - val_loss: 6.4453\n",
      "Epoch 2464/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4165 - val_loss: 6.4492\n",
      "Epoch 2465/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4164 - val_loss: 6.4459\n",
      "Epoch 2466/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4162 - val_loss: 6.4464\n",
      "Epoch 2467/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4162 - val_loss: 6.4454\n",
      "Epoch 2468/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4160 - val_loss: 6.4450\n",
      "Epoch 2469/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4160 - val_loss: 6.4446\n",
      "Epoch 2470/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4159 - val_loss: 6.4455\n",
      "Epoch 2471/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4157 - val_loss: 6.4446\n",
      "Epoch 2472/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 6.4156 - val_loss: 6.4445\n",
      "Epoch 2473/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4156 - val_loss: 6.4446\n",
      "Epoch 2474/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4155 - val_loss: 6.4449\n",
      "Epoch 2475/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4154 - val_loss: 6.4458\n",
      "Epoch 2476/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4153 - val_loss: 6.4452\n",
      "Epoch 2477/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4152 - val_loss: 6.4448\n",
      "Epoch 2478/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4151 - val_loss: 6.4460\n",
      "Epoch 2479/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4150 - val_loss: 6.4442\n",
      "Epoch 2480/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4149 - val_loss: 6.4458\n",
      "Epoch 2481/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4149 - val_loss: 6.4461\n",
      "Epoch 2482/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4147 - val_loss: 6.4432\n",
      "Epoch 2483/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4146 - val_loss: 6.4433\n",
      "Epoch 2484/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4145 - val_loss: 6.4434\n",
      "Epoch 2485/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4145 - val_loss: 6.4433\n",
      "Epoch 2486/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4143 - val_loss: 6.4431\n",
      "Epoch 2487/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4143 - val_loss: 6.4442\n",
      "Epoch 2488/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4141 - val_loss: 6.4430\n",
      "Epoch 2489/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4141 - val_loss: 6.4448\n",
      "Epoch 2490/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4140 - val_loss: 6.4433\n",
      "Epoch 2491/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4139 - val_loss: 6.4429\n",
      "Epoch 2492/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4137 - val_loss: 6.4439\n",
      "Epoch 2493/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4137 - val_loss: 6.4424\n",
      "Epoch 2494/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4137 - val_loss: 6.4429\n",
      "Epoch 2495/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4135 - val_loss: 6.4433\n",
      "Epoch 2496/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4134 - val_loss: 6.4420\n",
      "Epoch 2497/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4133 - val_loss: 6.4421\n",
      "Epoch 2498/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4132 - val_loss: 6.4419\n",
      "Epoch 2499/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4131 - val_loss: 6.4422\n",
      "Epoch 2500/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4130 - val_loss: 6.4419\n",
      "Epoch 2501/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4129 - val_loss: 6.4451\n",
      "Epoch 2502/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4128 - val_loss: 6.4416\n",
      "Epoch 2503/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4128 - val_loss: 6.4420\n",
      "Epoch 2504/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4126 - val_loss: 6.4421\n",
      "Epoch 2505/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4126 - val_loss: 6.4421\n",
      "Epoch 2506/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4125 - val_loss: 6.4411\n",
      "Epoch 2507/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4124 - val_loss: 6.4413\n",
      "Epoch 2508/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4123 - val_loss: 6.4407\n",
      "Epoch 2509/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4122 - val_loss: 6.4419\n",
      "Epoch 2510/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4121 - val_loss: 6.4416\n",
      "Epoch 2511/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4120 - val_loss: 6.4404\n",
      "Epoch 2512/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4119 - val_loss: 6.4407\n",
      "Epoch 2513/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4118 - val_loss: 6.4403\n",
      "Epoch 2514/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4117 - val_loss: 6.4404\n",
      "Epoch 2515/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4116 - val_loss: 6.4400\n",
      "Epoch 2516/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4115 - val_loss: 6.4431\n",
      "Epoch 2517/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4114 - val_loss: 6.4413\n",
      "Epoch 2518/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4114 - val_loss: 6.4403\n",
      "Epoch 2519/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4113 - val_loss: 6.4440\n",
      "Epoch 2520/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4112 - val_loss: 6.4404\n",
      "Epoch 2521/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4111 - val_loss: 6.4399\n",
      "Epoch 2522/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4110 - val_loss: 6.4403\n",
      "Epoch 2523/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4109 - val_loss: 6.4403\n",
      "Epoch 2524/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4108 - val_loss: 6.4392\n",
      "Epoch 2525/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4107 - val_loss: 6.4401\n",
      "Epoch 2526/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.4107 - val_loss: 6.4394\n",
      "Epoch 2527/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.4105 - val_loss: 6.4405\n",
      "Epoch 2528/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.4105 - val_loss: 6.4394\n",
      "Epoch 2529/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4104 - val_loss: 6.4389\n",
      "Epoch 2530/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4103 - val_loss: 6.4402\n",
      "Epoch 2531/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4102 - val_loss: 6.4391\n",
      "Epoch 2532/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4101 - val_loss: 6.4399\n",
      "Epoch 2533/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4100 - val_loss: 6.4388\n",
      "Epoch 2534/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4099 - val_loss: 6.4398\n",
      "Epoch 2535/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4097 - val_loss: 6.4455\n",
      "Epoch 2536/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4097 - val_loss: 6.4388\n",
      "Epoch 2537/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4096 - val_loss: 6.4392\n",
      "Epoch 2538/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4096 - val_loss: 6.4405\n",
      "Epoch 2539/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4095 - val_loss: 6.4379\n",
      "Epoch 2540/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4094 - val_loss: 6.4377\n",
      "Epoch 2541/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4093 - val_loss: 6.4393\n",
      "Epoch 2542/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4091 - val_loss: 6.4379\n",
      "Epoch 2543/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4091 - val_loss: 6.4379\n",
      "Epoch 2544/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4090 - val_loss: 6.4373\n",
      "Epoch 2545/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4089 - val_loss: 6.4377\n",
      "Epoch 2546/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4088 - val_loss: 6.4371\n",
      "Epoch 2547/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4087 - val_loss: 6.4369\n",
      "Epoch 2548/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4086 - val_loss: 6.4370\n",
      "Epoch 2549/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4085 - val_loss: 6.4373\n",
      "Epoch 2550/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4084 - val_loss: 6.4369\n",
      "Epoch 2551/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4084 - val_loss: 6.4368\n",
      "Epoch 2552/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4083 - val_loss: 6.4376\n",
      "Epoch 2553/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4081 - val_loss: 6.4365\n",
      "Epoch 2554/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4080 - val_loss: 6.4403\n",
      "Epoch 2555/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4080 - val_loss: 6.4375\n",
      "Epoch 2556/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.4080 - val_loss: 6.4384\n",
      "Epoch 2557/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.4079 - val_loss: 6.4366\n",
      "Epoch 2558/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4077 - val_loss: 6.4361\n",
      "Epoch 2559/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4077 - val_loss: 6.4362\n",
      "Epoch 2560/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4076 - val_loss: 6.4360\n",
      "Epoch 2561/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4075 - val_loss: 6.4368\n",
      "Epoch 2562/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4073 - val_loss: 6.4358\n",
      "Epoch 2563/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4072 - val_loss: 6.4373\n",
      "Epoch 2564/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4072 - val_loss: 6.4354\n",
      "Epoch 2565/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4071 - val_loss: 6.4371\n",
      "Epoch 2566/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4071 - val_loss: 6.4361\n",
      "Epoch 2567/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4069 - val_loss: 6.4352\n",
      "Epoch 2568/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4068 - val_loss: 6.4351\n",
      "Epoch 2569/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4068 - val_loss: 6.4370\n",
      "Epoch 2570/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4067 - val_loss: 6.4369\n",
      "Epoch 2571/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4065 - val_loss: 6.4349\n",
      "Epoch 2572/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4065 - val_loss: 6.4349\n",
      "Epoch 2573/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4064 - val_loss: 6.4355\n",
      "Epoch 2574/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4063 - val_loss: 6.4345\n",
      "Epoch 2575/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4062 - val_loss: 6.4346\n",
      "Epoch 2576/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4061 - val_loss: 6.4346\n",
      "Epoch 2577/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4061 - val_loss: 6.4371\n",
      "Epoch 2578/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4059 - val_loss: 6.4362\n",
      "Epoch 2579/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4059 - val_loss: 6.4376\n",
      "Epoch 2580/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4058 - val_loss: 6.4345\n",
      "Epoch 2581/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4057 - val_loss: 6.4338\n",
      "Epoch 2582/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4056 - val_loss: 6.4388\n",
      "Epoch 2583/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4055 - val_loss: 6.4347\n",
      "Epoch 2584/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4054 - val_loss: 6.4338\n",
      "Epoch 2585/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4052 - val_loss: 6.4338\n",
      "Epoch 2586/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4053 - val_loss: 6.4359\n",
      "Epoch 2587/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4051 - val_loss: 6.4337\n",
      "Epoch 2588/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4051 - val_loss: 6.4334\n",
      "Epoch 2589/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4049 - val_loss: 6.4338\n",
      "Epoch 2590/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4049 - val_loss: 6.4333\n",
      "Epoch 2591/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4048 - val_loss: 6.4339\n",
      "Epoch 2592/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4047 - val_loss: 6.4340\n",
      "Epoch 2593/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4047 - val_loss: 6.4340\n",
      "Epoch 2594/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4045 - val_loss: 6.4344\n",
      "Epoch 2595/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4045 - val_loss: 6.4344\n",
      "Epoch 2596/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4043 - val_loss: 6.4334\n",
      "Epoch 2597/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4043 - val_loss: 6.4333\n",
      "Epoch 2598/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4042 - val_loss: 6.4337\n",
      "Epoch 2599/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4041 - val_loss: 6.4329\n",
      "Epoch 2600/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4040 - val_loss: 6.4322\n",
      "Epoch 2601/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4040 - val_loss: 6.4321\n",
      "Epoch 2602/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4038 - val_loss: 6.4337\n",
      "Epoch 2603/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4038 - val_loss: 6.4332\n",
      "Epoch 2604/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4037 - val_loss: 6.4326\n",
      "Epoch 2605/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4036 - val_loss: 6.4325\n",
      "Epoch 2606/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4035 - val_loss: 6.4333\n",
      "Epoch 2607/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4034 - val_loss: 6.4316\n",
      "Epoch 2608/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4034 - val_loss: 6.4322\n",
      "Epoch 2609/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4033 - val_loss: 6.4322\n",
      "Epoch 2610/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4032 - val_loss: 6.4318\n",
      "Epoch 2611/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4030 - val_loss: 6.4320\n",
      "Epoch 2612/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4030 - val_loss: 6.4312\n",
      "Epoch 2613/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4029 - val_loss: 6.4314\n",
      "Epoch 2614/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4029 - val_loss: 6.4311\n",
      "Epoch 2615/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4027 - val_loss: 6.4340\n",
      "Epoch 2616/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4027 - val_loss: 6.4307\n",
      "Epoch 2617/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4026 - val_loss: 6.4310\n",
      "Epoch 2618/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4025 - val_loss: 6.4306\n",
      "Epoch 2619/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4024 - val_loss: 6.4310\n",
      "Epoch 2620/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4023 - val_loss: 6.4307\n",
      "Epoch 2621/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4022 - val_loss: 6.4307\n",
      "Epoch 2622/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4020 - val_loss: 6.4308\n",
      "Epoch 2623/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.4020 - val_loss: 6.4308\n",
      "Epoch 2624/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4020 - val_loss: 6.4303\n",
      "Epoch 2625/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4019 - val_loss: 6.4299\n",
      "Epoch 2626/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4017 - val_loss: 6.4304\n",
      "Epoch 2627/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4017 - val_loss: 6.4298\n",
      "Epoch 2628/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4017 - val_loss: 6.4307\n",
      "Epoch 2629/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4015 - val_loss: 6.4304\n",
      "Epoch 2630/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4014 - val_loss: 6.4304\n",
      "Epoch 2631/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4014 - val_loss: 6.4298\n",
      "Epoch 2632/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4013 - val_loss: 6.4295\n",
      "Epoch 2633/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4011 - val_loss: 6.4319\n",
      "Epoch 2634/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4011 - val_loss: 6.4292\n",
      "Epoch 2635/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4010 - val_loss: 6.4292\n",
      "Epoch 2636/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4009 - val_loss: 6.4294\n",
      "Epoch 2637/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4009 - val_loss: 6.4294\n",
      "Epoch 2638/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4008 - val_loss: 6.4309\n",
      "Epoch 2639/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4007 - val_loss: 6.4294\n",
      "Epoch 2640/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4006 - val_loss: 6.4292\n",
      "Epoch 2641/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4005 - val_loss: 6.4296\n",
      "Epoch 2642/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4005 - val_loss: 6.4288\n",
      "Epoch 2643/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4003 - val_loss: 6.4327\n",
      "Epoch 2644/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4003 - val_loss: 6.4285\n",
      "Epoch 2645/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4002 - val_loss: 6.4316\n",
      "Epoch 2646/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.4001 - val_loss: 6.4281\n",
      "Epoch 2647/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.4000 - val_loss: 6.4281\n",
      "Epoch 2648/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3999 - val_loss: 6.4284\n",
      "Epoch 2649/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3999 - val_loss: 6.4279\n",
      "Epoch 2650/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3997 - val_loss: 6.4297\n",
      "Epoch 2651/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3997 - val_loss: 6.4280\n",
      "Epoch 2652/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3995 - val_loss: 6.4289\n",
      "Epoch 2653/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3995 - val_loss: 6.4278\n",
      "Epoch 2654/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3994 - val_loss: 6.4278\n",
      "Epoch 2655/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3993 - val_loss: 6.4277\n",
      "Epoch 2656/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3993 - val_loss: 6.4282\n",
      "Epoch 2657/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3992 - val_loss: 6.4280\n",
      "Epoch 2658/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3992 - val_loss: 6.4296\n",
      "Epoch 2659/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3989 - val_loss: 6.4271\n",
      "Epoch 2660/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3989 - val_loss: 6.4275\n",
      "Epoch 2661/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3989 - val_loss: 6.4280\n",
      "Epoch 2662/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3987 - val_loss: 6.4276\n",
      "Epoch 2663/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3986 - val_loss: 6.4275\n",
      "Epoch 2664/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3986 - val_loss: 6.4331\n",
      "Epoch 2665/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3986 - val_loss: 6.4273\n",
      "Epoch 2666/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3983 - val_loss: 6.4274\n",
      "Epoch 2667/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3983 - val_loss: 6.4267\n",
      "Epoch 2668/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3983 - val_loss: 6.4264\n",
      "Epoch 2669/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3982 - val_loss: 6.4271\n",
      "Epoch 2670/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3981 - val_loss: 6.4259\n",
      "Epoch 2671/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3980 - val_loss: 6.4270\n",
      "Epoch 2672/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3979 - val_loss: 6.4276\n",
      "Epoch 2673/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3979 - val_loss: 6.4260\n",
      "Epoch 2674/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3978 - val_loss: 6.4262\n",
      "Epoch 2675/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3977 - val_loss: 6.4258\n",
      "Epoch 2676/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3976 - val_loss: 6.4257\n",
      "Epoch 2677/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3975 - val_loss: 6.4254\n",
      "Epoch 2678/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3974 - val_loss: 6.4254\n",
      "Epoch 2679/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3974 - val_loss: 6.4256\n",
      "Epoch 2680/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3973 - val_loss: 6.4259\n",
      "Epoch 2681/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3972 - val_loss: 6.4251\n",
      "Epoch 2682/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3971 - val_loss: 6.4280\n",
      "Epoch 2683/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3970 - val_loss: 6.4272\n",
      "Epoch 2684/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.3969 - val_loss: 6.4264\n",
      "Epoch 2685/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 6.3969 - val_loss: 6.4249\n",
      "Epoch 2686/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 6.3968 - val_loss: 6.4249\n",
      "Epoch 2687/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 6.3967 - val_loss: 6.4255\n",
      "Epoch 2688/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 6.3966 - val_loss: 6.4263\n",
      "Epoch 2689/3000\n",
      "4686/4686 [==============================] - 0s 45us/sample - loss: 6.3965 - val_loss: 6.4244\n",
      "Epoch 2690/3000\n",
      "4686/4686 [==============================] - 0s 44us/sample - loss: 6.3965 - val_loss: 6.4246\n",
      "Epoch 2691/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.3964 - val_loss: 6.4245\n",
      "Epoch 2692/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3962 - val_loss: 6.4261\n",
      "Epoch 2693/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3962 - val_loss: 6.4257\n",
      "Epoch 2694/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3961 - val_loss: 6.4242\n",
      "Epoch 2695/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3960 - val_loss: 6.4254\n",
      "Epoch 2696/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3959 - val_loss: 6.4245\n",
      "Epoch 2697/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3958 - val_loss: 6.4259\n",
      "Epoch 2698/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3958 - val_loss: 6.4238\n",
      "Epoch 2699/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3957 - val_loss: 6.4237\n",
      "Epoch 2700/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3957 - val_loss: 6.4241\n",
      "Epoch 2701/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3955 - val_loss: 6.4248\n",
      "Epoch 2702/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3955 - val_loss: 6.4238\n",
      "Epoch 2703/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.3954 - val_loss: 6.4246\n",
      "Epoch 2704/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3953 - val_loss: 6.4286\n",
      "Epoch 2705/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3952 - val_loss: 6.4236\n",
      "Epoch 2706/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3952 - val_loss: 6.4230\n",
      "Epoch 2707/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3950 - val_loss: 6.4232\n",
      "Epoch 2708/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3950 - val_loss: 6.4229\n",
      "Epoch 2709/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.3949 - val_loss: 6.4256\n",
      "Epoch 2710/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3948 - val_loss: 6.4235\n",
      "Epoch 2711/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3947 - val_loss: 6.4237\n",
      "Epoch 2712/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3946 - val_loss: 6.4302\n",
      "Epoch 2713/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3946 - val_loss: 6.4225\n",
      "Epoch 2714/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3945 - val_loss: 6.4228\n",
      "Epoch 2715/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3943 - val_loss: 6.4224\n",
      "Epoch 2716/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3943 - val_loss: 6.4263\n",
      "Epoch 2717/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3943 - val_loss: 6.4221\n",
      "Epoch 2718/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3943 - val_loss: 6.4230\n",
      "Epoch 2719/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.3941 - val_loss: 6.4225\n",
      "Epoch 2720/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3940 - val_loss: 6.4245\n",
      "Epoch 2721/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3940 - val_loss: 6.4219\n",
      "Epoch 2722/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3938 - val_loss: 6.4237\n",
      "Epoch 2723/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3939 - val_loss: 6.4223\n",
      "Epoch 2724/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3937 - val_loss: 6.4227\n",
      "Epoch 2725/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3936 - val_loss: 6.4222\n",
      "Epoch 2726/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3935 - val_loss: 6.4220\n",
      "Epoch 2727/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3935 - val_loss: 6.4225\n",
      "Epoch 2728/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3934 - val_loss: 6.4212\n",
      "Epoch 2729/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3933 - val_loss: 6.4248\n",
      "Epoch 2730/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3932 - val_loss: 6.4217\n",
      "Epoch 2731/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3931 - val_loss: 6.4225\n",
      "Epoch 2732/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3931 - val_loss: 6.4212\n",
      "Epoch 2733/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3929 - val_loss: 6.4207\n",
      "Epoch 2734/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3929 - val_loss: 6.4212\n",
      "Epoch 2735/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3928 - val_loss: 6.4231\n",
      "Epoch 2736/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3928 - val_loss: 6.4213\n",
      "Epoch 2737/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3926 - val_loss: 6.4210\n",
      "Epoch 2738/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3926 - val_loss: 6.4213\n",
      "Epoch 2739/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.3925 - val_loss: 6.4207\n",
      "Epoch 2740/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3924 - val_loss: 6.4208\n",
      "Epoch 2741/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3924 - val_loss: 6.4201\n",
      "Epoch 2742/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3923 - val_loss: 6.4204\n",
      "Epoch 2743/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3922 - val_loss: 6.4200\n",
      "Epoch 2744/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3921 - val_loss: 6.4231\n",
      "Epoch 2745/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3920 - val_loss: 6.4198\n",
      "Epoch 2746/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3919 - val_loss: 6.4200\n",
      "Epoch 2747/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3919 - val_loss: 6.4201\n",
      "Epoch 2748/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3918 - val_loss: 6.4203\n",
      "Epoch 2749/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3917 - val_loss: 6.4228\n",
      "Epoch 2750/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3917 - val_loss: 6.4195\n",
      "Epoch 2751/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3916 - val_loss: 6.4208\n",
      "Epoch 2752/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3915 - val_loss: 6.4200\n",
      "Epoch 2753/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3914 - val_loss: 6.4191\n",
      "Epoch 2754/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3913 - val_loss: 6.4192\n",
      "Epoch 2755/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3913 - val_loss: 6.4191\n",
      "Epoch 2756/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3911 - val_loss: 6.4194\n",
      "Epoch 2757/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3911 - val_loss: 6.4195\n",
      "Epoch 2758/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3911 - val_loss: 6.4192\n",
      "Epoch 2759/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3909 - val_loss: 6.4194\n",
      "Epoch 2760/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3910 - val_loss: 6.4188\n",
      "Epoch 2761/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3908 - val_loss: 6.4198\n",
      "Epoch 2762/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3907 - val_loss: 6.4215\n",
      "Epoch 2763/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3906 - val_loss: 6.4193\n",
      "Epoch 2764/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3905 - val_loss: 6.4192\n",
      "Epoch 2765/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3905 - val_loss: 6.4186\n",
      "Epoch 2766/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3904 - val_loss: 6.4185\n",
      "Epoch 2767/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3903 - val_loss: 6.4209\n",
      "Epoch 2768/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3903 - val_loss: 6.4192\n",
      "Epoch 2769/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3901 - val_loss: 6.4185\n",
      "Epoch 2770/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3900 - val_loss: 6.4185\n",
      "Epoch 2771/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3900 - val_loss: 6.4176\n",
      "Epoch 2772/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3899 - val_loss: 6.4179\n",
      "Epoch 2773/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3899 - val_loss: 6.4176\n",
      "Epoch 2774/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3898 - val_loss: 6.4193\n",
      "Epoch 2775/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3897 - val_loss: 6.4173\n",
      "Epoch 2776/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3896 - val_loss: 6.4184\n",
      "Epoch 2777/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3896 - val_loss: 6.4184\n",
      "Epoch 2778/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3895 - val_loss: 6.4177\n",
      "Epoch 2779/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3894 - val_loss: 6.4179\n",
      "Epoch 2780/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3894 - val_loss: 6.4212\n",
      "Epoch 2781/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3893 - val_loss: 6.4178\n",
      "Epoch 2782/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3891 - val_loss: 6.4182\n",
      "Epoch 2783/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3891 - val_loss: 6.4171\n",
      "Epoch 2784/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3890 - val_loss: 6.4170\n",
      "Epoch 2785/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3889 - val_loss: 6.4177\n",
      "Epoch 2786/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.3888 - val_loss: 6.4168\n",
      "Epoch 2787/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3889 - val_loss: 6.4175\n",
      "Epoch 2788/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3887 - val_loss: 6.4172\n",
      "Epoch 2789/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3886 - val_loss: 6.4163\n",
      "Epoch 2790/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3885 - val_loss: 6.4197\n",
      "Epoch 2791/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.3885 - val_loss: 6.4165\n",
      "Epoch 2792/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3884 - val_loss: 6.4162\n",
      "Epoch 2793/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3883 - val_loss: 6.4170\n",
      "Epoch 2794/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3882 - val_loss: 6.4165\n",
      "Epoch 2795/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3881 - val_loss: 6.4168\n",
      "Epoch 2796/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3882 - val_loss: 6.4159\n",
      "Epoch 2797/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3880 - val_loss: 6.4162\n",
      "Epoch 2798/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3879 - val_loss: 6.4166\n",
      "Epoch 2799/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3879 - val_loss: 6.4170\n",
      "Epoch 2800/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3878 - val_loss: 6.4156\n",
      "Epoch 2801/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3878 - val_loss: 6.4158\n",
      "Epoch 2802/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3876 - val_loss: 6.4153\n",
      "Epoch 2803/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3876 - val_loss: 6.4162\n",
      "Epoch 2804/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3875 - val_loss: 6.4169\n",
      "Epoch 2805/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3875 - val_loss: 6.4160\n",
      "Epoch 2806/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3873 - val_loss: 6.4168\n",
      "Epoch 2807/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3873 - val_loss: 6.4161\n",
      "Epoch 2808/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3872 - val_loss: 6.4248\n",
      "Epoch 2809/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3872 - val_loss: 6.4155\n",
      "Epoch 2810/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3870 - val_loss: 6.4148\n",
      "Epoch 2811/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3869 - val_loss: 6.4183\n",
      "Epoch 2812/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3869 - val_loss: 6.4157\n",
      "Epoch 2813/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3868 - val_loss: 6.4160\n",
      "Epoch 2814/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3867 - val_loss: 6.4159\n",
      "Epoch 2815/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3867 - val_loss: 6.4144\n",
      "Epoch 2816/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3866 - val_loss: 6.4145\n",
      "Epoch 2817/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3865 - val_loss: 6.4146\n",
      "Epoch 2818/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.3864 - val_loss: 6.4144\n",
      "Epoch 2819/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3865 - val_loss: 6.4163\n",
      "Epoch 2820/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3863 - val_loss: 6.4141\n",
      "Epoch 2821/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3863 - val_loss: 6.4149\n",
      "Epoch 2822/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3861 - val_loss: 6.4164\n",
      "Epoch 2823/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3860 - val_loss: 6.4137\n",
      "Epoch 2824/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3859 - val_loss: 6.4160\n",
      "Epoch 2825/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3858 - val_loss: 6.4138\n",
      "Epoch 2826/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3859 - val_loss: 6.4141\n",
      "Epoch 2827/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3857 - val_loss: 6.4145\n",
      "Epoch 2828/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3857 - val_loss: 6.4138\n",
      "Epoch 2829/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3857 - val_loss: 6.4179\n",
      "Epoch 2830/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3855 - val_loss: 6.4131\n",
      "Epoch 2831/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3854 - val_loss: 6.4148\n",
      "Epoch 2832/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3854 - val_loss: 6.4129\n",
      "Epoch 2833/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3853 - val_loss: 6.4149\n",
      "Epoch 2834/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.3852 - val_loss: 6.4155\n",
      "Epoch 2835/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3851 - val_loss: 6.4144\n",
      "Epoch 2836/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3851 - val_loss: 6.4129\n",
      "Epoch 2837/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3850 - val_loss: 6.4127\n",
      "Epoch 2838/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3850 - val_loss: 6.4126\n",
      "Epoch 2839/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.3849 - val_loss: 6.4162\n",
      "Epoch 2840/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3848 - val_loss: 6.4129\n",
      "Epoch 2841/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3848 - val_loss: 6.4126\n",
      "Epoch 2842/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3846 - val_loss: 6.4125\n",
      "Epoch 2843/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3846 - val_loss: 6.4127\n",
      "Epoch 2844/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3845 - val_loss: 6.4121\n",
      "Epoch 2845/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3844 - val_loss: 6.4138\n",
      "Epoch 2846/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3844 - val_loss: 6.4119\n",
      "Epoch 2847/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3843 - val_loss: 6.4119\n",
      "Epoch 2848/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3843 - val_loss: 6.4130\n",
      "Epoch 2849/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3842 - val_loss: 6.4117\n",
      "Epoch 2850/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3840 - val_loss: 6.4128\n",
      "Epoch 2851/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3840 - val_loss: 6.4121\n",
      "Epoch 2852/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3840 - val_loss: 6.4118\n",
      "Epoch 2853/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3839 - val_loss: 6.4115\n",
      "Epoch 2854/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3838 - val_loss: 6.4115\n",
      "Epoch 2855/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3836 - val_loss: 6.4117\n",
      "Epoch 2856/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3836 - val_loss: 6.4116\n",
      "Epoch 2857/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3836 - val_loss: 6.4117\n",
      "Epoch 2858/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3835 - val_loss: 6.4118\n",
      "Epoch 2859/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.3834 - val_loss: 6.4128\n",
      "Epoch 2860/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3833 - val_loss: 6.4109\n",
      "Epoch 2861/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3833 - val_loss: 6.4117\n",
      "Epoch 2862/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3833 - val_loss: 6.4108\n",
      "Epoch 2863/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3831 - val_loss: 6.4121\n",
      "Epoch 2864/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3831 - val_loss: 6.4110\n",
      "Epoch 2865/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3831 - val_loss: 6.4120\n",
      "Epoch 2866/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3829 - val_loss: 6.4120\n",
      "Epoch 2867/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3828 - val_loss: 6.4108\n",
      "Epoch 2868/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3828 - val_loss: 6.4106\n",
      "Epoch 2869/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3827 - val_loss: 6.4104\n",
      "Epoch 2870/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3825 - val_loss: 6.4108\n",
      "Epoch 2871/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3825 - val_loss: 6.4099\n",
      "Epoch 2872/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3824 - val_loss: 6.4123\n",
      "Epoch 2873/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3823 - val_loss: 6.4101\n",
      "Epoch 2874/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3823 - val_loss: 6.4113\n",
      "Epoch 2875/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3823 - val_loss: 6.4158\n",
      "Epoch 2876/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3822 - val_loss: 6.4104\n",
      "Epoch 2877/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3821 - val_loss: 6.4108\n",
      "Epoch 2878/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3820 - val_loss: 6.4097\n",
      "Epoch 2879/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3819 - val_loss: 6.4129\n",
      "Epoch 2880/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3819 - val_loss: 6.4103\n",
      "Epoch 2881/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3818 - val_loss: 6.4094\n",
      "Epoch 2882/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3818 - val_loss: 6.4110\n",
      "Epoch 2883/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3817 - val_loss: 6.4095\n",
      "Epoch 2884/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3816 - val_loss: 6.4105\n",
      "Epoch 2885/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3815 - val_loss: 6.4090\n",
      "Epoch 2886/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3815 - val_loss: 6.4099\n",
      "Epoch 2887/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3813 - val_loss: 6.4090\n",
      "Epoch 2888/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3813 - val_loss: 6.4089\n",
      "Epoch 2889/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3812 - val_loss: 6.4102\n",
      "Epoch 2890/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.3812 - val_loss: 6.4087\n",
      "Epoch 2891/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3810 - val_loss: 6.4088\n",
      "Epoch 2892/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3810 - val_loss: 6.4106\n",
      "Epoch 2893/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3809 - val_loss: 6.4089\n",
      "Epoch 2894/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3810 - val_loss: 6.4090\n",
      "Epoch 2895/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3808 - val_loss: 6.4088\n",
      "Epoch 2896/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3808 - val_loss: 6.4086\n",
      "Epoch 2897/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3807 - val_loss: 6.4093\n",
      "Epoch 2898/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3806 - val_loss: 6.4092\n",
      "Epoch 2899/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3806 - val_loss: 6.4090\n",
      "Epoch 2900/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3805 - val_loss: 6.4097\n",
      "Epoch 2901/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3804 - val_loss: 6.4081\n",
      "Epoch 2902/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3803 - val_loss: 6.4082\n",
      "Epoch 2903/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3803 - val_loss: 6.4082\n",
      "Epoch 2904/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3802 - val_loss: 6.4086\n",
      "Epoch 2905/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3802 - val_loss: 6.4095\n",
      "Epoch 2906/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3800 - val_loss: 6.4078\n",
      "Epoch 2907/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3799 - val_loss: 6.4074\n",
      "Epoch 2908/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3799 - val_loss: 6.4074\n",
      "Epoch 2909/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3799 - val_loss: 6.4073\n",
      "Epoch 2910/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3797 - val_loss: 6.4073\n",
      "Epoch 2911/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3797 - val_loss: 6.4072\n",
      "Epoch 2912/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.3796 - val_loss: 6.4096\n",
      "Epoch 2913/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3795 - val_loss: 6.4069\n",
      "Epoch 2914/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3795 - val_loss: 6.4088\n",
      "Epoch 2915/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3793 - val_loss: 6.4069\n",
      "Epoch 2916/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3793 - val_loss: 6.4084\n",
      "Epoch 2917/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3793 - val_loss: 6.4067\n",
      "Epoch 2918/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3792 - val_loss: 6.4070\n",
      "Epoch 2919/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3792 - val_loss: 6.4068\n",
      "Epoch 2920/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3790 - val_loss: 6.4068\n",
      "Epoch 2921/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3791 - val_loss: 6.4098\n",
      "Epoch 2922/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3789 - val_loss: 6.4071\n",
      "Epoch 2923/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3788 - val_loss: 6.4062\n",
      "Epoch 2924/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3787 - val_loss: 6.4070\n",
      "Epoch 2925/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3787 - val_loss: 6.4064\n",
      "Epoch 2926/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3787 - val_loss: 6.4063\n",
      "Epoch 2927/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3786 - val_loss: 6.4069\n",
      "Epoch 2928/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3785 - val_loss: 6.4058\n",
      "Epoch 2929/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3784 - val_loss: 6.4062\n",
      "Epoch 2930/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3783 - val_loss: 6.4058\n",
      "Epoch 2931/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3783 - val_loss: 6.4059\n",
      "Epoch 2932/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3783 - val_loss: 6.4073\n",
      "Epoch 2933/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3782 - val_loss: 6.4078\n",
      "Epoch 2934/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3780 - val_loss: 6.4058\n",
      "Epoch 2935/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3780 - val_loss: 6.4054\n",
      "Epoch 2936/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3780 - val_loss: 6.4053\n",
      "Epoch 2937/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3778 - val_loss: 6.4052\n",
      "Epoch 2938/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3778 - val_loss: 6.4056\n",
      "Epoch 2939/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3778 - val_loss: 6.4050\n",
      "Epoch 2940/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3776 - val_loss: 6.4094\n",
      "Epoch 2941/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3776 - val_loss: 6.4055\n",
      "Epoch 2942/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3776 - val_loss: 6.4057\n",
      "Epoch 2943/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3774 - val_loss: 6.4056\n",
      "Epoch 2944/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3774 - val_loss: 6.4058\n",
      "Epoch 2945/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3773 - val_loss: 6.4073\n",
      "Epoch 2946/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3772 - val_loss: 6.4057\n",
      "Epoch 2947/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3772 - val_loss: 6.4052\n",
      "Epoch 2948/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3772 - val_loss: 6.4055\n",
      "Epoch 2949/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3770 - val_loss: 6.4044\n",
      "Epoch 2950/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3769 - val_loss: 6.4049\n",
      "Epoch 2951/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3769 - val_loss: 6.4043\n",
      "Epoch 2952/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3768 - val_loss: 6.4050\n",
      "Epoch 2953/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3768 - val_loss: 6.4054\n",
      "Epoch 2954/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3767 - val_loss: 6.4049\n",
      "Epoch 2955/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3767 - val_loss: 6.4040\n",
      "Epoch 2956/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3765 - val_loss: 6.4039\n",
      "Epoch 2957/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3765 - val_loss: 6.4042\n",
      "Epoch 2958/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3765 - val_loss: 6.4041\n",
      "Epoch 2959/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3763 - val_loss: 6.4037\n",
      "Epoch 2960/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3763 - val_loss: 6.4048\n",
      "Epoch 2961/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.3762 - val_loss: 6.4072\n",
      "Epoch 2962/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3762 - val_loss: 6.4040\n",
      "Epoch 2963/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3761 - val_loss: 6.4035\n",
      "Epoch 2964/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3761 - val_loss: 6.4036\n",
      "Epoch 2965/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3760 - val_loss: 6.4034\n",
      "Epoch 2966/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.3759 - val_loss: 6.4053\n",
      "Epoch 2967/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3758 - val_loss: 6.4035\n",
      "Epoch 2968/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3758 - val_loss: 6.4031\n",
      "Epoch 2969/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3757 - val_loss: 6.4037\n",
      "Epoch 2970/3000\n",
      "4686/4686 [==============================] - 0s 43us/sample - loss: 6.3756 - val_loss: 6.4034\n",
      "Epoch 2971/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3755 - val_loss: 6.4035\n",
      "Epoch 2972/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3755 - val_loss: 6.4031\n",
      "Epoch 2973/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3754 - val_loss: 6.4047\n",
      "Epoch 2974/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3753 - val_loss: 6.4035\n",
      "Epoch 2975/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.3753 - val_loss: 6.4035\n",
      "Epoch 2976/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3752 - val_loss: 6.4033\n",
      "Epoch 2977/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3752 - val_loss: 6.4031\n",
      "Epoch 2978/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3751 - val_loss: 6.4026\n",
      "Epoch 2979/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.3750 - val_loss: 6.4027\n",
      "Epoch 2980/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3749 - val_loss: 6.4024\n",
      "Epoch 2981/3000\n",
      "4686/4686 [==============================] - 0s 40us/sample - loss: 6.3749 - val_loss: 6.4029\n",
      "Epoch 2982/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3748 - val_loss: 6.4021\n",
      "Epoch 2983/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3747 - val_loss: 6.4042\n",
      "Epoch 2984/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3747 - val_loss: 6.4023\n",
      "Epoch 2985/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3746 - val_loss: 6.4021\n",
      "Epoch 2986/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3745 - val_loss: 6.4037\n",
      "Epoch 2987/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3745 - val_loss: 6.4032\n",
      "Epoch 2988/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3744 - val_loss: 6.4017\n",
      "Epoch 2989/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3743 - val_loss: 6.4017\n",
      "Epoch 2990/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3742 - val_loss: 6.4017\n",
      "Epoch 2991/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3742 - val_loss: 6.4020\n",
      "Epoch 2992/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3741 - val_loss: 6.4031\n",
      "Epoch 2993/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3741 - val_loss: 6.4017\n",
      "Epoch 2994/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3740 - val_loss: 6.4012\n",
      "Epoch 2995/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3739 - val_loss: 6.4014\n",
      "Epoch 2996/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3738 - val_loss: 6.4068\n",
      "Epoch 2997/3000\n",
      "4686/4686 [==============================] - 0s 42us/sample - loss: 6.3738 - val_loss: 6.4011\n",
      "Epoch 2998/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3737 - val_loss: 6.4022\n",
      "Epoch 2999/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3736 - val_loss: 6.4010\n",
      "Epoch 3000/3000\n",
      "4686/4686 [==============================] - 0s 41us/sample - loss: 6.3736 - val_loss: 6.4013\n",
      "dca: Calculating reconstructions...\n"
     ]
    }
   ],
   "source": [
    "res = dca(adata,\n",
    "          ae_type='meth-simple-encoder',\n",
    "          return_info=True,\n",
    "          return_model=True,\n",
    "          return_bottleneck=True,\n",
    "          verbose=True,\n",
    "          early_stop=50,\n",
    "          epochs=3000,\n",
    "          network_kwds={'debug': True},\n",
    "          init='glorot_normal',\n",
    "          hidden_size=(16,8,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8237a8",
   "metadata": {},
   "source": [
    "### Writing the data on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "di = '/users/lvelten/project/Methylome/analysis/missionbio/tapestri/' + sample + '/methylation_autoencoder/'\n",
    "if not os.path.isdir(di):\n",
    "    os.mkdir(di)\n",
    "    \n",
    "pd.DataFrame(adata.obsm['X_meth_value']).to_csv(di + 'mixture_prob_dca_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81520432",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = res.get_encoder().predict([adata.X, adata.X.mean(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beb56ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(adata.obsm['X_bottleneck']).to_csv(di + 'bottleneck.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62af1a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[159.77126],\n",
       "       [139.99767],\n",
       "       [167.62038],\n",
       "       ...,\n",
       "       [188.73166],\n",
       "       [137.76099],\n",
       "       [148.5073 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obsm['mean1_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26c5afa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 63.69657 ],\n",
       "       [ 39.869816],\n",
       "       [ 71.896454],\n",
       "       ...,\n",
       "       [100.23306 ],\n",
       "       [ 37.72623 ],\n",
       "       [ 47.666855]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obsm['mean2_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2377f23",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'alpha'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20978/475665408.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobsm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/users/mscherer/software/anaconda3/envs/dca/lib/python3.8/site-packages/anndata/_core/aligned_mapping.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'alpha'"
     ]
    }
   ],
   "source": [
    "adata.obsm['alpha']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
